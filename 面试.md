[TOC]

## mybatis

### mybatis工作原理

MyBatis 是支持定制化 SQL、存储过程以及高级映射的优秀的持久层框架。MyBatis 避免了几乎所有的 JDBC 代码和手工设置参数以及抽取结果集。MyBatis 使用简单的 XML 或注解来配置和映射基本体，将接口和 Java 的POJOs(Plain Old) 映射成数据库中的记录。

#### 传统的JDBC编程

（1）注册数据库驱动包，配置连接信息

（2）操作Connection对象，打开Statement对象

（3）使用Statement对象进行查询，返回ResultSet对象

（4）解析ResultSet中的数据，将其转化为POJO实体对象

（5）关闭数据库资源

上述操作存在的问题:

（1）工作量大，需要反复操作四个核心的API接口对象。

（2）需要对JDBC编程产生的异常进行捕捉和处理。

（3）如果项目业务复杂，JDBC代码也就越复杂。(MyBatis的必要性！)

mybatis框架原理图：

![](https://mmbiz.qpic.cn/mmbiz_png/e9yDYxtdb899pn1mWeicjHISib760gJuAWicjettaPe7HSYT5ic3ylLUA9reYYA5P2SwBXBDW55icG6sGYUnScQVaIg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

#### mybatis构成

- SqlSessionFactoryBuilder  

  SqlSessionFactoryBuilder是利用XML或者Java编码获得资源来构建SqlSessionFactory 的，通过它可以构建多个SessionFactory。它的作用仅仅是一个构建器而已，一旦我们构建了SessionFactory，那么它将毫无意义应立即回收！

- SqlSessionFactory

  SqlSessionFactory的作用是创建SqlSession，而SqlSession相当于一个会话，相当于JDBC中的connection对象，每次应用程序需要访问数据库,我们就要通过SqlSessionFactory创建SqlSession，所以SqlSessionFactory应该在整个应用的生命周期中。而如果我们多次创建同一个数据库的SqlSessionFactory，则每次创建的SqlSessionFactory会打开更多的数据库连接资源，那么连接资源很开会被耗尽，因此SqlSessionFactory的职责是唯一的。果断的采取单例模式，在应用中使用同一个SqlSessionFactory对象即可。

- SqlSession

   SqlSession是一个会话，相当于JDBC中的一个Connection对象，它的生命周期应该是在请求数据库处理事务的过程中，且SqlSession是线程非安全的对象，涉及多线程时要特别的当心，每次创建的SqlSession对象都要及时的关闭它，它长期存在就会使数据库连接池的活动资源减少，对系统性能影响很大。


#### mybatis配置文件详解

```
<?xml version="1.0" encoding="UTF-8"?>
<configuration><!-- 配置 -->
	<properties/><!-- 属性 可以配置在java属性配置文件中-->
	<settings/><!-- 设置 修改Mybatis在运行时的行为方式 -->
	<typeAliases/><!-- 类型命名 为java类型命名一个别名（简称） -->
	<typeHandlers/><!-- 类型处理器 -->
	<objectFactory/><!-- 对象工厂 -->
	<plugins/><!-- 插件 -->
	<environments><!-- 配合环境 -->
		<environment><!-- 环境变量 -->
			<transactionManager/><!-- 事务管理器 -->
			<dataSource/><!-- 数据源 -->
		</environment>
	</environments>
	<databaseIdProvider/><!-- 数据库厂商标识 -->
	<mappers/><!-- 映射器 -->
</configuration>
```

#### SQL映射文件

**使用Mapper的动态代理实现增删改查**

传统JDBC方式操作数据库：

- 声明dao接口
- 在dao接口的实现类daoimpl中编写sql语句执行

使用MyBatis操作数据库:

- 声明mapper接口
- 在mapper.xml文件中编写sql语句
- mapper接口的实现类中获取session和XML文件中的sql字句

> MyBatis框架自身就抛弃了MapperImpl类,让我们可以直接定位到mapper.xml文件中的sql语句。我们就可以通过sql操作数据库,  以上被称之为Mapper的动态代理。

**实现Mapper动态代理的步骤**

1. 删除UserMapperImpl 实现类
2. 保证UserMapper.xml文件中<mapper>节点的namespace的属性值为UserMapper接口的全类名(√)。
3. 保证UserMapper.xml文件中的insert/delete/update/select标签的id属性值和UserMapper.java中的方法名保持一致(√)。
4. session.insert()/delete()/update()/selectOne()方法执行，现在改变为session.getMapper(Mapper接口的Class对象)，通过代理的mapper实现类调用方法。

SQL映射文件的几个顶级元素(按照定义的顺序):

- mapper - namespace
- cache  -   配置给定命名空间的缓存
- cache-ref  -  从其他命名空间引用缓存配置
- resultMap  -  用来描述数据库结果集和对象的对应关系
- sql  -  可以重用的SQL块，也可以被其他语句引用
- insert  -  映射插入语句
- update  -  映射更新语句
- delete  -  映射删除语句
- select  -   映射查询语句

#### MyBatis的延迟加载策略和缓存

MyBatis中的延迟加载，也称为懒加载，是指在进行关联查询的时候，按照设置延迟加载规则推迟对关联对象的select检索。延迟加载可以有效的减少数据库的压力。

> 注意:MyBatis的延迟加载只是对关联对象的查询有延迟设置，对于主加载对象都是直接执行查询语句的。

关联对象的加载时机:

- 直接加载

  即执行对象的select语句，完成对主加载马上执行对关联对象的select查询。

- 侵入式延迟加载(aggressiveLazyLoading) 也可看做立即加载

  执行对主加载对象的查询时，不会执行对关联对象的查询。但是当要访问主加载对象的详情时马上执行对关联对象的select查询。即对关联对象的执行查询，侵入到了主加载对象的访问详情中。也可理解为:将关联对象的详情侵入到主加载对象的详情中去，即将关联对象的详情作为主加载对象的一部分出现了！

- 深度延迟加载

  执行对主加载对象的查询时，不会执行对关联对象的查询。访问主加载对象的详情时也不会执行关联对象的select查询。只有当真正访问关联对象的详情时，才会执行对关联对象的select查询。

> 注意的问题:延迟加载的应用要求：关联对象的查询与主加载对象的查询必须是分别进行的select语句，不能是使用多表连接所进行的select查询。因为，多表连接查询，实质是对一张表的查询，对由多个表连接后形成的一张表的查询。会一次性将多张表的所有信息查询出来。

#### Mybatis初始化原理

MyBatis采用了一个非常直白和简单的方式---使用 org.apache.ibatis.session.Configuration 对象作为一个所有配置信息的容器，Configuration对象的组织结构和XML配置文件的组织结构几乎完全一样。

MyBatis初始化的过程，就是创建 Configuration对象的过程。

MyBatis的初始化可以有两种方式：

- 基于XML配置文件：基于XML配置文件的方式是将MyBatis的所有配置信息放在XML文件中，MyBatis通过加载XML配置文件，将配置信息组装成内部的Configuration对象
- 基于Java API：这种方式不使用XML配置文件，需要MyBatis使用者在Java代码中，手动创建Configuration对象，然后将配置参数set 进入Configuration对象中

SqlSessionFactoryBuilder根据传入的数据流生成Configuration对象，然后根据Configuration对象创建默认的SqlSessionFactory实例。

![初始化原理](https://mmbiz.qpic.cn/mmbiz_png/0aWl00iaQWSGULHVyRGbxOaj6gaEAooLkjHtlSHh4IQO6TKZr2z4ObicXg1qxibanjWgeAlDC3MnN4f1wR7thsdwQ/640?tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

mybatis初始化要经过简单的以下几步：

- 调用SqlSessionFactoryBuilder对象的build(inputStream)方法；
- SqlSessionFactoryBuilder会根据输入流inputStream等信息创建XMLConfigBuilder对象;
- SqlSessionFactoryBuilder调用XMLConfigBuilder对象的parse()方法；
- XMLConfigBuilder对象返回Configuration对象；
- SqlSessionFactoryBuilder根据Configuration对象创建一个DefaultSessionFactory对象
- SqlSessionFactoryBuilder返回 DefaultSessionFactory对象给Client，供Client使用。

![](https://mmbiz.qpic.cn/mmbiz_png/0aWl00iaQWSGULHVyRGbxOaj6gaEAooLk4LFBNXia5sCQVKvcTndxuDvLx5HtyZkY0Eam1WJf4BZ7kwWQwkOKF7Q/640?tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)




### mybatis缓存机制

mybatis提供了缓存机制减轻数据库压力，提高数据库性能

查询缓存分为一级缓存和二级缓存

mybatis默认只开启一级缓存

一级缓存是SqlSession级别的缓存，缓存的数据只在SqlSession内有效

二级缓存是mapper级别的缓存，同一个namespace共用这一个缓存，所以对SqlSession是共享的

#### 一级缓存

mybatis的一级缓存是SqlSession级别的缓存，在操作数据库的时候需要先创建SqlSession会话对象，在对象中有一个HashMap用于存储缓存数据，此HashMap是当前会话对象私有的，别的SqlSession会话对象无法访问。

**流程：** 

1. 第一次执行select完毕会将查到的数据写入SqlSession内的HashMap中缓存起来
2. 第二次执行select会从缓存中查数据，如果select相同且传参数一样，那么就能从缓存中返回数据，不用去数据库了，从而提高了效率

**注意：**  

1. 如果SqlSession执行了DML操作（insert、update、delete），并commit了，那么mybatis就会清空当前SqlSession缓存中的所有缓存数据，这样可以保证缓存中的存的数据永远和数据库中一致，避免出现脏读
2. 当一个SqlSession结束后那么他里面的一级缓存也就不存在了，mybatis默认是开启一级缓存，不需要配置
3. mybatis的缓存是基于[namespace:sql语句:参数]来进行缓存的，意思就是，SqlSession的HashMap存储缓存数据时，是使用[namespace:sql:参数]作为key，查询返回的语句作为value保存的。

#### 二级缓存

二级缓存是mapper级别的缓存，也就是同一个namespace的mappe.xml，当多个SqlSession使用同一个Mapper操作数据库的时候，得到的数据会缓存在同一个二级缓存区域

二级缓存默认是没有开启的。需要在setting全局参数中配置开启二级缓存  在conf.xml：

```
<settings>
        <setting name="cacheEnabled" value="true"/><!--默认是false：关闭二级缓存-->
<settings>
```

在xxxMapper.xml中配置：

```
<cache eviction="LRU" flushInterval="60000" size="512" readOnly="true"/><!--当前mapper下所有语句开启二级缓存-->
```

表示: 配置了一个LRU缓存，并每隔60秒刷新，最大存储512个对象，而却返回的对象是只读的

参数含义：

- flushInterval       刷新间隔，可以被设置为任意的正整数，代表一个合理的毫秒形式的时间段。默认情况是不设置，即没有刷新间隔，缓存仅仅调用语句时刷新
- size     引用数目缓存的对象数目和运行环境的可用内存资源数目，默认值1024
- readOnly    只读 ，只读的缓存会给所有调用者返回缓存对象的相同实例。
- evivtion    回收策略，默认为LRU.常用的策略有：
  - LRU   - 最近最少使用的： 移除最长时间不被使用的对象
  - FIFO   - 先进先出：按对象进入缓存的顺序来移除它们
  - SOFT  - 软引用：移除基于垃圾回收器状态和软引用规则的对象
  - WEAK  - 弱引用：更积极地移除基于垃圾收集器状态和弱引用规则的对象

**流程：**

1. 当一个sqlseesion执行了一次select后，在关闭此session的时候，会将查询结果缓存到二级缓存
2. 当另一个sqlsession执行select时，首先会在他自己的一级缓存中找，如果没找到，就回去二级缓存中找，找到了就返回，就不用去数据库了，从而减少了数据库压力提高了性能　

**注意：**

1. 如果SqlSession执行了DML操作（insert、update、delete），并commit了，那么mybatis就会清空当前mapper缓存中的所有缓存数据，这样可以保证缓存中的存的数据永远和数据库中一致，避免出现脏读
2. mybatis的缓存是基于[namespace:sql语句:参数]来进行缓存的，意思就是，SqlSession的HashMap存储缓存数据时，是使用[namespace:sql:参数]作为key，查询返回的语句作为value保存的。

> 使用二级缓存时，与查询结果映射的java对象必须实现java.io.Serializable接口的序列化和反序列化操作，如果存在父类，其成员都需要实现序列化接口，实现序列化接口是为了对缓存数据进行序列化和反序列化操作，因为二级缓存数据存储介质多种多样，不一定在内存，有可能是硬盘或者远程服务器。

> 一级、二级缓存的不同之处在于，SqlSession对象一旦关闭，则SqlSession中的数据将不存在，即一级缓存就不复存在。而二级缓存的生命周期与整个应用同步，与SqlSession是否关闭无关。换句话说，一级缓存是在同一个线程(同一SqlSession)间共享数据，而二级缓存是在不同线程(不同的SqlSession)间共享数据。

#### hiberante的缓存

Hibernate中提供了两级缓存，一级缓存是Session级别的缓存，它属于事务范围的缓存，该级缓存由hibernate管理，应用程序无需干预；二级缓存是SessionFactory级别的缓存，该级缓存可以进行配置和更改，并且可以动态加载和卸载，hibernate还为查询结果提供了一个查询缓存，它依赖于二级缓存

#### 缓存概念

缓存是位于应用程序和永久性数据存储源之间用于临时存放复制数据的内存区域，缓存可以降低应用程序之间读写永久性数据存储源的次数，从而提高应用程序的运行性能。

参考[计算机缓存结构](https://blog.csdn.net/hujutaoseu/article/details/56842762)

缓存范围决定了缓存的生命周期，缓存范围分为3类：

1. 事务范围：

   缓存只能被当前事务访问，缓存的生命周期依赖于事务的生命周期，事务结束时，缓存的生命周期也结束了；

2. 进程范围：

   缓存被进程内的所有事务共享，这些事务会并发访问缓存，需要对缓存采用必要的事务隔离机制，缓存的生命周期取决与进程的生命周期，进程结束，缓存的生命周期也结束了；

3. 集群范围：

   缓存被一个或多个计算机的进程共享，缓存中的数据被复制到集群中的每个进行节点，进程间通过远程通信来保证缓存中数据的一致性；

   在查询时，如果在事务范围内的缓存中没有找到，可以到进程范围或集群范围的缓存中查找，如果还没找到，则到数据库中查询；

### mybatis面试题

#### ？ 什么是Mybatis的接口绑定，有什么好处

Mybatis实现了DAO接口与xml映射文件的绑定，自动为我们生成接口的具体实现，使用起来变得更加省事和方便。

#### ？ 什么情况用注解，什么情况用xml绑定

注解使用情况：Sql语句简单时

xml绑定使用情况：xml绑定 (@RequestMap用来绑定xml文件)

#### ？ Mybatis在核心处理类叫什么

SqlSession

#### ？ 查询表名和返回实体Bean对象不一致，如何处理

映射键值对即可

```
<result column="title" property="title" javaType="java.lang.String"/>
```

column：数据库中表的列名

property：实体Bean中的属性名

#### ? mybatis优点

- 把Sql语句从Java中独立出来。
- 封装了底层的JDBC，API的调用，并且能够将结果集自动转换成JavaBean对象，简化了Java数据库编程的重复工作。
- 自己编写Sql语句，更加的灵活。
- 入参无需用对象封装（或者map封装）,使用@Param注解

#### ? mybatis配置一对多和一对一

**一对多**

```
<collection property="topicComment" column="id" ofType="com.tmf.bbs.pojo.Comment" select="selectComment" />
```

property：属性名       column：共同列       ofType：集合中元素的类型   select：要连接的查询

**一对一**

```
<association property="topicType" select="selectType" column="topics_type_id" javaType="com.tmf.bbs.pojo.Type"/>
```

property：属性名   select：要连接的查询   column：共同列      javaType：集合中元素的类型

#### ? ${} 和 #{}的区别

```
${}：简单字符串替换，把${}直接替换成变量的值，不做任何转换，这种是取值以后再去编译SQL语句。
#{}：预编译处理，sql中的#{}替换成？，补全预编译语句，有效的防止Sql语句注入，这种取值是编译好SQL语句再取值。
总结：一般用#{}来进行列的代替
```

#### ？ mybatis如何防止SQL注入

【底层实现原理】MyBatis是如何做到SQL预编译的呢？其实在框架底层，是JDBC中的PreparedStatement类在起作用，PreparedStatement是我们很熟悉的Statement的子类，它的对象包含了编译好的SQL语句。这种“准备好”的方式不仅能提高安全性，而且在多次执行同一个SQL时，能够提高效率。原因是SQL已编译好，再次执行时无需再编译。

\#{}：相当于JDBC中的PreparedStatement

${}：是输出变量的值

简单说，**#**{}是经过**预编译的**，是**安全的**；**$**{}是未经过预编译的，仅仅是取变量的值，是非安全的，存在SQL注入。



#### ? 获取上一次自动生成的主键值

select last _insert_id()

#### ? Mybatis如何分页，分页原理

RowBounds对象分页

在Sql内直接书写，带有物理分页

#### ？ mybatis的注解

MyBatis的注解方式就是将SQL语句直接写在接口上。这种方式的优点是，对于需求比较简单的系统，效率较高。缺点是，当SQL有变化时需要重新编译代码，一般情况下不建议使用注解方式。

#### ?  mybatis的优缺点

**优点**

1. 简单易学：mybatis本身就很小且简单。没有任何第三方依赖，最简单安装只要两个jar文件+配置几个sql映射文件易于学习，易于使用，通过文档和源代码，可以比较完全的掌握它的设计思路和实现。
2. 灵活： mybatis不会对应用程序或者数据库的现有设计强加任何影响。 sql写在xml里，便于统一管理和优化。通过sql基本上可以实现我们不使用数据访问框架可以实现的所有功能，或许更多。
3. 解除sql与程序代码的耦合 ：  通过提供DAL层，将业务逻辑和数据访问逻辑分离，使系统的设计更清晰，更易维护，更易单元测试。sql和代码的分离，提高了可维护性。
4. 提供映射标签，支持对象与数据库的orm字段关系映射
5. 提供对象关系映射标签，支持对象关系组建维护
6. 提供xml标签，支持编写动态sql。

**缺点**

1. 编写SQL语句时工作量很大，尤其是字段多、关联表多时，更是如此。
2. SQL语句依赖于数据库，导致数据库移植性差，不能更换数据库。
3. 框架还是比较简陋，功能尚有缺失，虽然简化了数据绑定代码，但是整个底层数据库查询实际还是要自己写的，工作量也比较大，而且不太容易适应快速数据库修改。
4. 二级缓存机制不佳

#### ? mybatis中应用的设计模式

##### Builder模式

1. SqlSessionFactory的创建

   对于创建SqlSessionFactory时，会根据情况提供不同的参数，由于构造时参数不定，可以为其创建一个构造器Builder，将SqlSessionFactory的构建过程和表示分开。MyBatis将SqlSessionFactoryBuilder和SqlSessionFactory相互独立。

2. 数据库连接环境Environment对象的创建

#### ？mybatis获取sql connection

确保在web.xml中使用listener配置spring，否则无法使用ContextLoader.getCurrentWebApplicationContext()得到WebApplicationContext。

```
<context-param>
  <param-name>contextConfigLocation</param-name>
  <param-value>classpath:applicationContext.xml</param-value>
</context-param>
<listener>
    <listener-class>org.springframework.web.context.ContextLoaderListener</listener-class>
</listener>
```

在applicationContext.xml中配置数据库连接所需的bean

```
<bean id="DatabaseSource" class="org.apache.commons.dbcp.BasicDataSource">
        <property name="driverClassName" value="com.mysql.jdbc.Driver" />
        <property name="url" value="jdbc:mysql://localhost:3306/test" />
        <property name="username" value="root" />
        <property name="password" value="111111" />
        <property name="initialSize" value="2" />
        <property name="minIdle" value="2" />
        <property name="maxActive" value="20" />
        <property name="maxIdle" value="20" />
    </bean>
 
    <bean class="org.mybatis.spring.mapper.MapperScannerConfigurer">
        <property name="basePackage" value="com.my.test" />
    </bean>
 
    <!--关键通过bean的名字得到SqlSessionFactory-->
    <bean id="SqlSessionFactory" class="org.mybatis.spring.SqlSessionFactoryBean">
        <property name="dataSource" ref="DatabaseSource" />
        <property name="configLocation" value="classpath:sqlmap-config.xml" />
    </bean>
```

编写代码得到Connection

```
WebApplicationContext webApplicationContext =ContextLoader.getCurrentWebApplicationContext();
SqlSessionFactory sqlSessionFactory = (SqlSessionFactory )webApplicationContext.getBean("SqlSessionFactory");
SqlSession sqlSession = sqlSessionFactory.openSession();
Connection conn = sqlSession.getConnection();
```

或者

```
BasicDataSource basicDataSource=(BasicDataSource)ContextLoader.getCurrentWebApplicationContext().getBean("DatabaseSource");
try {
  Connection connection=basicDataSource.getConnection();
}catch(SQLException e){  
}
```



## 缓存

### 缓存穿透、缓存并发、缓存失效、缓存雪崩

**缓存穿透**

缓存穿透指的是使用不存在的key进行大量的高并发查询，这导致缓存无法命中，每次请求都要穿透到后端数据库系统进行查询，使数据库压力过大，甚至使数据库服务被压死。

​:arrow_forward: 我们通常将空值缓存起来，再次接收到同样的查询请求时，若命中缓存并且值为空，就会直接返回，不会透传到数据库，避免缓存穿透。

(如果一个查询返回的数据为空（不管是数 据不存在，还是系统故障），我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。)

:arrow_forward:采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被 这个bitmap拦截掉，从而避免了对底层存储系统的查询压力。

**缓存并发**

缓存并发的问题通常发生在高并发的场景下，当一个缓存key过期时，因为访问这个缓存key 的请求量较大，多个请求同时发现缓存过期，因此多个请求会同时访问数据库来查询最新数据，并且回写缓存，这样会造成应用和数据库的负载增加，性能降低，由于并发较高，甚至会导致数据库被压死。

​:arrow_forward: **分布式锁** 使用分布式锁，保证对于每个key同时只有一个线程去查询后端服务，其他线程没有获得分布式锁的权限，因此只需要等待即可。这种方式将高并发的压力转移到了分布式锁，因此对分布式锁的考验很大。这种情况和刚才说的预先设定值问题有些类似，只不过利用锁的方式，会造成部分请求等待。

:arrow_forward:**本地锁** 与分布式锁类似，我们通过本地锁的方式来限制只有一个线程去数据库中查询数据，而其他线程只需等待，等前面的线程查询到数据后再访问缓存。但是，这种方法只能限制一个服务节点只有一个线程去数据库中查询，如果一个服务有多个节点，则还会有多个数据库查询操作，也就是说在节点数量较多的情况下并没有完全解决缓存并发的问题。

:arrow_forward:**软过期** 软过期指对缓存中的数据设置失效时间，就是不使用缓存服务提供的过期时间，而是业务层在数据中存储过期时间信息，由业务程序判断是否过期并更新，在发现了数据即将过期时，将缓存的时效延长，程序可以派遣一个线程去数据库中获取最新的数据，其他线程这时看到延长了的过期时间，就会继续使用旧数据，等派遣的线程获取最新数据后再更新缓存。

*也可以通过异步更新服务来更新设置软过期的缓存，这样应用层就不用关心缓存并发的问题了。*

**缓存失效**

引起这个问题的主要原因还是高并发的时候，平时我们设定一个缓存的过期时间时，可能有一些会设置1分钟啊，5分钟这些，并发很高时可能会出在某一个时间同时生成了很多的缓存，并且过期时间都一样，这个时候就可能引发一当过期时间到后，这些缓存同时失效，请求全部转发到DB，DB可能会压力过重。

​:arrow_forward: 将缓存失效时间分散开，比如我们可以在原有的失效时间基础上增加一个随机值，比如1-5分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。 

:arrow_forward:分析用户行为，尽量让失效时间点均匀分布

**缓存雪崩**

缓存雪崩指缓存服务器重启或者大量缓存集中在某一个时间段内失效，给后端数据库造成瞬时的负载升高的压力，甚至压垮数据库的情况。

当发生大量的缓存穿透，例如对某个失效的缓存的大并发访问就造成了缓存雪崩。

​:arrow_forward: 对不同的数据使用不同的失效时间，甚至对相同的数据、不同的请求使用不同的失效时间.

:arrow_forward:考虑用加锁或者队列的方式保证来保证不会有大量的线程对数据库一次性进行读写，避免缓存失效时对数据库造成太大的压力，虽然能够在一定的程度上缓解了数据库的压力但是与此同时又降低了系统的吞吐量。

:arrow_forward:如果是因为某台缓存服务器宕机，可以考虑做主备

**缓存预热**

存预热就是系统上线后，将相关的缓存数据直接加载到缓存系统。这样就可以避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题！用户直接查询事先被预热的缓存数据！

实现思路：

1. 直接写个缓存刷新页面，上线时手工操作下；
2. 数据量不大，可以在项目启动的时候自动进行加载；
3. 定时刷新缓存。

**缓存更新**

 除了缓存服务器自带的缓存失效策略之外（Redis默认的有6中策略可供选择），我们还可以根据具体的业务需求进行自定义的缓存淘汰，常见的策略有两种：

- 定时去清理过期的缓存；
- 当有用户请求过来时，再判断这个请求所用到的缓存是否过期，过期的话就去底层系统得到新数据并更新缓存。

> 第一种的缺点是维护大量缓存的key是比较麻烦的，第二种的缺点就是每次用户请求过来都要判断缓存失效，逻辑相对比较复杂！

**缓存降级**

 当访问量剧增、服务出现问题（如响应时间慢或不响应）或非核心服务影响到核心流程的性能时，仍然需要保证服务还是可用的，即使是有损服务。系统可以根据一些关键数据进行自动降级，也可以配置开关实现人工降级。

降级的最终目的是保证核心服务可用，即使是有损的。而且有些服务是无法降级的。

​:bang:  在进行降级之前要对系统进行梳理，看看系统是不是可以丢卒保帅；从而梳理出哪些必须誓死保护，哪些可降级；比如可以参考日志级别设置预案：

- 一般：比如有些服务偶尔因为网络抖动或者服务正在上线而超时，可以自动降级；
- 警告：有些服务在一段时间内成功率有波动（如在95~100%之间），可以自动降级或人工降级，并发送告警；
- 错误：比如可用率低于90%，或者数据库连接池被打爆了，或者访问量突然猛增到系统能承受的最大阀值，此时可以根据情况自动降级或者人工降级；
- 严重错误：比如因为特殊原因数据错误了，此时需要紧急人工降级。

### 缓存算法

- FIFO算法：First in First out，先进先出。原则：一个数据最先进入缓存中，则应该最早淘汰掉。也就是说，当缓存满的时候，应当把最先进入缓存的数据给淘汰掉。
- LFU算法：Least Frequently Used，最不经常使用算法。
- LRU算法：Least Recently Used，近期最少使用算法。

> LRU和LFU的区别。LFU算法是根据在一段时间里数据项被使用的次数选择出最少使用的数据项，即根据使用次数的差异来决定。而LRU是根据使用时间的差异来决定的

### 缓存热点key问题

**问题**  我们通常使用 缓存 + 过期时间的策略来帮助我们加速接口的访问速度，减少了后端负载，同时保证功能的更新。但有两个问题如果同时出现，可能就会对系统造成致命的危害：

- 这个key是一个热点key
- 缓存的构建是需要一定时间的。

会有一个致命问题：在缓存失效的瞬间，有大量线程来构建缓存，造成后端负载加大，甚至可能会让系统崩溃 。

解决方案：

1. 使用互斥锁(mutex key)

   种解决方案思路比较简单，就是只让一个线程构建缓存，其他线程等待构建缓存的线程执行完，重新从缓存获取数据就可以了. 如果是单机，可以用synchronized或者lock来处理，如果是分布式环境可以用分布式锁就可以了（分布式锁，可以用memcache的add, redis的setnx, zookeeper的添加节点操作）。

   redis代码示例：

   ```
   public String get(key) {  
         String value = redis.get(key);  
         if (value == null) { //代表缓存值过期  
             //设置3min的超时，防止del操作失败的时候，下次缓存过期一直不能load db  
             if (redis.setnx(key_mutex, 1, 3 * 60) == 1) {  //代表设置成功  
                  value = db.get(key);  
                         redis.set(key, value, expire_secs);  
                         redis.del(key_mutex);  
                 } else {  //这个时候代表同时候的其他线程已经load db并回设到缓存了，这时候重试获取缓存值即可  
                         sleep(50);  
                         get(key);  //重试  
                 }  
             } else {  
                 return value;        
             }  
    }  
   ```

2.  "提前"使用互斥锁(mutex key)

   在value内部设置1个超时值(timeout1), timeout1比实际的memcache timeout(timeout2)小。当从cache读取到timeout1发现它已经过期时候，马上延长timeout1并重新设置到cache。然后再从数据库加载数据并设置到cache中。伪代码如下：

   ```
   v = memcache.get(key);    
   if (v == null) {    
       if (memcache.add(key_mutex, 3 * 60 * 1000) == true) {    
           value = db.get(key);    
           memcache.set(key, value);    
           memcache.delete(key_mutex);    
       } else {    
           sleep(50);    
           retry();    
       }    
   } else {    
       if (v.timeout <= now()) {    
           if (memcache.add(key_mutex, 3 * 60 * 1000) == true) {    
               // extend the timeout for other threads    
               v.timeout += 3 * 60 * 1000;    
               memcache.set(key, v, KEY_TIMEOUT * 2);    
               // load the latest value from db    
               v = db.get(key);    
               v.timeout = KEY_TIMEOUT;    
               memcache.set(key, value, KEY_TIMEOUT * 2);    
               memcache.delete(key_mutex);    
           } else {    
               sleep(50);    
               retry();    
           }    
       }    
   }
   ```

3. 永远不过期

   - 从redis上看，确实没有设置过期时间，这就保证了，不会出现热点key过期问题，也就是“物理”不过期。
   - 从功能上看，如果不过期，那不就成静态的了吗？所以我们把过期时间存在key对应的value里，如果发现要过期了，通过一个后台的异步线程进行缓存的构建，也就是“逻辑”过期

> 从实战看，这种方法对于性能非常友好，唯一不足的就是构建缓存时候，其余线程(非构建缓存的线程)可能访问的是老数据，但是对于一般的互联网功能来说这个还是可以忍受。

```
String get(final String key) {    
        V v = redis.get(key);    
        String value = v.getValue();    
        long timeout = v.getTimeout();    
        if (v.timeout <= System.currentTimeMillis()) {    
            // 异步更新后台异常执行    
            threadPool.execute(new Runnable() {    
                public void run() {    
                    String keyMutex = "mutex:" + key;    
                    if (redis.setnx(keyMutex, "1")) {    
                        // 3 min timeout to avoid mutex holder crash    
                        redis.expire(keyMutex, 3 * 60);    
                        String dbValue = db.get(key);    
                        redis.set(key, dbValue);    
                        redis.delete(keyMutex);    
                    }    
                }    
            });    
        }    
        return value;    
}  
```

4. 资源保护

   采用netflix的hystrix，可以做资源的隔离保护主线程池，如果把这个应用到缓存的构建也未尝不可。

四中方式对比：

| 解决方案                | 优点                                       | 缺点                                       |
| ------------------- | ---------------------------------------- | ---------------------------------------- |
| 简单分布式互斥锁（mutex key） | 1.思路简单                        2.保证一直性    | 1.代码复杂度增大                                                                                                                                                     2.存在死锁的风险                                                                                                                                                                          3.  存在线程池阻塞 |
| “提前”使用互斥锁           | 保证一致性                                    | 同上                                       |
| 不过期                 | 异步构建缓存，不会阻塞线程池                           | 1.不保证一致性                                                                                                                                                           2.代码复杂度增大（每个value都要维护一个timekey）                                                                                                3.占用一定的内存空间（每个value都要维护一个timekey） |
| 资源隔离组件hystrix       | 1.hystrix技术成熟，有效保证后端                     2.hystrix监控强大 | 部分访问存在降级策略                               |

## Redis

### redis的使用场景

redis最常用的物种数据格式：   1.String   2.Hash   3.List   4.Set   5.Sorted set  

1. String 

   | 常用命令          | 应用场景                                   |
   | ------------- | -------------------------------------- |
   | set、get       | 最简单的数据缓存                               |
   | mset、mget     | 批量操作，把数据统一传回客户端，节省网络io时间               |
   | decr、incr     | 计数器                                    |
   | append        | 可以作为时间序列，配合getrange、setrange,对字符串进行操作， |
   | setbit、getbit | 可以作为简单的布尔过滤器来判断用户是否执行过某些操作             |

2. List

   | 常用命令        | 应用场景        |
   | ----------- | ----------- |
   | lpush、lpop  | 队列操作，实现队列任务 |
   | lpush、ltrim | 显示最新的数据     |

3. Hash

   | 常用命令                | 应用场景                                     |
   | ------------------- | ---------------------------------------- |
   | hget、hset           | 实现一个key对应一个数据集集合，数据集集合里包含多个单独的key/value，操作依然是原子性的 |
   | hmget、hmset、hgetall | 批量操作，节省网络io时间                            |
   | hincrby             | 对哈希里域值，进行原子性加1                           |

4. Set

   | 常用命令                | 应用场景            |
   | ------------------- | --------------- |
   | sadd                | 存储一个不重复的数据      |
   | sunion、sdiff、sinter | 进行集合处理，并集、交集、差集 |

5. Sorted Set

   | 常用命令                 | 应用场景                      |
   | -------------------- | ------------------------- |
   | zadd                 | 存储一个按照score排序的数据集合，添加自动排序 |
   | zrange、zrangebyscore | 按照score顺序获取数据集            |
   | zrank                | 排行榜功能                     |

常见使用场景：

- 会话缓存（Session cache） redis提供持久化。

- 热数据缓存

- 全页缓存(FPC)   极大的提高网页的响应速率

- 队列   相当于消息系统，ActiveMQ，RocketMQ等工具类似；队列不仅可以把并发请求变成串行，并且还可以做队列或者栈使用

- 排行榜/计数器   Redis在内存中对数字进行递增或递减的操作实现的非常好。集合（Set）和有序集合（Sorted Set）也使得我们在执行这些操作的时候变的非常简单；诸如统计点击数等应用。由于单线程，可以避免并发问题，保证不会出错，而且100%毫秒级性能！

- 发布/订阅功能

- 位操作   用于数据量上亿的场景下。

  redis内构建一个足够长的数组，每个数组元素只能是0和1两个值，然后这个数组的下标index用来表示我们上面例子里面的用户id（必须是数字哈），那么很显然，这个几亿长的大数组就能通过下标和元素值（0和1）来构建一个记忆系统

- 分布式锁与单线程机制

  - 验证前端的重复请求，可以通过redis进行过滤：每次请求将request ip、参数、接口等hash作为key存储redis(幂等性请求)。设置多长时间有效期，然后下次请求过来的时候先在redis中检索有没有这个key，进而验证是不是一定时间内过来的重复请求
  - 秒杀系统，基于redis是单线程特征，防止出现数据库爆破
  - 全局增量ID 生成


## Error与Exception

Error类和Exception类的父类都是throwable类。

- Error类一般是指与虚拟机相关的问题，如系统崩溃，虚拟机错误，内存空间不足，方法调用栈溢等。对于这类错误的导致的应用程序中断，仅靠程序本身无法恢复和和预防，遇到这样的错误，建议让程序终止。
- Exception类表示程序可以处理的异常，可以捕获且可能恢复。遇到这类异常，应该尽可能处理异常，使程序恢复运行，而不应该随意终止异常。

#### CheckedException与RuntimeEception的区别

- 运行时异常（Runtime Exception）

  > 运行时异常;ArithmaticException,IllegalArgumentException，编译能通过，但是一运行就终止了，程序不会处理运行时异常，出现这类异常，程序会终止。

- 受检查的异常(Checked Exception )

  > 受检查的异常，要么用try。。。catch捕获，要么用throws字句声明抛出，交给它的父类处理，否则编译不会通过。

## 反射

#### 反射概念

反射就是动态加载对象，并对对象进行剖析。在运行状态中，对于任意一个类，都能够知道这个类的所有属性和方法；对于任意一个对象，都能够调用它的任意一个方法，这种动态获取信息以及动态调用对象方法的功能称为Java反射机制。

**动态加载类**

1. 编译时加载类是静态加载类

   new 创建对象是静态加载类，在编译时刻就需要加载所有可用使用到的类，如果有一个用不了，那么整个文件都无法通过编译

2. 运行时加载类是动态加载类 

   Class c =  Class.forName("类的全名")，不仅表示了类的类型，还表示了动态加载类，编译不会报错，在运行时才会加载，使用接口标准能更方便动态加载类的实现。功能性的类尽量使用动态加载，而不用静态加载。

> 反射的操作都是编译之后的操作,编译之后集合的泛型是去泛型化的。
>
> 泛型用在编译期，编译过后泛型擦除（消失掉）。所以是可以通过反射越过泛型检查的

反射其实是获取类的字节码文件，也就是.class文件，那么我们就可以通过Class这个对象进行获取。有三种方式可以获取：

1. 实例获取，getClass()是Object的一个方法，Class继承了Object

   ```
          Test02 t = new Test02();// 创建一个对象
          Class c = t.getClass();// 获取该对象的Class对象
          System.out.println(c.getName()); // com.ms.Test02  // 获取类名称
   ```

2. 通过类名直接获取

   ```
   	   Class c = Test02.class;      
          System.out.println(c.getName()); // com.ms.Test02    // 获取类名称
   ```

3. 通过类的全路径名获取Class对象会抛出一个异常，如果根据类路径找不到这个类那么就会抛出这个异常。

   ```
   try {
              Class c = Class.forName("com.ms.Test02");// 根据类的全路径名获取
              System.out.println(c.getName()); // com.ms.Test02   // 获取类名称
       } catch (ClassNotFoundException e) {
              e.printStackTrace();
       }
   ```

##### 通过反射获取类的构造方法、方法以及属性

**构造方法** 

```
       Class c = Class.forName("com.reflect.User");  // 加载Class对象

       // 获取所有公用的构造方法
       Constructor[] constructors = c.getConstructors();
       for (Constructor constructor : constructors) {
           System.out.println(constructor);
       }

       // 获取所有的构造方法
       Constructor[] declaredConstructors = c.getDeclaredConstructors();
       for (Constructor declaredConstructor : declaredConstructors) {
           System.out.println(declaredConstructor);
       }

       //获取公有 & 无参的构造方法
       Constructor constructor = c.getConstructor(null);
       System.out.println(constructor);

       //获取公有 & 有参的构造方法
       Constructor constructor1 = c.getConstructor(new Class[]{String.class, Integer.class, String.class});
       System.out.println(constructor1);

       //获取私有 & 有参 构造方法
       Constructor declaredConstructor1 = c.getDeclaredConstructor(new Class[]{String.class});
       System.out.println(declaredConstructor1);
```

**类属性**

```
       Class<?> clazz = Class.forName("com.reflect.User");// 获取Class对象

       //获取所有的公共字段
       Field[] fields = clazz.getFields();
       for (Field field : fields) {
           System.out.println(field);
       }

       //获取所有的字段(公开的、私有的
       Field[] declaredFields = clazz.getDeclaredFields();
       for (Field declaredField : declaredFields) {
           System.out.println(declaredField);
       }

       //获取公有字段并使用
       // 获取指定公有字段
       Field field = clazz.getField("name");
       // 获取一个公有构造方法，然后实例化
       Object obj = clazz.getConstructor().newInstance();
       // 为属性设置值
       field.set(obj, "张三");
       // 测试，看设置的值是否成功
       User user = (User) obj;
       System.out.println(user.getName());

       //获取私有字段并使用
       Field field1 = clazz.getDeclaredField("sex");
       // 获取构造函数，实例化对象
       Object obj1 = clazz.getConstructor().newInstance();
       // 暴力反射
       field1.setAccessible(true);
       // 给属性设置值
       field1.set(obj1, "男");
       // 测试
       User u = (User) obj1;
       System.out.println(u.getSex());
```

**类中的方法**

```
       Class<?> clazz = Class.forName("com.reflect.User");// 获取Class对象

       //获取所有的public修饰的方法
       Method[] methods = clazz.getMethods();
       for (Method method : methods) {
           System.out.println(method);
       }
       Thread.sleep(1000);

       //获取所有的方法
       Method[] declaredMethods = clazz.getDeclaredMethods();
       for (Method declaredMethod : declaredMethods) {
           System.out.println(declaredMethod);
       }
       Thread.sleep(1000);

       //获取特定方法(带参)并使用
       Method method1 = clazz.getMethod("method1", String.class);
       System.out.println(method1);
       Thread.sleep(1000);

       //获取特定方法(不带参)并使用
       Method method2 = clazz.getDeclaredMethod("method2");
       System.out.println(method2);

       //获取特定方法(多个参数)并使用
       Method method3 = clazz.getDeclaredMethod("method3", String.class, Integer.class, String.class);
       // 获取构造方法，实例化一个对象
       Object obj = clazz.getConstructor().newInstance();
       // 给方法传值
       Object invoke = method3.invoke(obj, "小涛", 24, "男");
       // 测试
       System.out.println(invoke);
```

**调用main方法**

```
 try {           
           Class<?> clazz = Class.forName("com.reflect.Main");// 获取Class对象           
           Method method = clazz.getMethod("main", java.lang.String[].class);// 获取Main方法
           // 调用
           method.invoke(null, (Object) new String[]{"a"});
       } catch (Exception e) {
           e.printStackTrace();
       }
```

#### 反射的优缺点

**优点**

- 能够运行时动态获取类的实例，大大提高系统的灵活性和扩展性。 
- 与Java动态编译相结合，可以实现无比强大的功能 

**缺点**

- 使用反射的性能较低 
- 使用反射相对来说不安全 
- 破坏了类的封装性，可以通过反射获取这个类的私有方法和属性

使用反射操作会模糊化程序的内部逻辑，从代码的维护角度来讲，我们更希望在源码中看到程序的逻辑，反射相当于绕过了源码的方式,因此会带来维护难度比较大的问题。

#### 反射的使用场景

- 实现RPC框架
- 实现ORM框架
- 拷贝属性值（BeanUtils.copyProperties）
- 动态代理

#### Class.forName和ClassLoader区别

java中class.forName()和classLoader都可用来对类进行加载。

- class.forName()前者除了将类的.class文件加载到jvm中之外，还会对类进行解释，执行类中的static块。
- classLoader只干一件事情，就是将.class文件加载到jvm中，不会执行static中的内容,只有在newInstance才会去执行static块。

Class.forName(name, initialize, loader)带参函数也可控制是否加载static块。并且只有调用了newInstance()方法采用调用构造函数，创建类的对象。如果程序依赖于Class是否被初始化，就必须用Class.forName(name)了。

## JVM相关

#### Java类加载器

##### 类的加载

当程序要使用某个类时，如果该类还未被加载到内存中，则系统会通过加载，连接，初始化三步来实现对这个类进行初始化：

- 加载：就是指将class文件读入内存，并为之创建一个Class对象，任何类被使用时系统都会建立一个Class对象
- 链接： 把二进制数据组装为可以运行的状态,分为校验，准备，解析这3个阶段:
  - 验证：确保被加载类的正确性(确认此二进制文件是否适合当前的JVM（版本）)
  - 准备：负责为类的静态成员分配内存，并设置默认初始化值
  - 解析：将类中的符号引用替换为直接引用(转换常量池中的代码作为直接引用的过程，直到所有的符号引用都可以被运行程序使用（建立完整的对应关系）)
- 初始化：
  - 局部变量保存在栈区：必须手动初始化
  - new 的对象保存在堆区：虚拟机会进行默认初始化，基本数据类型初始化值为0，引用类型初始化值为null

当没有任何引用指向Class对象时就会被卸载，结束类的生命周期

##### 类加载的时机（只加载一次）

1. 创建类的实例的时候
2. 访问类的静态变量的时候
3. 调用类的静态方法的时候
4. 使用反射方式来强制创建某个类或接口对应的java.lang.Class对象
5. 初始化某个类的子类的时候
6. 直接使用java.exe命令来运行某个主类

##### 类加载器

负责将.class文件加载到内存中，并为之生成对应的Class对象

##### 类加载器的组成

- Bootstrap ClassLoader 根类加载器

  也被称为引导类加载器，负责Java核心类的加载，比如System类，在JDK中JRE的lib目录下rt.jar文件中的类

- Extension ClassLoader 扩展类加载器

  负责JRE的扩展目录中jar包的加载，在JDK中JRE的lib目录下ext目录

- System ClassLoader 系统类加载器

  负责在JVM启动时加载来自java命令的class文件，以及classpath环境变量所指定的jar包和类路径，主要是我们开发者自己写的类

#### 什么情况下会发生栈内存溢出？

一般情况下有两种栈溢出情况：

- 如果线程请求分配的栈容量超过java虚拟机栈允许的最大容量的时候，java虚拟机将抛出一个StackOverFlowError异常。
- 如果java虚拟机栈可以动态拓展，并且扩展的动作已经尝试过，但是目前无法申请到足够的内存去完成拓展，或者在建立新线程的时候没有足够的内存去创建对应的虚拟机栈，那java虚拟机将会抛出一个OutOfMemoryError异常。

## 泛型

#### 泛型概念

泛型（Generic type 或者 generics）是对 Java 语言的类型系统的一种扩展，以支持创建可以按类型进行参数化的类。可以把类型参数看作是使用参数化类型时指定的类型的一个占位符，就像方法的形式参数是运行时传递的值的占位符一样。

*泛型还有一种较为准确的说法就是为了参数化类型，或者说可以将类型当作参数传递给一个类或者是方法。*

*泛型就是对参数类型的增强。允许一些自定义类型作为泛型的参数类型*

好处：

1. 类型安全。 泛型的主要目标是提高 Java 程序的类型安全。
2. 消除强制类型转换。
3. 潜在的性能收益。

泛型信息只存在于代码编译阶段，在进入 JVM 之前，与泛型相关的信息会被擦除掉，专业术语叫做**类型擦除。**

> 泛型类或者泛型方法中，不接受 8 种基本数据类型

## Java基础

#### 如何从一个static方法对非static方法进行调用

​:a:  不可以在一个static方法内部发出对非static方法的调用；static方法是静态方法，是属于类的方法，非static方法是属于对象的方法。

所以在static方法中想要调用非static方法，要先新创建一个对象，再有这个对象来调用非static方法。

#### java中如何跳出当前的多重嵌套循环

​:a: 要想跳出多重循环，可以在外面的循环语句前定义一个标号，然后在里层循环体的代码中使用带有标号的的break语句，即可跳出

```
ok:
for(int i = 0;i<10;i++){
  for(int j = 0;j<10;j++){
    if(j == 5) break ok;
  }
}
```

#### java中如何实现动态数组

​:a: 当想增加数组大小时，就另开一个新的数组，把旧的数组放入其中即可

System.arraycopy(src, 0, dest, 0, src.length);    //关键方法

## IO

#### BIO、NIO、AIO

> 同步和异步是针对应用程序和内核的交互而言的。 阻塞和非阻塞是针对于进程在访问数据的时候，根据IO操作的就绪状态来采取的不同方式，说白了是一种读取或者写入操作函数的实现方式，阻塞方式下读取或者写入函数将一直等待，而非阻塞方式下，读取或者写入函数会立即返回一个状态值。  

同步	指的是用户进程触发IO操作并等待或者轮询的去查看IO操作是否就绪

异步	异步是指用户进程触发IO操作以后便开始做自己的事情，而当IO操作已经完成的时候会得到IO完成的通知（异步的特点就是通知）

阻塞	所谓阻塞方式的意思是指, 当试图对该文件描述符进行读写时, 如果当时没有东西可读,或者暂时不可写, 程序就进入等待状态, 直到有东西可读或者可写为止

非阻塞	非阻塞状态下, 如果没有东西可读, 或者不可写, 读写函数马上返回, 而不会等待，

Java BIO : 同步并阻塞，服务器实现模式为一个连接一个线程，即客户端有连接请求时服务器端就需要启动一个线程进行处理，如果这个连接不做任何事情会造成不必要的线程开销，当然可以通过线程池机制改善。

Java NIO: 同步非阻塞，服务器实现模式为一个请求一个线程，即客户端发送的连接请求都会注册到多路复用器上，多路复用器轮询到连接有I/O请求时才启动一个线程进行处理。

Java AIO(NIO.2) : 异步非阻塞，服务器实现模式为一个有效请求一个线程，客户端的I/O请求都是由OS先完成了再通知服务器应用去启动线程进行处理，

[BIO、NIO、AIO参考](https://blog.csdn.net/anxpp/article/details/51512200) 

##### 适用场景

- BIO方式适用于连接数目比较小且固定的架构，这种方式对服务器资源要求比较高，并发局限于应用中，JDK1.4以前的唯一选择，但程序直观简单易理解。
- NIO方式适用于连接数目多且连接比较短（轻操作）的架构，比如聊天服务器，并发局限于应用中，编程比较复杂，JDK1.4开始支持。
- AIO方式使用于连接数目多且连接比较长（重操作）的架构，比如相册服务器，充分调用OS参与并发操作，编程比较复杂，JDK7开始支持。

*另外，I/O属于底层操作，需要操作系统支持，并发也需要操作系统的支持，所以性能方面不同操作系统差异会比较明显。*

### IO面试题

##### ？ java中有几种类型的流？

字符流和字节流。字节流继承inputStream和OutputStream,字符流继承自InputSteamReader和OutputStreamWriter。

##### ? Netty

Netty是一款异步的事件驱动的网络应用框架和工具，用于快速开发可维护的高性能、高扩展性协议服务器和客户端。也就是说，Netty是一个NIO客户端/服务器框架，支持快速、简单地开发网络应用，如协议服务器和客户端。它极大简化了网络编程，如TCP和UDP套接字服务器。

#### ？ 递归读取文件夹的文件名

```
public static void listFile(String path) {
        if (path == null) {
            return;// 因为下面的new File如果path为空，回报异常
        }
        File[] files = new File(path).listFiles();
        if (files == null) {
            return;
        }
        for(File file : files) {
            if (file.isFile()) {
                System.out.println(file.getName());
            } else if (file.isDirectory()) {
                System.out.println("Directory:"+file.getName());
                listFile(file.getPath());
            } else {
                System.out.println("Error");
            }
        }
    }
```

#### ?  **什么是比特(Bit),什么是字节(Byte),什么是字符(Char),它们长度是多少,各有什么区别**

Bit最小的二进制单位 ，是计算机的操作部分 取值0或者1
Byte是计算机操作数据的最小单位由8位bit组成 取值（-128-127）
Char是用户的可读写的最小单位，在java里面由16位bit组成 取值（0-65535）

Bit 是最小单位 计算机 只能认识 0或者1 

8个字节 是给计算机看的
字符 是看到的东西  一个字符=二个字节

#### ？**什么是节点流,什么是处理流,它们各有什么用处,处理流的创建有什么特征**

节点流 直接与数据源相连，用于输入或者输出，例如OutputStream
处理流：在节点流的基础上对之进行加工，进行一些功能的扩展 ，例如 OutputStreamWriter
处理流的构造器必须要 传入节点流的子类

#### ？ **把输出字节流转换成输出字符流**

使用 转换处理流OutputStreamWriter 可以将字符流转为字节流New OutputStreamWriter（new FileOutputStream（File file））;

[IO流的使用](https://blog.csdn.net/t0404/article/details/51893168)



## Java线程与并发

#### java线程

##### java中创建线程的三种方法以及区别

**Java使用Thread类代表线程，所有的线程对象都必须是Thread类或其子类的实例。**

###### **继承Thread类创建线程**

通过继承Thread类来创建并启动多线程的一般步骤如下：

1. 定义Thread类的子类，并重写该类的**run()**方法，该方法的方法体就是线程需要完成的任务，run()方法也称为线程执行体。
2. 创建Thread子类的实例，也就是创建了线程对象
3. 启动线程，即调用线程的**start()**方法

###### **实现Runnable接口创建线程**

通过实现Runnable接口创建并启动线程一般步骤如下：

1. 定义Runnable接口的实现类，一样要重写run()方法，这个run（）方法和Thread中的run()方法一样是线程的执行体
2. 创建Runnable实现类的实例，并用这个实例作为Thread的target来创建Thread对象，这个Thread对象才是真正的线程对象
3. 通过调用线程对象的start()方法来启动线程

###### **使用Callable和Future创建线程**

和Runnable接口不一样，Callable接口提供了一个call（）方法作为线程执行体，call()方法比run()方法功能要强大。

call()方法可以有返回值

call()方法可以声明抛出异常

> Java5提供了Future接口来代表Callable接口里call()方法的返回值，并且为Future接口提供了一个实现类FutureTask，这个实现类既实现了Future接口，还实现了Runnable接口，因此可以作为Thread类的target。在Future接口里定义了几个公共方法来控制它关联的Callable任务:
>
> - boolean cancel(boolean mayInterruptIfRunning)：视图取消该Future里面关联的Callable任务
> - V get()：返回Callable里call（）方法的返回值，调用这个方法会导致程序阻塞，必须等到子线程结束后才会得到返回值
> - V get(long timeout,TimeUnit unit)：返回Callable里call（）方法的返回值，最多阻塞timeout时间，经过指定时间没有返回抛出TimeoutException
> - boolean isDone()：若Callable任务完成，返回True
> - boolean isCancelled()：如果在Callable任务正常完成前被取消，返回True

创建并启动有返回值的线程的步骤如下：

1. 创建Callable接口的实现类，并实现call()方法，然后创建该实现类的实例（从java8开始可以直接使用Lambda表达式创建Callable对象）。
2. 使用FutureTask类来包装Callable对象，该FutureTask对象封装了Callable对象的call()方法的返回值
3. 使用FutureTask对象作为Thread对象的target创建并启动线程（因为FutureTask实现了Runnable接口）
4. 调用FutureTask对象的get()方法来获得子线程执行结束后的返回值

**三种创建线程方法对比**

实现Runnable和实现Callable接口的方式基本相同，不过是后者执行call()方法有返回值，后者线程执行体run()方法无返回值，因此可以把这两种方式归为一种这种方式与继承Thread类的方法之间的差别如下：

- 线程只是实现Runnable或实现Callable接口，还可以继承其他类。
- 这种方式下，多个线程可以共享一个target对象，非常适合多线程处理同一份资源的情形。
- 但是编程稍微复杂，如果需要访问当前线程，必须调用Thread.currentThread()方法。
- 继承Thread类的线程类不能再继承其他父类（Java单继承决定）。

注：一般推荐采用实现接口的方式来创建多线程

#### java线程池

在缓冲池中预先放置一定数量的线程对象以实现复用的机制就叫做线程池。

**线程池的优点：**

1. 线程是稀缺资源，使用线程池可以减少创建和销毁线程的次数，每个工作线程都可以重复使用。
2. 可以根据系统的承受能力，调整线程池中工作线程的数量，防止因为消耗过多内存导致服务器崩溃。

**工作流程**

1. 提交一个任务时，线程池会创建一个新的线程执行任务，直到当前线程数等于 corePoolSize。
2. 如果当前线程数为 corePoolSize，继续提交的任务被保存到任务队列中，等待被执行。
3. 如果任务队列满了，那就创建新的线程执行当前任务，直到线程池中的线程数达到 maxPoolSize，这时再有任务来，只能执行reject() 拒绝处理该任务。

ThreadPoolExecutor、AbstractExecutorService、ExecutorService 和 Executor 之间的关系:

- Executor是一个顶层接口，只声明了一个方法execute(Runnable)，用来执行任务。
- ExecutorService 接口继承了 Executor 接口，并额外声明了一些相关方法。
- 抽象类 AbstractExecutorService 实现了 ExecutorService 接口，并且实现了ExecutorService 中声明的方法。
- ThreadPoolExecutor 继承了 AbstractExecutorService。

ThreadPoolExecutor 类的核心方法有这么几个：

- execute() 方法继承自顶层接口 Executor，在 ThreadPoolExecutor 进行了具体的实现，通过这个方法可以向线程池提交一个任务，交由线程池去调度执行。
- submit() 方法是 ExecutorService 声明的方法，在 AbstractExecutorService 进行了具体实现，ThreadPoolExecutor 从 AbstractExecutorService 中直接继承过来，该方法也可以向线程池提交任务，与 execute() 方法不同之处在于它能够返回任务执行的结果。
- shutdown  尝试关闭线程池，首先会拒绝接收新的任务，其次会等待正在执行中的所有任务执行完（包括阻塞等待中的）
- shutdownNow  尝试关闭线程池，首先也会拒绝接收新的任务，对正在执行中的所有任务发出中断请求，同时抛弃队列中还在等待的任务。
- isShutdown   是否尝试关闭线程池，尝试过则返回 `true`否则返回 `false`
- isTerminated  线程池是否已经终止，用来判断 `shutdown`或 `shutdownNow`是否已经完全关闭了线程池
- awaitTermination   根据传入的时间延迟获取线程池关闭的状态，这里需要注意的是是阻塞等待
- invokeAll   批量给定任务，返回执行完的所有任务
- invokeAny  批量给定任务，返回一个已执行完的任务

ThreadPoolExecutor 类各种构造函数的参数含义如下：

1. corePoolSize：核心线程的数量
2. maximumPoolSize：线程池的最大线程数，表示在线程池中最多能创建多少个线程。

> corePoolSize 可以理解为就是线程池的大小，而 maximumPoolSize 是线程池在特定情况下的一种处理机制，当任务量突增的时候，会额外创建一些线程对象以满足调用需求，一旦任务量恢复正常，额外创建的线程对象随即释放，maximumPoolSize 就是线程池最大的容载量（核心线程数量+额外线程数量）。
>
> 可通过以下两个方法动态调整线程池容量：
>
> - setCorePoolSize()：设置核心线程数量。
> - setMaximumPoolSize()：设置线程池的最大线程数量。

3. keepAliveTime:  非核心线程的超时时长，当系统中非核心线程（额外创建的线程）闲置时间超过 keepAliveTime 之后，则会被回收。如果ThreadPoolExecutor 的 allowCoreThreadTimeOut 属性设置为 true，则该参数也表示核心线程的超时时长。
4. unit：keepAliveTime 参数的时间单位，取值范围 TimeUnit 类中的7种静态属性。
5. workQueue: 线程池中的任务队列，该队列主要用来存储已经被提交但是尚未执行的任务。存储在这里的任务是由 ThreadPoolExecutor 的 execute() 方法提交来的，常用的任务队列有以下几种选择：
   - ArrayBlockingQueue：基于数组的先进先出队列，此队列创建时必须指定大小。
   - LinkedBlockingQueue：基于链表的先进先出队列，如果创建时没有指定此队列大小，则默认为Integer.MAX_VALUE。
   - synchronousQueue：这个队列比较特殊，它不会保存提交的任务，而是将直接新建一个线程来执行新来的任务。
   - PriorityBlockingQuene：具有优先级的无界阻塞队列。
6. threadFactory：为线程池提供创建新线程的功能。
7. handler：拒绝策略，当线程无法执行新任务时（一般是由于线程池中的线程数量已经达到最大数或者线程池关闭导致的），默认情况下，当线程池无法处理新线程时，会抛出一个RejectedExecutionException，常用的拒绝策略有以下四种：
   - ThreadPoolExecutor.AbortPolicy:丢弃任务并抛出 RejectedExecutionException 异常。 
   - ThreadPoolExecutor.DiscardPolicy：丢弃任务不抛出异常。 
   - ThreadPoolExecutor.DiscardOldestPolicy：丢弃队列首位的任务，然后重新尝试执行任务。
   - ThreadPoolExecutor.CallerRunsPolicy：由调用线程处理该任务。

##### 线程池的状态

- **RUNNING**：运行状态，线程池可以接收新任务，并处理队列中的任务。
- **SHUTDOWN**： 关闭状态，线程池不接收新任务，但是会处理队列中的任务。
- **STOP** ： 停止状态，线程池中断所有正在运行的任务，不接收新任务，同时也不处理队列中的任务。
- **TIDYING** ： 整理状态，线程池对线程资源进行整理优化。
- **TERMINATED**：结束状态，线程池停止工作。

##### 常见的四种线程池

**newFixedThreadPool()**

创建一个固定大小的线程池，任务超过10个时，会将线程放入等待队列中。初始化一个指定线程数的线程池，其中 corePoolSize == maxiPoolSize，使用 LinkedBlockingQuene 作为任务队列。

特点：即使当线程池没有可执行任务时，也不会释放线程。

**newCachedThreadPool()**

创建一个缓存线程池，初始化一个可以缓存线程的线程池，默认缓存60s，线程池的线程数可达到 Integer.MAX_VALUE，即2147483647，内部使用 SynchronousQueue 作为任务队列。

特点：在没有任务执行时，当线程的空闲时间超过 keepAliveTime，会自动释放线程资源。当提交新任务时，如果没有空闲线程，则创建新线程执行任务，会导致一定的系统开销，因此，使用时要注意控制并发的任务数，防止因创建大量的线程导致而降低性能。该线程池的核心线程数量是0，线程的数量最高可以达到Integer 类型最大值

**newSingleThreadExecutor()**

创建一个单例线程池，线程池中只有一个线程，初始化只有一个线程的线程池，内部使用 LinkedBlockingQueue 作为任务队列。

特点：如果该线程异常结束，会重新创建一个新的线程继续执行任务，唯一的线程可以保证所提交任务的顺序执行。

**newScheduledThreadPool()**

任务调度线程池。

特点：初始化的线程池可以在指定的时间内周期性的执行所提交的任务，在实际的业务场景中可以使用该线程池定期的同步数据。

该线程池可以设置核心线程数量，最大线程数与newCachedThreadPool一样，都是Integer.MAX_VALUE。该线程池采用的队列是DelayedWorkQueue，具有延迟和定时的作用。

> 除了 newScheduledThreadPool 的内部实现特殊一点之外，其它线程池内部都是基于 ThreadPoolExecutor 类实现的。

##### 池化技术

池化技术简单点来说，就是提前保存大量的资源，以备不时之需。在机器资源有限的情况下，使用池化技术可以大大的提高资源的利用率，提升性能等。在编程领域，比较典型的池化技术有：

线程池、连接池、内存池、对象池等。

##### 线程池的监控

由于大量的使用线程池，所以很有必要对其进行监控。可以通过继承线程池来自定义线程池，重写线程池的beforeExecute、afterExecute 和 terminated 方法，也可以在任务执行前，执行后和线程池关闭前执行一些代码来进行监控。在监控线程池的时候可以使用一下属性：

- taskCount：线程池需要执行的任务数量
- completedTaskCount：线程池在运行过程中已完成的任务数量，小于或等于taskCount
- largestPoolSize： 线程池里曾经创建过最大的线程数量。通过这个数据可以知道线程池是否曾经满过。如该数值等于线程池最大大小，则表示线程池曾经满过。
- getPoolSize：线程池的线程数量。如果线程池不销毁的话，线程池里的线程不会自动销毁，所以这个大小只增不减。
- getActiveCount：获取活动的线程数

##### Runnable和Callable

可以向线程池提交的任务有两种：`Runnable`和`Callable`，二者的区别如下：

- 方法签名不同，`void Runnable.run()`, `V Callable.call() throws Exception`
- 是否允许有返回值，`Callable`允许有返回值
- 是否允许抛出异常，`Callable`允许抛出异常。

`Callable`是JDK1.5时加入的接口，作为`Runnable`的一种补充，允许有返回值，允许抛出异常。

三种提交任务的方式：

| 提交方式                               | 是否关心返回结果                        |
| ---------------------------------- | ------------------------------- |
| Future<T> submit(Callable<T> task) | 是                               |
| void execute(Runnable command)     | 否                               |
| Future<?> submit(Runnable task)    | 否，虽然返回Future，但是其get()方法总是返回null |

##### FutureTask 与线程池使用

FutureTask 是一个支持取消的异步处理器，一般在线程池中用于异步接受 callable 返回值。主要实现分三部分：

- 封装callable，然后放到线程池中去异步执行->run。
- 获取结果->get。
- 取消任务->cancel。

![](https://mmbiz.qpic.cn/mmbiz/iarMRfJHmKibX0sExyAm4qWSuBCEOFy2bGx3PGjclbya5k4icPml3s9lQAunrdmffnVkicKiaRk76ibbtBZeRtAwic5pw/640?wx_fmt=other&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

[FutureTask参考](https://mp.weixin.qq.com/s?__biz=MzI3ODc3NzQ4NQ==&mid=2247485468&idx=1&sn=6ee78d4735d7a184f2c701d3b861b090&chksm=eb5093fedc271ae8eb67da360d63e3b335021ed3f2be5da4f59a2ce3bea388712d59884a4b79&scene=0#rd) 

#### ThreadLocal

> 该类提供了线程局部 (thread-local) 变量。这些变量不同于它们的普通对应物，因为访问某个变量（通过其`get` 或 `set` 方法）的每个线程都有自己的局部变量，它独立于变量的初始化副本。`ThreadLocal`实例通常是类中的 private static 字段，它们希望将状态与某一个线程（例如，用户 ID 或事务 ID）相关联。可以保证共享变量在多线程环境下访问的线程安全性

所以ThreadLocal与线程同步机制不同，线程同步机制是多个线程共享同一个变量，而ThreadLocal是为每一个线程创建一个单独的变量副本，故而每个线程都可以独立地改变自己所拥有的变量副本，而不会影响其他线程所对应的副本。可以说ThreadLocal为多线程环境下变量问题提供了另外一种解决思路。

ThreadLocal定义了四个方法：

- get()：返回此线程局部变量的当前线程副本中的值。
- initialValue()：返回此线程局部变量的当前线程的“初始值”。
- remove()：移除此线程局部变量当前线程的值。
- set(T value)：将此线程局部变量的当前线程副本中的值设置为指定值。

除了这四个方法，ThreadLocal内部还有一个静态内部类ThreadLocalMap，该内部类才是实现线程隔离机制的关键，get()、set()、remove()都是基于该内部类操作。ThreadLocalMap提供了一种用键值对方式存储每一个线程的变量副本的方法，key为当前ThreadLocal对象，value则是对应线程的变量副本。

ThreadLocal会给定一个初始值，也就是 `initialValue()`方法，而每个线程都会从ThreadLocal中获得这个初始化的值的副本，这样可以使得每个线程都拥有一个副本拷贝

注意：

- ThreadLocal实例本身是不存储值，它只是提供了一个在当前线程中找到副本值得key。
- 是ThreadLocal包含在Thread中，而不是Thread包含在ThreadLocal中，有些小伙伴会弄错他们的关系。

> ThreadLocal并不是为线程保存对象的副本，它仅仅只起到一个索引的作用。它的主要目的是为每一个线程隔离一个类的实例，这个实例的作用范围仅限于线程内部。

#### ？ ThreadLoacl为什么会内存泄露

每个Thread都有一个ThreadLocal.ThreadLocalMap的map，该map的key为ThreadLocal实例，它为一个弱引用，我们知道弱引用有利于GC回收。当ThreadLocal的key == null时，GC就会回收这部分空间，但是value却不一定能够被回收，因为他还与Current Thread存在一个强引用关系。

由于存在这个强引用关系，会导致value无法回收。如果这个线程对象不会销毁那么这个强引用关系则会一直存在，就会出现内存泄漏情况。所以说只要这个线程对象能够及时被GC回收，就不会出现内存泄漏。如果碰到线程池，那就更坑了。

在ThreadLocalMap中的setEntry()、getEntry()，如果遇到key == null的情况，会对value设置为null。当然我们也可以显示调用ThreadLocal的remove()方法进行处理。

##### ThreadLocal的应用场景

1. 比如在线程级别，维护session,维护用户登录信息userID（登陆时插入，多个地方获取）
2. 数据库的链接对象 `Connection`，可以通过ThreadLocal来做隔离避免线程安全问题

#### java锁与线程阻塞

> 为保障多线程下处理共享数据的安全性，Java 语言给我们提供了线程锁，保证同一时刻只有一个线程能处理共享数据。当一个锁被某个线程持有的时候，另一个线程尝试去获取这个锁将产生线程阻塞，直到持有锁的线程释放了该锁。
>
> 除了抢占锁的时候会出现线程阻塞，另外还有一些方法也会产生线程阻塞，比如： Object.wait(), Thread.sleep(), ArrayBlockingQueue.put() 等等，他们都有一个共同特点：不消耗 CPU 时间片。另外值得指出的是 Object.wait() 会释放持有的锁，而 Thread.sleep() 不会。

目前有三种线程锁：

- synchronized 方法
- synchronized 区块
- ReentrantLock

[参考](https://mp.weixin.qq.com/s?__biz=MzIwMzYwMTk1NA==&mid=2247491998&idx=1&sn=6eb1bb9a1c32bfc82174e14c9f6f157e&chksm=96ce40d3a1b9c9c5e7c3c744cc9666f288f8ea4a98aa311db7ccddcee7cda13bdaf9fae74b70&scene=0#rd) 

#### java中的锁分类

##### 公平锁 / 非公平锁

**公平锁** 

公平锁是指多个线程按照申请锁的顺序来获取锁。

**非公平锁**

非公平锁是指多个线程获取锁的顺序并不是按照申请锁的顺序，有可能后申请的线程比先申请的线程优先获取锁。有可能，会造成优先级反转或者饥饿现象。

对于`Java ReentrantLock`而言，通过构造函数指定该锁是否是公平锁，默认是非公平锁。非公平锁的优点在于吞吐量比公平锁大。
对于`Synchronized`而言，也是一种非公平锁。由于其并不像`ReentrantLock`是通过`AQS`的来实现线程调度，所以并没有任何办法使其变成公平锁。

##### 可重入锁/不可重入锁

**可重入锁**

可重入锁又名递归锁，是指在同一个线程在外层方法获取锁的时候，在进入内层方法会自动获取锁。

> 广义上的可重入锁指的是可重复可递归调用的锁，在外层使用锁之后，在内层仍然可以使用，并且不发生死锁（前提得是同一个对象或者class），这样的锁就叫做可重入锁。
>
> `ReentrantLock`和`synchronized`都是可重入锁

```
代码示例
synchronized void setA() throws Exception{
   Thread.sleep(1000);
   setB();
}
synchronized void setB() throws Exception{
   Thread.sleep(1000);
}
>>> 上面的代码就是一个可重入锁的一个特点，如果不是可重入锁的话，setB可能不会被当前线程执行，可能造成死锁。
```

**不可重入锁** 

不可重入锁，与可重入锁相反，不可递归调用，递归调用就发生死锁。

##### 独占锁/共享锁

**独占锁**

该锁每一次只能被一个线程所持有。

**共享锁**

该锁可被多个线程共有，典型的就是ReentrantReadWriteLock里的读锁，它的读锁是可以被共享的，但是它的写锁确每次只能被独占。

另外读锁的共享可保证并发读是非常高效的，但是读写和写写，写读都是互斥的。

独享锁与共享锁也是通过AQS来实现的，通过实现不同的方法，来实现独享或者共享。对于Synchronized而言，当然是独享锁。

##### 互斥锁/读写锁

**互斥锁** 

在访问共享资源之前对进行加锁操作，在访问完成之后进行解锁操作。 加锁后，任何其他试图再次加锁的线程会被阻塞，直到当前进程解锁。

如果解锁时有一个以上的线程阻塞，那么所有该锁上的线程都被编程就绪状态， 第一个变为就绪状态的线程又执行加锁操作，那么其他的线程又会进入等待。 在这种方式下，只有一个线程能够访问被互斥锁保护的资源

**读写锁在Java中的具体实现就是**`ReentrantLock`

**读写锁** 

读写锁既是互斥锁，又是共享锁，read模式是共享，write是互斥(排它锁)的。

**读写锁有三种状态**：读加锁状态、写加锁状态和不加锁状态

**读写锁在Java中的具体实现就是**`ReadWriteLock`

> 一次只有一个线程可以占有写模式的读写锁，但是多个线程可以同时占有读模式的读写锁。
> 只有一个线程可以占有写状态的锁，但可以有多个线程同时占有读状态锁，这也是它可以实现高并发的原因。当其处于写状态锁下，任何想要尝试获得锁的线程都会被阻塞，直到写状态锁被释放；如果是处于读状态锁下，允许其它线程获得它的读状态锁，但是不允许获得它的写状态锁，直到所有线程的读状态锁被释放；为了避免想要尝试写操作的线程一直得不到写状态锁，当读写锁感知到有线程想要获得写状态锁时，便会阻塞其后所有想要获得读状态锁的线程。所以读写锁非常适合资源的读操作远多于写操作的情况。

##### 乐观锁/悲观锁

乐观锁与悲观锁不是指具体的什么类型的锁，而是指看待并发同步的角度。

**乐观锁**

乐观锁则认为对于同一个数据的并发操作，是不会发生修改的。在更新数据的时候，会采用尝试更新，不断重新的方式更新数据。乐观的认为，不加锁的并发操作是没有事情的。

> 乐观锁适用于多读的应用类型，这样可以提高吞吐量，像数据库提供的类似于`write_condition`机制，其实都是提供的乐观锁。在`Java`中`java.util.concurrent.atomic`包下面的原子变量类就是使用了乐观锁的一种实现方式CAS实现的。

**悲观锁**

悲观锁认为对于同一个数据的并发操作，一定是会发生修改的，哪怕没有修改，也会认为修改。因此对于同一个数据的并发操作，悲观锁采取加锁的形式。悲观的认为，不加锁的并发操作一定会出问题。

> 传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。`Java`中`synchronized`和`ReentrantLock`等独占锁就是悲观锁思想的实现。

悲观锁适合写操作非常多的场景，乐观锁适合读操作非常多的场景，不加锁会带来大量的性能提升。

##### 分段锁

分段锁其实是一种锁的设计，并不是具体的一种锁，对于`ConcurrentHashMap`而言，其并发的实现就是通过分段锁的形式来实现高效的并发操作。并发容器类的加锁机制是基于粒度更小的分段锁，分段锁也是提升多并发程序性能的重要手段之一。

**我们一般有三种方式降低锁的竞争程度**： 

1. 减少锁的持有时间 
2. 降低锁的请求频率 
3. 使用带有协调机制的独占锁，这些机制允许更高的并发性。

[[ConcurrentHashMap的锁分段设计](https://www.cnblogs.com/protected/p/6432977.html)](http://www.cnblogs.com/protected/p/6432977.html) 

##### 偏向锁/轻量级锁/重量级锁

**锁的状态**：

- 无锁状态
- 偏向锁状态
- 轻量级锁状态
- 重量级锁状态

> 锁的状态是通过对象监视器在对象头中的字段来表明的。
> 四种状态会随着竞争的情况逐渐升级，而且是不可逆的过程，即不可降级。
> **这四种状态都不是Java语言中的锁**，而是Jvm为了提高锁的获取与释放效率而做的优化(**使用synchronized时**)。

**偏向锁**

偏向锁是指一段同步代码一直被一个线程所访问，那么该线程会自动获取锁。降低获取锁的代价。

**轻量级锁**

轻量级锁是指当锁是偏向锁的时候，被另一个线程所访问，偏向锁就会升级为轻量级锁，其他线程会通过自旋的形式尝试获取锁，不会阻塞，提高性能。

**重量级锁**

重量级锁是指当锁为轻量级锁的时候，另一个线程虽然是自旋，但自旋不会一直持续下去，当自旋一定次数的时候，还没有获取到锁，就会进入阻塞，该锁膨胀为重量级锁。重量级锁会让其他申请的线程进入阻塞，性能降低。

##### 自旋锁

在Java中，自旋锁是指尝试获取锁的线程不会立即阻塞，而是采用循环的方式去尝试获取锁，这样的好处是减少线程上下文切换的消耗，缺点是循环会消耗CPU。

> 它是为实现保护共享资源而提出一种锁机制。其实，自旋锁与互斥锁比较类似，它们都是为了解决对某项资源的互斥使用。**无论是互斥锁，还是自旋锁，在任何时刻，最多只能有一个保持者，也就说，在任何时刻最多只能有一个执行单元获得锁**。但是两者在调度机制上略有不同。对于互斥锁，如果资源已经被占用，资源申请者只能进入睡眠状态。但是自旋锁不会引起调用者睡眠，如果自旋锁已经被别的执行单元保持，调用者就一直循环在那里看是否该自旋锁的保持者已经释放了锁，”自旋”一词就是因此而得名。

**简单的自旋锁实现** 

```
public class SpinLock {
   private AtomicReference<Thread> cas = new AtomicReference<Thread>();
   public void lock() {
       Thread current = Thread.currentThread();
       // 利用CAS
       while (!cas.compareAndSet(null, current)) {
           // DO nothing
       }
   }
   public void unlock() {
       Thread current = Thread.currentThread();
       cas.compareAndSet(current, null);
   }
}
```

> lock（)方法利用的CAS，当第一个线程A获取锁的时候，能够成功获取到，不会进入while循环，如果此时线程A没有释放锁，另一个线程B又来获取锁，此时由于不满足CAS，所以就会进入while循环，不断判断是否满足CAS，直到A线程调用unlock方法释放了该锁。

**自旋锁存在的问题**

- 如果某个线程持有锁的时间过长，就会导致其它等待获取锁的线程进入循环等待，消耗CPU。使用不当会造成CPU使用率极高。
- 上面Java实现的自旋锁不是公平的，即无法满足等待时间最长的线程优先获取锁。不公平的锁就会存在“线程饥饿”问题。

**自旋锁优点**

- 自旋锁不会使线程状态发生切换，一直处于用户态，即线程一直都是active的；不会使线程进入阻塞状态，减少了不必要的上下文切换，执行速度快
- 非自旋锁在获取不到锁的时候会进入阻塞状态，从而进入内核态，当获取到锁的时候需要从内核态恢复，需要线程上下文切换。 （线程被阻塞后便进入内核（Linux）调度状态，这个会导致系统在用户态与内核态之间来回切换，严重影响锁的性能）

**可重入的自旋锁实现**

```
public class ReentrantSpinLock {
   private AtomicReference<Thread> cas = new AtomicReference<Thread>();
   private int count;
   public void lock() {
       Thread current = Thread.currentThread();
       if (current == cas.get()) { // 如果当前线程已经获取到了锁，线程数增加一，然后返回
           count++;
           return;
       }
       // 如果没获取到锁，则通过CAS自旋
       while (!cas.compareAndSet(null, current)) {
           // DO nothing
       }
   }
   public void unlock() {
       Thread cur = Thread.currentThread();
       if (cur == cas.get()) {
           if (count > 0) {// 如果大于0，表示当前线程多次获取了该锁，释放锁通过count减一来模拟
               count--;
           } else {// 如果count==0，可以将锁释放，这样就能保证获取锁的次数与释放锁的次数是一致的了。
               cas.compareAndSet(cur, null);
           }
       }
   }
}
```

**自旋锁与互斥锁**

1. 自旋锁与互斥锁都是为了实现保护资源共享的机制。
2. 无论是自旋锁还是互斥锁，在任意时刻，都最多只能有一个保持者。
3. 获取互斥锁的线程，如果锁已经被占用，则该线程将进入睡眠状态；获取自旋锁的线程则不会睡眠，而是一直循环等待锁释放。

**自旋锁总结**

1. 自旋锁：线程获取锁的时候，如果锁被其他线程持有，则当前线程将循环等待，直到获取到锁。
2. 自旋锁等待期间，线程的状态不会改变，线程一直是用户态并且是活动的(active)。
3. 自旋锁如果持有锁的时间太长，则会导致其它等待获取锁的线程耗尽CPU。
4. 自旋锁本身无法保证公平性，同时也无法保证可重入性。
5. 基于自旋锁，可以实现具备公平性和可重入性质的锁。

#### 锁的几个概念

##### CAS算法

`CAS`是英文单词`Compare and Swap`（比较并交换），是一种有名的无锁算法。无锁编程，即不使用锁的情况下实现多线程之间的变量同步，也就是在没有线程被阻塞的情况下实现变量的同步，所以也叫非阻塞同步（`Non-blocking Synchronization`）。

CAS算法涉及到三个操作数：

- 需要读写的内存值 V
- 进行比较的值 A
- 拟写入的新值 B

> 更新一个变量的时候，只有当变量的预期值A和内存地址V当中的实际值相同时，才会将内存地址V对应的值修改为B，否则不会执行任何操作。一般情况下是一个自旋操作，即不断的重试。

*synchronized、Lock 都采用了悲观锁的机制，而 CAS 是一种乐观锁的实现。*

CAS 的特性：

- 通过调用 JNI 的代码实现
- 非阻塞算法
- 非独占锁

CAS 存在的问题：

- ABA
- 循环时间长开销大
- 只能保证一个共享变量的原子操作

##### 线程的用户态和内核态

内核态：CPU可以访问内存所有数据, 包括外围设备, 例如硬盘, 网卡. CPU也可以将自己从一个程序切换到另一个程序

用户态：只能受限的访问内存, 且不允许访问外围设备. 占用CPU的能力被剥夺, CPU资源可以被其他程序获取

> 由于需要限制不同的程序之间的访问能力, 防止他们获取别的程序的内存数据, 或者获取外围设备的数据, 并发送到网络, CPU划分出两个权限等级 :**用户态** 和 **内核态**

**用户态与内核态的切换** 

> 所有用户程序都是运行在用户态的, 但是有时候程序确实需要做一些内核态的事情, 例如从硬盘读取数据, 或者从键盘获取输入等. 而唯一可以做这些事情的就是操作系统, 所以此时程序就需要先操作系统请求以程序的名义来执行这些操作.这时需要一个这样的机制: 用户态程序切换到内核态, 但是不能控制在内核态中执行的指令.
>
> 这种机制叫**系统调用**, 在CPU中的实现称之为**陷阱指令**(Trap Instruction).工作流程如下：
>
> 1. 用户态程序将一些数据值放在寄存器中, 或者使用参数创建一个堆栈(stack frame), 以此表明需要操作系统提供的服务.
> 2. 用户态程序执行陷阱指令
> 3. CPU切换到内核态, 并跳到位于内存指定位置的指令, 这些指令是操作系统的一部分, 他们具有内存保护, 不可被用户态程序访问
> 4. 这些指令称之为陷阱(trap)或者系统调用处理器(system call handler). 他们会读取程序放入内存的数据参数, 并执行程序请求的服务
> 5. 系统调用完成后, 操作系统会重置CPU为用户态并返回系统调用的结果

[参考](https://www.cnblogs.com/duanjiapingjy/p/9630711.html)  

##### AQS

AbstractQueuedSynchronizer  抽象的队列式的同步器，AQS定义了一套多线程访问共享资源的同步器框架，许多同步类实现都依赖于它，如常用的ReentrantLock/Semaphore/CountDownLatch...。

AQS是JDK下提供的一套用于实现基于FIFO等待队列的阻塞锁和相关的同步器的一个同步框架。这个抽象类被设计为作为一些可用原子int值来表示状态的同步器的基类。

[参考](https://www.cnblogs.com/waterystone/p/4920797.html) 

##### ReentrantLock

ReentrantLock（可重入锁）是基于AQS实现的

ReentrantLock 是一个独占/排他锁。相对于 synchronized，它更加灵活。但是需要自己写出加锁和解锁的过程。它的灵活性在于它拥有很多特性:

- **公平性**：支持公平锁和非公平锁。默认使用了非公平锁。
- **可重入**
- **可中断**：相对于 synchronized，它是可中断的锁，能够对中断作出响应。
- **超时机制**：超时后不能获得锁，因此不会造成死锁。

> ReentrantLock 需要显示地进行释放锁。特别是在程序异常时，synchronized 会自动释放锁，而 ReentrantLock 并不会自动释放锁，所以必须在 finally 中进行释放锁。

###### ReentrantReadWriteLock

它拥有读锁(ReadLock)和写锁(WriteLock)，读锁是一个共享锁，写锁是一个排他锁。

特性：

- **公平性**：支持公平锁和非公平锁。默认使用了非公平锁。
- **可重入**：读线程在获取读锁之后能够再次获取读锁。写线程在获取写锁之后能够再次获取写锁，同时也可以获取读锁（锁降级）。
- **锁降级**：先获取写锁，再获取读锁，然后再释放写锁的过程。锁降级是为了保证数据的可见性。

[参考](http://www.cnblogs.com/-new/p/7256297.html) 

##### synchronized

> 在 JDK 1.6 之前，synchronized 是重量级锁，效率低下。
>
> 从 JDK 1.6 开始，synchronized 做了很多优化，如偏向锁、轻量级锁、自旋锁、适应性自旋锁、锁消除、锁粗化等技术来减少锁操作的开销。
>
> synchronized 同步锁一共包含四种状态：无锁、偏向锁、轻量级锁、重量级锁，它会随着竞争情况逐渐升级。synchronized 同步锁可以升级但是不可以降级，目的是为了提高获取锁和释放锁的效率。

##### 对象锁、类锁、私有锁

**对象锁**：使用 synchronized 修饰**非静态**的方法以及 synchronized(this) 同步代码块使用的锁是对象锁。

**类锁**：使用 synchronized 修饰**静态**的方法以及 synchronized(class) 同步代码块使用的锁是类锁。

**私有锁**：在类内部声明一个私有属性如private Object lock，在需要加锁的同步块使用 synchronized(lock）

特性如下：

- 对象锁具有可重入性。
- 当一个线程获得了某个对象的对象锁，则该线程仍然可以调用其他任何需要该对象锁的 synchronized 方法或 synchronized(this) 同步代码块。
- 当一个线程访问某个对象的一个 synchronized(this) 同步代码块时，其他线程对该对象中所有其它 synchronized(this) 同步代码块的访问将被阻塞，因为访问的是同一个对象锁。
- 每个类只有一个类锁，但是类可以实例化成对象，因此每一个对象对应一个对象锁。
- 类锁和对象锁不会产生竞争。
- 私有锁和对象锁也不会产生竞争。
- 使用私有锁可以减小锁的细粒度，减少由锁产生的开销。

##### Unsafe

Java无法直接访问底层操作系统，而是通过本地（native）方法来访问。不过尽管如此，JVM还是开了一个后门，JDK中有一个类Unsafe，它提供了硬件级别的**原子操作**。

这个类尽管里面的方法都是public的，但是并没有办法使用它们，JDK API文档也没有提供任何关于这个类的方法的解释。总而言之，对于Unsafe类的使用都是受限制的，只有授信的代码才能获得该类的实例，当然JDK库里面的类是可以随意使用的。

##### condition

Condition 用于替代传统的 Object 的 wait()、notify() 实现线程间的协作。

> 在 Condition 对象中，与 wait、notify、notifyAll 方法对应的分别是 await、signal 和 signalAll。

Condition 必须要配合 Lock 一起使用，一个 Condition 的实例必须与一个 Lock 绑定。

特性：

- 一个 Lock 对象可以创建多个 Condition 实例，所以可以支持多个等待队列。
- Condition 在使用 await、signal 或 signalAll 方法时，必须先获得 Lock 的 lock()
- 支持响应中断
- 支持定时唤醒功能

##### Semaphore

Semaphore、CountDownLatch、CyclicBarrier 都是并发工具类。

Semaphore 可以指定多个线程同时访问某个资源，而 synchronized 和 ReentrantLock 都是一次只允许一个线程访问某个资源。由于 Semaphore 适用于限制访问某些资源的线程数目，因此可以使用它来做限流。

> Semaphore 并不会实现数据的同步，数据的同步还是需要使用 synchronized、Lock 等实现。

特性：

- 基于 AQS 的共享模式
- 公平性：支持公平模式和非公平模式。默认使用了非公平模式。

##### CountDownLatch

CountDownLatch 可以看成是一个倒计数器，它允许一个或多个线程等待其他线程完成操作。因此，CountDownLatch 是共享锁。

CountDownLatch 的 countDown() 方法将计数器减1，await() 方法会阻塞当前线程直到计数器变为0。

![锁分类](https://mmbiz.qpic.cn/mmbiz_jpg/JdLkEI9sZfe0CIYAicpDpSQkmGaGVibLyc5TjNG9qibibQnUdtbCznvdQ4f1wqJmuqGndQSHdUT1jFXwURH8WqAR4g/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

#### 锁相关面试题

##### ?**分段锁的设计解决的是什么问题**

分段锁的设计目的是细化锁的粒度，当操作不需要更新整个数组的时候，就仅仅针对数组中的一部分行加锁操作。

## JavaWeb

#### web.xml配置文件

参考: 1.   [web.xml配置](https://www.jianshu.com/p/bdf19d50a723) 

2.   [web.xml元素](http://www.cnblogs.com/hafiz/p/5715523.html)

#### tomcat处理一个Http请求过程

*假设请求地址   http://localhost:8080/wsota/wsota_index.jsp*

1. 请求被发送到本机端口8080，被在那里侦听的Coyote HTTP/1.1 Connector获得
2. Connector把该请求交给它所在的Service的Engine来处理，并等待来自Engine的回应
3. Engine获得请求localhost/wsota/wsota_index.jsp，匹配它所拥有的所有虚拟主机Host
4. Engine匹配到名为localhost的Host（即使匹配不到也把请求交给该Host处理，因为该Host被定义为该Engine的默认主机）
5. localhost Host获得请求/wsota/wsota_index.jsp，匹配它所拥有的所有Context
6. Host匹配到路径为/wsota的Context（如果匹配不到就把该请求交给路径名为”"的Context去处理）
7. path=”/wsota”的Context获得请求/wsota_index.jsp，在它的mapping table中寻找对应的servlet
8. Context匹配到URL PATTERN为*.jsp的servlet，对应于JspServlet类
9. 构造HttpServletRequest对象和HttpServletResponse对象，作为参数调用JspServlet的doGet或doPost方法
10. Context把执行完了之后的HttpServletResponse对象返回给Host
11. Host把HttpServletResponse对象返回给Engine
12. Engine把HttpServletResponse对象返回给Connector
13. Connector把HttpServletResponse对象返回给客户browser

---

[谈谈 Tomcat 请求处理流程](https://mp.weixin.qq.com/s?__biz=MzAxMjY5NDU2Ng==&mid=2651852959&idx=1&sn=6bc98fb93e981e511e37cddd921b2f08&chksm=804955d6b73edcc07fb78383ad9f8c9273a40ba46dfe2cb614693610095a99430bb6042b4586&scene=0#rd)

[Tomcat Connector 参数优化说明](https://www.cnblogs.com/xiangsikai/p/9156631.html) 

#### Tomcat启动过程

通过bin目录下的startup.bat来启动tomcat，startup.bat又调用了catalina.bat，catalina.bat从命令行启动org.apache.catalina.startup.Bootstrap，这个类有main方法，所以可以从命令行执行。

Bootstrap执行后，首先执行init()方法进行初始化，然后调用load()和start()方法。下面具体介绍init()方法、load()、start()方法

1. init()

   首先设置catalina.home，catalina.base这两个环境变量；

   创建了三个类加载器

   根据conf/catalina.properties中的配置，初始化了三个ClassLoader：commonLoader、catalinaLoader、sharedLoader；并且把catalinaLoader设置为当前线程上下文的类加载器；然后创建Catalina类的对象（变量名是catalinaDaemon）：

   ```
   Class startupClass =catalinaLoader.loadClass ("org.apache.catalina.startup.Catalina");
   Object startupInstance = startupClass.newInstance();
   ```

2. load()

   通过反射机制，调用catalina对象的load()方法------在该方法中，初始化一些目录，比如temp目录，初始化名称空间，如java:env；然后使用Digester的方式，根据server.xml的配置来装配tomcat的各个组件，这里暂时提一下tomcat的结构，tomcat顶层组件是Server，Server下面有多个Service组件，还有Connector、Engin、Host等。装配组件的过程中，生成了各个组件的对象，并设置了他们之间的关联关系。

3. start()

   该方法里面，通过反射机制，调用了Catalina对象的start()方法。Catalina对象的start()方法又调用了Server对象的Start()方法，并设置关闭Server的回调方法。

#### Tomcat简单使用

[参考](https://mp.weixin.qq.com/s?__biz=MzI4Njg5MDA5NA==&mid=2247484755&idx=2&sn=b09e747bd0af5e1899a47911f92d1afe&chksm=ebd74452dca0cd44ebbcdacab7373a72d0c769746eaa2bfa454d1dbc8295e3f93b0645c0ac58&scene=0&xtrack=1#rd) 

#### JVM类加载过程

当jvm运行时，需要加载某些类：（父类委托机制）

1.  用户自己的类加载器，把加载请求传给父加载器，父加载器再传给其父加载器，一直到加载器树的顶层。
2.  最顶层的类加载器首先针对其特定的位置加载，如果加载不到就转交给子类。
3.  如果一直到底层的类加载都没有加载到，那么就会抛出异常ClassNotFoundException。

#### Tocmat类加载过程

web应用加载类：

1. 使用bootstrap引导类加载器加载


2. 使用system系统类加载器加载
3. 使用应用类加载器在WEB-INF/classes中加载
4. 使用应用类加载器在WEB-INF/lib中加载
5. 使用common类加载器在CATALINA_HOME/lib中加载

#### Tomcat组件

![](https://mmbiz.qpic.cn/mmbiz_png/UtWdDgynLdbF4cx28gxqQNf6ggZbaiaLXHNNHbkgHsIJSC3YRftWwTg6VDn1vCiasxIU0Hv158uxjbcSQnKTdgIA/640?tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

##### 顶层元素：<Server>和<Service>

<Server>元素是整个配置文件的根元素，<Service>元素则代表一个Engine元素以及一组与之相连的Connector元素。

Server元素在最顶层，代表整个Tomcat容器，因此它必须是server.xml中唯一一个最外层的元素。一个Server元素中可以有一个或多个Service元素。

在最外层有一个<Server>元素，shutdown属性表示关闭Server的指令；port属性表示Server接收shutdown指令的端口号，设为-1可以禁掉该端口。

> Server的主要任务，就是提供一个接口让客户端能够访问到这个Service集合，同时维护它所包含的所有的Service的声明周期，包括如何初始化、如何结束服务、如何找到客户端要访问的Service。

Service的作用，是在Connector和Engine外面包了一层，把它们组装在一起，对外提供服务。一个Service可以包含多个Connector，但是只能包含一个Engine；其中Connector的作用是从客户端接收请求，Engine的作用是处理接收进来的请求。

Server中包含一个名称为“Catalina”的Service。实际上，Tomcat可以提供多个Service，不同的Service监听不同的端口

##### 连接器：<Connector>

<Connector>代表了外部客户端发送请求到特定Service的接口；同时也是外部客户端从特定Service接收响应的接口。

Connector的主要功能，是接收连接请求，创建Request和Response对象用于和请求端交换数据；然后分配线程让Engine来处理这个请求，并把产生的Request和Response对象传给Engine。

通过配置Connector，可以控制请求Service的协议及端口号。

- 其中，protocol属性规定了请求的协议，port规定了请求的端口号，redirectPort表示当强制要求https而请求是http时，重定向至端口号为8443的Connector，connectionTimeout表示连接的超时时间。
- 实际上，在正式的生产环境中，Tomcat也常常监听8080端口，而不是80端口。这是因为在生产环境中，很少将Tomcat直接对外开放接收请求，而是在Tomcat和客户端之间加一层代理服务器(如nginx)，用于请求的转发、负载均衡、处理静态文件等；通过代理服务器访问Tomcat时，是在局域网中，因此一般仍使用8080端口。
- AJP协议负责和其他的HTTP服务器(如Apache)建立连接；在把Tomcat与其他HTTP服务器集成时，就需要用到这个连接器。之所以使用Tomcat和其他服务器集成，是因为Tomcat可以用作Servlet/JSP容器，但是对静态资源的处理速度较慢，不如Apache和IIS等HTTP服务器；因此常常将Tomcat与Apache等集成，前者作Servlet容器，后者处理静态资源，而AJP协议便负责Tomcat和Apache的连接。

##### 容器：<Engine><Host><Context>

容器的功能是处理Connector接收进来的请求，并产生相应的响应。Engine、Host和Context都是容器，但它们不是平行的关系，而是父子关系：Engine包含Host，Host包含Context。一个Engine组件可以处理Service中的所有请求，一个Host组件可以处理发向一个特定虚拟主机的所有请求，一个Context组件可以处理一个特定Web应用的所有请求。

Engine组件在Service组件中有且只有一个；Engine是Service组件中的请求处理组件。Engine组件从一个或多个Connector中接收请求并处理，并将完成的响应返回给Connector，最终传递给客户端。

Engine、Host和Context都是容器，但它们不是平行的关系，而是父子关系：Engine包含Host，Host包含Context。

```
<Engine name="Catalina" defaultHost="localhost">
```

name属性用于日志和错误信息，在整个Server中应该唯一。defaultHost属性指定了默认的host名称，当发往本机的请求指定的host名称不存在时，一律使用defaultHost指定的host进行处理；因此，defaultHost的值，必须与Engine中的一个Host组件的name属性值匹配。

Host是Engine的子容器。Engine组件中可以内嵌1个或多个Host组件，每个Host组件代表Engine中的一个虚拟主机。Host组件至少有一个，且其中一个的name必须与Engine组件的defaultHost属性相匹配。

Host虚拟主机的作用，是运行多个Web应用（一个Context代表一个Web应用），并负责安装、展开、启动和结束每个Web应用。

Host组件代表的虚拟主机，对应了服务器中一个网络名实体(如”www.javastack.cn”，或IP地址”116.25.25.25”)；为了使用户可以通过网络名连接Tomcat服务器，这个名字应该在DNS服务器上注册。

客户端通常使用主机名来标识它们希望连接的服务器；该主机名也会包含在HTTP请求头中。Tomcat从HTTP头中提取出主机名，寻找名称匹配的主机。如果没有匹配，请求将发送至默认主机。因此默认主机不需要是在DNS服务器中注册的网络名，因为任何与所有Host名称不匹配的请求，都会路由至默认主机。

```
<Host name="localhost" appBase="webapps" unpackWARs="true" autoDeploy="true">
```

- name属性指定虚拟主机的主机名，一个Engine中有且仅有一个Host组件的name属性与Engine组件的defaultHost属性相匹配；一般情况下，主机名需要是在DNS服务器中注册的网络名，但是Engine指定的defaultHost不需要，原因在前面已经说明。
- unpackWARs指定了是否将代表Web应用的WAR文件解压；如果为true，通过解压后的文件结构运行该Web应用，如果为false，直接使用WAR文件运行Web应用。
- Host的autoDeploy和appBase属性，与Host内Web应用的自动部署有关；此外，本例中没有出现的xmlBase和deployOnStartup属性，也与Web应用的自动部署有关；

Context元素代表在特定虚拟主机上运行的一个Web应用。在后文中，提到Context、应用或Web应用，它们指代的都是Web应用。每个Web应用基于WAR文件，或WAR文件解压后对应的目录（这里称为应用目录）。

Context是Host的子容器，每个Host中可以定义任意多的Context元素。

> server.xml配置文件中可以没有Context元素的配置。这是因为，Tomcat开启了自动部署，Web应用没有在server.xml中配置静态部署，而是由Tomcat通过特定的规则自动部署。

##### 内嵌组件：可以内嵌到容器中的组件

实际上，Server、Service、Connector、Engine、Host和Context是最重要的最核心的Tomcat组件，其他组件都可以归为内嵌组件。

#### server.xml中静态部署Web应用

除了自动部署，我们也可以在server.xml中通过<context>元素静态部署Web应用。静态部署与自动部署是可以共存的。在实际应用中，并不推荐使用静态部署，因为server.xml 是不可动态重加载的资源，服务器一旦启动了以后，要修改这个文件，就得重启服务器才能重新加载。而自动部署可以在Tomcat运行时通过定期的扫描来实现，不需要重启服务器。

```
<Context path="/" docBase="D:\program Files \app1.war" reloadable="true" />
```

- docBase：静态部署时，docBase可以在appBase目录下，也可以不在；
- path：静态部署时，可以显式指定path属性，但是仍然受到了严格的限制：只有当自动部署完全关闭(deployOnStartup和autoDeploy都为false)或docBase不在appBase中时，才可以设置path属性。
- reloadable属性的用法与自动部署时相同。

#### Web应用自动部署

**Host的配置**

要开启Web应用的自动部署，需要配置所在的虚拟主机；配置的方式就是前面提到的Host元素的deployOnStartup和autoDeploy属性。如果deployOnStartup和autoDeploy设置为true，则tomcat启动自动部署：当检测到新的Web应用或Web应用的更新时，会触发应用的部署(或重新部署)。二者的主要区别在于:

- deployOnStartup为true时，Tomcat在启动时检查Web应用，且检测到的所有Web应用视作新应用；
- autoDeploy为true时，Tomcat在运行时定期检查新的Web应用或Web应用的更新

除此之外，二者的处理相似。通过配置deployOnStartup和autoDeploy可以开启虚拟主机自动部署Web应用；实际上，自动部署依赖于检查是否有新的或更改过的Web应用，而Host元素的appBase和xmlBase设置了检查Web应用更新的目录。

其中，appBase属性指定Web应用所在的目录，默认值是webapps，这是一个相对路径，代表Tomcat根目录下webapps文件夹。

xmlBase属性指定Web应用的XML配置文件所在的目录，默认值为conf/<engine_name>/<host_name>

**检查Web应用更新**

一个Web应用可能包括以下文件：XML配置文件，WAR包，以及一个应用目录(该目录包含Web应用的文件结构)；其中XML配置文件位于xmlBase指定的目录，WAR包和应用目录位于appBase指定的目录。Tomcat按照如下的顺序进行扫描，来检查应用更新：

1. 扫描虚拟主机指定的xmlBase下的XML配置文件
2. 扫描虚拟主机指定的appBase下的WAR文件
3. 扫描虚拟主机指定的appBase下的应用目录

**<Context>元素的配置**

Context元素最重要的属性是docBase和path，此外reloadable属性也比较常用。

- docBase指定了该Web应用使用的WAR包路径，或应用目录。需要注意的是，在自动部署场景下(配置文件位于xmlBase中)，docBase不在appBase目录中，才需要指定；如果docBase指定的WAR包或应用目录就在docBase中，则不需要指定，因为Tomcat会自动扫描appBase中的WAR包和应用目录，指定了反而会造成问题。

- path指定了访问该Web应用的上下文路径，当请求到来时，Tomcat根据Web应用的 path属性与URI的匹配程度来选择Web应用处理相应请求。例如，Web应用app1的path属性是”/app1”，Web应用app2的path属性是”/app2”，那么请求/app1/index.html会交由app1来处理；而请求/app2/index.html会交由app2来处理。如果一个Context元素的path属性为””，那么这个Context是虚拟主机的默认Web应用；当请求的uri与所有的path都不匹配时，使用该默认Web应用来处理。

  但是，需要注意的是，在自动部署场景下(配置文件位于xmlBase中)，不能指定path属性，path属性由配置文件的文件名、WAR文件的文件名或应用目录的名称自动推导出来。如扫描Web应用时，发现了xmlBase目录下的app1.xml，或appBase目录下的app1.WAR或app1应用目录，则该Web应用的path属性是”app1”。如果名称不是app1而是ROOT，则该Web应用是虚拟主机默认的Web应用，此时path属性推导为””。

- reloadable属性指示tomcat是否在运行时监控在WEB-INF/classes和WEB-INF/lib目录下class文件的改动。如果值为true，那么当class文件改动时，会触发Web应用的重新加载。在开发环境下，reloadable设置为true便于调试；但是在生产环境中设置为true会给服务器带来性能压力，因此reloadable参数的默认值为false。

#### 页面间对象传递的方法

JSP页面之间的七种传参方法

1. 利用javaBean
2. 绑定到session对象
3. 绑定到application
4. 绑定到request
5. 使用JSP动作指令传参
6. 表单传参
7. URL传参

#### 如何确定请求由谁处理

- 根据协议和端口号选定Service和Engine
- 根据域名或IP地址选定Host
- 根据URI选定Context/Web应用

#### JSP九大内置对象的主要方法

1. request对象

   客户端的请求信息被封装在request对象中，它是HttpServletRequest类的实例。

   1   object getAttribute(String name) 返回指定属性的属性值 
   2   Enumeration getAttributeNames() 返回所有可用属性名的枚举 
   3   String getCharacterEncoding() 返回字符编码方式 
   4   int getContentLength() 返回请求体的长度（以字节数） 
   5   String getContentType() 得到请求体的MIME类型 
   6   ServletInputStream getInputStream() 得到请求体中一行的二进制流 
   7   String getParameter(String name) 返回name指定参数的参数值 
   8   Enumeration getParameterNames() 返回可用参数名的枚举 
   9   String[] getParameterValues(String name) 返回包含参数name的所有值的数组 
   10   String getProtocol() 返回请求用的协议类型及版本号 
   11   String getScheme() 返回请求用的计划名,如:http.https及ftp等 
   12   String getServerName() 返回接受请求的服务器主机名 
   13   int getServerPort() 返回服务器接受此请求所用的端口号 
   14   BufferedReader getReader() 返回解码过了的请求体 
   15   String getRemoteAddr() 返回发送此请求的客户端IP地址 
   16   String getRemoteHost() 返回发送此请求的客户端主机名 
   17   void setAttribute(String key,Object obj) 设置属性的属性值 
   18   String getRealPath(String path) 返回一虚拟路径的真实路径 

2. response对象

     response对象包含了响应客户请求的有关信息，它是HttpServletResponse类的实例。

   1   String getCharacterEncoding() 返回响应用的是何种字符编码 
   2   ServletOutputStream getOutputStream() 返回响应的一个二进制输出流 
   3   PrintWriter getWriter() 返回可以向客户端输出字符的一个对象 
   4   void setContentLength(int len) 设置响应头长度 
   5   void setContentType(String type) 设置响应的MIME类型 
   6   sendRedirect(java.lang.String location) 重新定向客户端的请求 

3. session对象

   session对象指的是客户端与服务器的一次会话，从客户连到服务器的一个WebApplication开始，直到客户端与服务器断开连接为止。它是HttpSession类的实例.

   1   long getCreationTime() 返回SESSION创建时间 
   2   public String getId() 返回SESSION创建时JSP引擎为它设的惟一ID号 
   3   long getLastAccessedTime() 返回此SESSION里客户端最近一次请求时间 
   4   int getMaxInactiveInterval() 返回两次请求间隔多长时间此SESSION被取消(ms) 
   5   String[] getValueNames() 返回一个包含此SESSION中所有可用属性的数组 
   6   void invalidate() 取消SESSION，使SESSION不可用 
   7   boolean isNew() 返回服务器创建的一个SESSION,客户端是否已经加入 
   8   void removeValue(String name) 删除SESSION中指定的属性 
   9   void setMaxInactiveInterval() 设置两次请求间隔多长时间此SESSION被取消(ms) 

4. out对象

    out对象是JspWriter类的实例,是向客户端输出内容常用的对象

   1   void clear() 清除缓冲区的内容 
   2   void clearBuffer() 清除缓冲区的当前内容 
   3   void flush() 清空流 
   4   int getBufferSize() 返回缓冲区以字节数的大小，如不设缓冲区则为0 
   5   int getRemaining() 返回缓冲区还剩余多少可用 
   6   boolean isAutoFlush() 返回缓冲区满时，是自动清空还是抛出异常 
   7   void close() 关闭输出流 

5. page对象

    page对象就是指向当前JSP页面本身，有点像类中的this指针，它是java.lang.Object类的实例

   1   class getClass 返回此Object的类 
   2   int hashCode() 返回此Object的hash码 
   3   boolean equals(Object obj) 判断此Object是否与指定的Object对象相等 
   4   void copy(Object obj) 把此Object拷贝到指定的Object对象中 
   5   Object clone() 克隆此Object对象 
   6   String toString() 把此Object对象转换成String类的对象 
   7   void notify() 唤醒一个等待的线程 
   8   void notifyAll() 唤醒所有等待的线程 
   9   void wait(int timeout) 使一个线程处于等待直到timeout结束或被唤醒 
   10   void wait() 使一个线程处于等待直到被唤醒 
   11   void enterMonitor() 对Object加锁 
   12   void exitMonitor() 对Object开锁 

6. application对象

   application对象实现了用户间数据的共享，可存放全局变量。它开始于服务器的启动，直到服务器的关闭，在此期间，此对象将一直存在；这样在用户的前后连接或不同用户之间的连接中，可以对此对象的同一属性进行操作；在任何地方对此对象属性的操作，都将影响到其他用户对此的访问。服务器的启动和关闭决定了application对象的生命。它是ServletContext类的实例。

   1   Object getAttribute(String name) 返回给定名的属性值 
   2   Enumeration getAttributeNames() 返回所有可用属性名的枚举 
   3   void setAttribute(String name,Object obj) 设定属性的属性值 
   4   void removeAttribute(String name) 删除一属性及其属性值 
   5   String getServerInfo() 返回JSP(SERVLET)引擎名及版本号 
   6   String getRealPath(String path) 返回一虚拟路径的真实路径 
   7   ServletContext getContext(String uripath) 返回指定WebApplication的application对象 
   8   int getMajorVersion() 返回服务器支持的Servlet API的最大版本号 
   9   int getMinorVersion() 返回服务器支持的Servlet API的最小版本号 
   10   String getMimeType(String file) 返回指定文件的MIME类型 
   11   URL getResource(String path) 返回指定资源(文件及目录)的URL路径 
   12   InputStream getResourceAsStream(String path) 返回指定资源的输入流 
   13   RequestDispatcher getRequestDispatcher(String uripath) 返回指定资源的RequestDispatcher对象 
   14   Servlet getServlet(String name) 返回指定名的Servlet 
   15   Enumeration getServlets() 返回所有Servlet的枚举 
   16   Enumeration getServletNames() 返回所有Servlet名的枚举 
   17   void log(String msg) 把指定消息写入Servlet的日志文件 
   18   void log(Exception exception,String msg) 把指定异常的栈轨迹及错误消息写入Servlet的日志文件 
   19   void log(String msg,Throwable throwable) 把栈轨迹及给出的Throwable异常的说明信息 写入Servlet的日志文件 

7. exception对象

   exception对象是一个例外对象，当一个页面在运行过程中发生了例外，就产生这个对象。如果一个JSP页面要应用此对象，就必须把isErrorPage设为true，否则无法编译。他实际上是java.lang.Throwable的对象

   1   String getMessage() 返回描述异常的消息 
   2   String toString() 返回关于异常的简短描述消息 
   3   void printStackTrace() 显示异常及其栈轨迹 
   4   Throwable FillInStackTrace() 重写异常的执行栈轨迹 

8. pageContext对象

   pageContext对象提供了对JSP页面内所有的对象及名字空间的访问，也就是说他可以访问到本页所在的SESSION，也可以取本页面所在的application的某一属性值，他相当于页面中所有功能的集大成者，它的本类名也叫pageContext。

   1   JspWriter getOut() 返回当前客户端响应被使用的JspWriter流(out) 
   2   HttpSession getSession() 返回当前页中的HttpSession对象(session) 
   3   Object getPage() 返回当前页的Object对象(page) 
   4   ServletRequest getRequest() 返回当前页的ServletRequest对象(request) 
   5   ServletResponse getResponse() 返回当前页的ServletResponse对象(response) 
   6   Exception getException() 返回当前页的Exception对象(exception) 
   7   ServletConfig getServletConfig() 返回当前页的ServletConfig对象(config) 
   8   ServletContext getServletContext() 返回当前页的ServletContext对象(application) 
   9   void setAttribute(String name,Object attribute) 设置属性及属性值 
   10   void setAttribute(String name,Object obj,int scope) 在指定范围内设置属性及属性值 
   11   public Object getAttribute(String name) 取属性的值 
   12   Object getAttribute(String name,int scope) 在指定范围内取属性的值 
   13   public Object findAttribute(String name) 寻找一属性,返回其属性值或NULL 
   14   void removeAttribute(String name) 删除某属性 
   15   void removeAttribute(String name,int scope) 在指定范围删除某属性 
   16   int getAttributeScope(String name) 返回某属性的作用范围 
   17   Enumeration getAttributeNamesInScope(int scope) 返回指定范围内可用的属性名枚举 
   18   void release() 释放pageContext所占用的资源 
   19   void forward(String relativeUrlPath) 使当前页面重导到另一页面 
   20   void include(String relativeUrlPath) 在当前位置包含另一文件 

9. config对象

    config对象是在一个Servlet初始化时，JSP引擎向它传递信息用的，此信息包括Servlet初始化时所要用到的参数（通过属性名和属性值构成）以及服务器的有关信息（通过传递一个ServletContext对象）

   1   ServletContext getServletContext() 返回含有服务器相关信息的ServletContext对象 
   2   String getInitParameter(String name) 返回初始化参数的值 
   3   Enumeration getInitParameterNames() 返回Servlet初始化所需所有参数的枚举 

#### Get和Post的区别

1. get是从服务器上获取数据，post是向服务器传送数据。 
2. get是把参数数据队列加到提交表单的ACTION属性所指的URL中，值和表单内各个字段一一对应，在URL中可以看到。post是通过HTTP post机制，将表单内各个字段与其内容放置在HTML HEADER内一起传送到ACTION属性所指的URL地址。用户看不到这个过程。 
3. 对于get方式，服务器端用Request.QueryString获取变量的值，对于post方式，服务器端用Request.Form获取提交的数据

> GET后退按钮/刷新无害，POST数据会被重新提交（浏览器应该告知用户数据会被重新提交）。
> GET书签可收藏，POST为书签不可收藏。
> GET能被缓存，POST不能缓存 。
> GET编码类型application/x-www-form-url，POST编码类型encodedapplication/x-www-form-urlencoded 或 multipart/form-data。为二进制数据使用多重编码。
> GET历史参数保留在浏览器历史中。POST参数不会保存在浏览器历史中。
> GET对数据长度有限制，当发送数据时，GET 方法向 URL 添加数据；URL 的长度是受限制的（URL 的最大长度是 2048 个字符）。POST无限制。
> GET只允许 ASCII 字符。POST没有限制。也允许二进制数据。
> 与 POST 相比，GET 的安全性较差，因为所发送的数据是 URL 的一部分。在发送密码或其他敏感信息时绝不要使用 GET ！POST 比 GET 更安全，因为参数不会被保存在浏览器历史或 web 服务器日志中。
> GET的数据在 URL 中对所有人都是可见的。POST的数据不会显示在 URL 中

**重大区别** 

GET产生一个TCP数据包；POST产生两个TCP数据包。

对于GET方式的请求，浏览器会把http header和data一并发送出去，服务器响应200（返回数据）； 而对于POST，浏览器先发送header，服务器响应100 continue，浏览器再发送data，服务器响应200 ok（返回数据）。

GET的语义是请求获取指定的资源。GET方法是安全、幂等、可缓存的（除非有 Cache-ControlHeader的约束）,GET方法的报文主体没有任何语义。

POST的语义是根据请求负荷（报文主体）对指定的资源做出处理，具体的处理方式视资源类型而不同。POST不安全，不幂等，（大部分实现）不可缓存。

#### 转发和重定向的区别

**调用方式** 

- servlet

```
request.getRequestDispatcher("new.jsp").forward(request, response);   //转发到new.jsp
response.sendRedirect("new.jsp");   //重定向到new.jsp
```

- Jsp

```
<jsp:forward page="apage.jsp" />   //转发
<%response.sendRedirect("new.jsp"); %> //重定向到new.jsp
```

**本质**： 

转发是服务器行为，重定向是客户端行为

> 转发过程：客户浏览器发送http请求——》web服务器接受此请求——》调用内部的一个方法在容器内部完成请求处理和转发动作——》将目标资源发送给客户；在这里，转发的路径必须是同一个web容器下的url，其不能转向到其他的web路径上去，中间传递的是自己的容器内的request。在客户浏览器路径栏显示的仍然是其第一次访问的路径，也就是说客户是感觉不到服务器做了转发的。转发行为是浏览器只做了一次访问请求。
>
> 请求转发是服务器内部把对一个request/response的处理权，移交给另外一个
>
> 对于客户端而言，它只知道自己最早请求的那个A，而不知道中间的B，甚至C、D。传输的信息不会丢失。

> 重定向过程：客户浏览器发送http请求——》web服务器接受后发送302状态码响应及对应新的location给客户浏览器——》客户浏览器发现是302响应，则**自动**再发送一个新的http请求，请求url是新的location地址——》服务器根据此请求寻找资源并发送给客户。在这里location可以重定向到任意URL，既然是浏览器重新发出了请求，则就没有什么request传递的概念了。在客户浏览器路径栏显示的是其重定向的路径，客户可以观察到地址的变化的。重定向行为是浏览器做了至少两次的访问请求的。
>
> 重定向，其实是两次request
>
> 第一次，客户端request   A,服务器响应，并response回来，告诉浏览器，你应该去B。这个时候IE可以看到地址变了，而且历史的回退按钮也亮了。重定向可以访问自己web应用以外的资源。在重定向的过程中，传输的信息会被丢失。

**区别**：

- 重定向时浏览器的网址改变，转发是浏览器上的网址不变
- 重定向实际上产生了两次请求，转发只有一次请求
- 重定向时的网址可以是任何网址，转发的网址必须是本站点的网址
- 重定向：以前的request中存放的变量全部失效，并进入一个新的request作用域。转发：以前的request中存放的变量不会失效，就像把两个页面拼到了一起。


#### servlet/filter/listener/interceptor区别与联系

##### servlet

servlet是一种运行服务器端的java应用程序，具有独立于平台和协议的特性，并且可以动态的生成web页面，它工作在客户端请求与服务器响应的中间层。最早支持 Servlet 技术的是 JavaSoft 的 Java Web Server。此后，一些其它的基于 Java 的 Web Server 开始支持标准的 Servlet API。Servlet 的主要功能在于交互式地浏览和修改数据，生成动态 Web 内容。这个过程为：

- 客户端发送请求至服务器端；
- 服务器将请求信息发送至 Servlet；
- Servlet 生成响应内容并将其传给服务器。响应内容动态生成，通常取决于客户端的请求；
- 服务器将响应返回给客户端

![](https://images0.cnblogs.com/blog/150046/201501/072114581714750.png)

在 Web 应用程序中，一个 Servlet 在一个时刻可能被多个用户同时访问。这时 Web 容器将为每个用户创建一个线程来执行 Servlet。如果 Servlet 不涉及共享资源的问题，不必关心多线程问题。但如果 Servlet 需要共享资源，需要保证 Servlet 是线程安全的。

**servlet职责**

- 创建并返回一个包含基于客户请求性质的动态内容的完整的html页面；
- 创建可嵌入到现有的html页面中的一部分html页面（html片段）；
- 读取客户端发来的隐藏数据；
- 读取客户端发来的显示数据；
- 与其他服务器资源（包括数据库和java的应用程序）进行通信；
- 通过状态代码和响应头向客户端发送隐藏数据。

##### filter

filter是一个可以复用的代码片段，可以用来转换HTTP请求、响应和头信息。Filter不像Servlet，它不能产生一个请求或者响应，它只是修改对某一资源的请求，或者修改从某一的响应。Servlet中的过滤器Filter是实现了javax.servlet.Filter接口的服务器端程序，主要的用途是过滤字符编码、做一些业务逻辑判断等。

> 其工作原理是，只要你在web.xml文件配置好要拦截的客户端请求，它都会帮你拦截到请求，此时你就可以对请求或响应(Request、Response)统一设置编码，简化操作；同时还可进行逻辑判断，如用户是否已经登陆、有没有权限访问该页面等等工作。它是随你的web应用启动而启动的，只初始化一次，以后就可以拦截相关请求，只有当你的web应用停止或重新部署的时候才销毁。Filter可认为是Servlet的一种“变种”，它主要用于对用户请求进行预处理，也可以对HttpServletResponse进行后处理，是个典型的处理链。

它与Servlet的区别在于：它不能直接向用户生成响应。完整的流程是：Filter对用户请求进行预处理，接着将请求交给Servlet进行处理并生成响应，最后Filter再对服务器响应进行后处理。

Filter的应用：

- 在HttpServletRequest到达Servlet之前，拦截客户的HttpServletRequest。
- 根据需要检查HttpServletRequest，也可以修改HttpServletRequest头和数据。
- 在HttpServletResponse到达客户端之前，拦截HttpServletResponse。
- 根据需要检查HttpServletResponse，也可以修改HttpServletResponse头和数据。

![](https://images0.cnblogs.com/blog/150046/201501/072115001257420.png)

Filter有如下几个种类：

- 用户授权的Filter：Filter负责检查用户请求，根据请求过滤用户非法请求。
- 日志Filter：详细记录某些特殊的用户请求。
- 负责解码的Filter：包括对非标准编码的请求解码。
- 能改变XML内容的XSLT Filter等。
- Filter可负责拦截多个请求或响应；一个请求或响应也可被多个filter拦截。

创建一个Filter只需两个步骤：

- 建Filter处理类；
- web.xml文件中配置Filter。

**filter职责**

- filter能够在一个请求到达servlet之前预处理用户请求，也可以在离开servlet时处理http响应
- 在执行servlet之前，首先执行filter程序，并为之做一些预处理工作
- 根据程序需要修改请求和响应
- 在servlet被调用之后截获servlet的执行

##### listener

监听器，从字面上可以看出listener主要用来监听只用。通过listener可以监听web服务器中某一个执行动作，并根据其要求作出相应的响应。通俗的语言说就是在application，session，request三个对象创建消亡或者往其中添加修改删除属性时自动执行代码的功能组件。比如spring 的总监听器 会在服务器启动的时候实例化我们配置的bean对象 、 hibernate 的 session 的监听器会监听session的活动和生命周期，负责创建，关闭session等活动。

![](https://images0.cnblogs.com/blog/150046/201501/072115013901934.png)

Servlet的监听器Listener，它是实现了javax.servlet.ServletContextListener 接口的服务器端程序，它也是随web应用的启动而启动，只初始化一次，随web应用的停止而销毁。主要作用是： 做一些初始化的内容添加工作、设置一些基本的内容、比如一些参数或者是一些固定的对象等等。

listener接口，可以将其分为三类，分别如下：

- 与servletContext有关的listner接口。包括：ServletContextListener、ServletContextAttributeListener
- 与HttpSession有关的Listner接口。包括：HttpSessionListner、HttpSessionAttributeListener、HttpSessionBindingListener、                      HttpSessionActivationListener；
- 与ServletRequest有关的Listener接口，包括：ServletRequestListner、ServletRequestAttributeListener

##### interceptor

是在面向切面编程的，就是在你的service或者一个方法，前调用一个方法，或者在方法后调用一个方法，是基于JAVA的反射机制。比如动态代理就是拦截器的简单实现，在你调用方法前打印出字符串（或者做其它业务逻辑的操作），也可以在你调用方法后打印出字符串，甚至在你抛出异常的时候做业务逻辑的操作。

![](https://images0.cnblogs.com/blog/150046/201501/072115027818176.png)

>   servlet、filter、listener是配置到web.xml中（web.xml 的加载顺序是：context-param -> listener -> filter -> servlet ），interceptor不配置到web.xml中，struts的拦截器配置到struts.xml中。spring的拦截器配置到spring.xml中。 

职责与过滤器十分相似，通过层层拦截，处理用户的请求和响应。

##### 四者区别

1. servlet 流程是短的，url传来之后，就对其进行处理，之后返回或转向到某一自己指定的页面。它主要用来在 业务处理之前进行控制.

2. filter 流程是线性的， url传来之后，检查之后，可保持原来的流程继续向下执行，被下一个filter, servlet接收等，而servlet 处理之后，不会继续向下传递。filter功能可用来保持流程继续按照原来的方式进行下去，或者主导流程，而servlet的功能主要用来主导流程。

     filter可用来进行字符编码的过滤，检测用户是否登陆的过滤，禁止页面缓存等

3. servlet,filter都是针对url之类的，而listener是针对对象的操作的，如session的创建，session.setAttribute的发生，在这样的事件发生时做一些事情。 可用来进行：Spring整合Struts,为Struts的action注入属性，web应用定时任务的实现，在线人数的统计等

4. interceptor 拦截器，类似于filter,不过在struts.xml中配置，不是在web.xml,并且不是针对URL的，而是针对action,当页面提交action时，进行过滤操作，相当于struts1.x提供的plug-in机制，可以看作，前者是struts1.x自带的filter,而interceptor 是struts2 提供的filter.

   与filter不同点：

   - 不在web.xml中配置，而是在struts.xml中完成配置，与action在一起
   - 可由action自己指定用哪个interceptor 来在接收之前做事    

5. struts2中的过滤器和拦截器的区别与联系：

   - 拦截器是基于java反射机制的，而过滤器是基于函数回调的。
   - 过滤器依赖与servlet容器，而拦截器不依赖与servlet容器。
   - 拦截器只能对Action请求起作用，而过滤器则可以对几乎所有请求起作用。
   - 拦截器可以访问Action上下文、值栈里的对象，而过滤器不能。
   - 在Action的生命周期中，拦截器可以多次调用，而过滤器只能在容器初始化时被调用一次。

#### servlet/filter/listener/interceptor的生命周期

##### servlet生命周期

1. 装入：启动服务器时加载Servlet的实例； 
2. 初始化：web服务器启动时或web服务器接收到请求时，或者两者之间的某个时刻启动。初始化工作有init（）方法负责执行完成； 
3. 调用：从第一次到以后的多次访问，都是只调用doGet()或doPost()方法； 
4. 销毁：停止服务器时调用destroy()方法，销毁实例。 

##### filter生命周期

1. 启动服务器时加载过滤器的实例，并调用init()方法来初始化实例； 
2. 每一次请求时都只调用方法doFilter()进行处理； 
3. 停止服务器时调用destroy()方法，销毁实例。

##### listener生命周期

Servlet的监听器Listener，它是实现了javax.servlet.ServletContextListener 接口的服务器端程序，它也是随web应用的启动而启动，只初始化一次，随web应用的停止而销毁。

 web.xml 的加载顺序是：context- param -> listener -> filter -> servlet 

##### interceptor生命周期

以struts的拦截器为例，加载了struts.xml以后，初始化相应拦截器。当action请求来时调用intercept方法，服务器停止销毁interceptor。




## SQL

#### 如何让sql使用指定的索引

select * from tabel with(指定索引名)

或  select * from tabel with(INDEX =指定索引名)

#### 位图索引

**位图索引**是一种使用[位图](https://baike.so.com/doc/630856-667651.html)的特殊数据库索引。

主要针对大量相同值的列而创建(例如:类别，操作员，部门ID,库房ID等),索引块的一个索引行中存储键值和起止Rowid,以及这些键值的位置编码,

位置编码中的每一位表示键值对应的数据行的有无.一个块可能指向的是几十甚至成百上千行数据的位置.这种方式存储数据,相对于B*Tree索引,占用的空间非常小,创建和使用非常快.

当根据键值查询时,可以根据起始Rowid和位图状态,快速定位数据.

当根据键值做and,or或 in(x,y,..)查询时,直接用索引的位图进行或运算,快速得出结果行数据.

当select count(XX) 时,可以直接访问索引就快速得出统计数据.

```
创建语法
create bitmap index ssex_bitmap_index on zhou.student(ssex) 
tablespace MYSPACE; 
```

##### 位图索引的优势和不适合使用的场景

优势：

1. 位图索引使用于低基数的列，相对于B树索引，它的count,and,or操作更有效
2. 位图索引存放的是0,1的比特位，相对于B树索引，占字节数特别少?

不适用场景：

1. 列的基数比较多，不适合位图索引，因为它会占用更多的存储空间
2. 索引列DML频繁的列，不适合位图索引，容易造成死锁?

#### 索引的作用？它的优点缺点是什么？

索引就一种特殊的查询表，数据库的搜索可以利用它加速对数据的检索。索引可以是唯一的，创建索引允许指定单个列或者是多个列。缺点是它减慢了数据录入的速度，同时也增加了数据库的尺寸大小。一般唯一、不为空、经常被查询的字段适合建索引

MySQL数据库几个基本的索引类型：普通索引、唯一索引、主键索引、全文索引

**优点：** 

- 通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性
- 可以大大加快数据的检索速度，这也是创建索引的最主要的原因
- 可以加速表和表之间的连接，特别是在实现数据的参考完整性方面特别有意义
- 在使用分组和排序子句进行数据检索时，同样可以显著减少查询中分组和排序的时间
- 通过使用索引，可以在查询的过程中，使用优化隐藏器，提高系统的性能

**缺点：** 

- 创建索引和维护索引要耗费时间，这种时间随着数据量的增加而增加
- 索引需要占物理空间，除了数据表占数据空间之外，每一个索引还要占一定的物理空间，如果要建立聚簇索引，那么需要的空间就会更大
- 当对表中的数据进行增加、删除和修改的时候，索引也要动态的维护，这样就降低了数据的维护速度

#### 什么样的字段适合建索引？

- 总的来说就是数据量大的，经常进行查询操作的表要建立索引
- 表中字段建立索引应该遵循几个原则：
  1. 越小的数据类型通常更好：越小的数据类型通常在磁盘、内存中都需要更少的空间，处理起来更快
  2. 简单的数据类型更好：整型数据比起字符，处理开销更小，因为字符串的比较更复杂，处理起来也更耗时
  3. 尽量避免NULL：应该指定列为NOT NULL。含有空值的列很难进行查询优化，因为它们使得索引、索引的统计信息以及比较运算更加复杂。你应该用0、一个特殊的值或者一个空串代替空值
  4. 索引的建立应当更多的选取唯一性更高的字段
- 表与表连接用于多表联合查询的约束条件的字段应当建立索引
- 用于排序的字段可以添加索引，用于分组的字段应当视情况看是否需要添加索引
- 添加多列索引的时候，对应的多条件查询可以触发该索引的同时，索引最左侧的列的单条件查询也可以触发
- 如果有些表注定只会进行查询所有，也就没必要添加索引，因为查询全部只能进行全量搜索即扫描全表

##### 不应该创建索引的的这些列具有下列特点:

1. 对于那些在查询中很少使用或者参考的列不应该创建索引。这是因为，既然这些列很少使用到，因此有索引或者无索引，并不能提高查询速度。相反，由于增加了索引，反而降低了系统的维护速度和增大了空间需求。 
2. 对于那些只有很少数据值的列也不应该增加索引。这是因为，由于这些列的取值很少，例如人事表的性别列，在查询的结果中，结果集的数据行占了表中数据行的很大比例，即需要在表中搜索的数据行的比例很大。增加索引，并不能明显加快检索速度。 
3. 对于那些定义为text, image和bit数据类型的列不应该增加索引。这是因为，这些列的数据量要么相当大，要么取值很少。 
4. 当修改性能远远大于检索性能时，不应该创建索引。这是因为，修改性能和检索性能是互相矛盾的。当增加索引时，会提高检索性能，但是会降低修改性能。当减少索引时，会提高修改性能，降低检索性能。因此，当修改性能远远大于检索性能时，不应该创建索引。

#### 创建索引的方法和索引的特征

创建索引有多种方法，这些方法包括直接创建索引的方法和间接创建索引的方法。直接创建索引，例如使用CREATE INDEX语句或者使用创建索引向导，间接创建索引，例如在表中定义主键约束或者唯一性键约束时，同时也创建了索引。虽然，这两种方法都可以创建索引，但 是，它们创建索引的具体内容是有区别的。 

> 使用CREATE INDEX语句或者使用创建索引向导来创建索引，这是最基本的索引创建方式，并且这种方法最具有柔性，可以定制创建出符合自己需要的索引。在使用这种方式 创建索引时，可以使用许多选项，例如指定数据页的充满度、进行排序、整理统计信息等，这样可以优化索引。使用这种方法，可以指定索引的类型、唯一性和复合 性，也就是说，既可以创建聚簇索引，也可以创建非聚簇索引，既可以在一个列上创建索引，也可以在两个或者两个以上的列上创建索引。 

> 通过定义主键约束或者唯一性键约束，也可以间接创建索引。主键约束是一种保持数据完整性的逻辑，它限制表中的记录有相同的主键记录。在创建主键约束时，系 统自动创建了一个唯一性的聚簇索引。虽然，在逻辑上，主键约束是一种重要的结构，但是，在物理结构上，与主键约束相对应的结构是唯一性的聚簇索引。换句话说，在物理实现上，不存在主键约束，而只存在唯一性的聚簇索引。同样，在创建唯一性键约束时，也同时创建了索引，这种索引则是唯一性的非聚簇索引。因此，当使用约束创建索引时，索引的类型和特征基本上都已经确定了，由用户定制的余地比较小。 

主键约束或者唯一性键约束创建的索引的优先级高于使用CREATE INDEX语句创建的索引。 

**索引有两个特征，即唯一性索引和复合索引**

> 唯一性索引保证在索引列中的全部数据是唯一的，不会包含冗余数据。如果表中已经有一个主键约束或者唯一性键约束，那么当创建表或者修改表时，SQL Server自动创建一个唯一性索引。然而，如果必须保证唯一性，那么应该创建主键约束或者唯一性键约束，而不是创建一个唯一性索引。当创建唯一性索引 时，应该认真考虑这些规则：当在表中创建主键约束或者唯一性键约束时，SQL Server自动创建一个唯一性索引；如果表中已经包含有数据，那么当创建索引时，SQL Server检查表中已有数据的冗余性；每当使用插入语句插入数据或者使用修改语句修改数据时，SQL Server检查数据的冗余性：如果有冗余值，那么SQL Server取消该语句的执行，并且返回一个错误消息；确保表中的每一行数据都有一个唯一值，这样可以确保每一个实体都可以唯一确认；只能在可以保证实体 完整性的列上创建唯一性索引，例如，不能在人事表中的姓名列上创建唯一性索引，因为人们可以有相同的姓名。 

> 复合索引就是一个索引创建在两个列或者多个列上。在搜索时，当两个或者多个列作为一个关键值时，最好在这些列上创建复合索引。当创建复合索引时，应该考虑 这些规则：最多可以把16个列合并成一个单独的复合索引，构成复合索引的列的总长度不能超过900字节，也就是说复合列的长度不能太长；在复合索引中，所 有的列必须来自同一个表中，不能跨表建立复合列；在复合索引中，列的排列顺序是非常重要的，因此要认真排列列的顺序，原则上，应该首先定义最唯一的列，例 如在（COL1，COL2）上的索引与在（COL2，COL1）上的索引是不相同的，因为两个索引的列的顺序不同；为了使查询优化器使用复合索引，查询语 句中的WHERE子句必须参考复合索引中第一个列；当表中有多个关键列时，复合索引是非常有用的；使用复合索引可以提高查询性能，减少在一个表中所创建的索引数量。

#### 使用索引查询一定能提高查询的性能吗？为什么？

1. 表存储量，超过百万，查询效率会明显降低。
2. 索引类型。虽然增加索引可以增加查询效率，可是过多，会略影响性能，而且索引字段的类型，也影响查询性能，int性能是最好的，字符类型的索引查询性能略差
3. 表存储类型影响性能，有innodb myisam 等类型

#### mysql的三大引擎是啥？

简单来说，存储引擎就是指**表的类型以及表在计算机上的存储方式**。

存储引擎的概念是MySQL的特点，Oracle中没有专门的存储引擎的概念，Oracle有OLTP和OLAP模式的区分。不同的存储引擎决定了MySQL数据库中的表可以用不同的方式来存储。我们可以根据数据的特点来选择不同的存储引擎。

在MySQL中的存储引擎有很多种，可以通过“SHOW ENGINES”语句来查看。主要由InnoDB、MyISAM、MEMORY这三种。

- MYISAM ： 全表锁，拥有较高的执行速度，一个写请求请阻塞另外相同表格的所有读写请求，并发性能差，占用空间相对较小，mysql 5.5 及以下仅 MYISAM 支持全文索引，不支持事务。
- Innodb ： 行级锁（SQL 都走索引查询），并发能力相对强，占用空间是 MYISAM 的 2.5 倍，不支持全文索引（5.6 开始支持），支持事务。
- Memory ： 全表锁，存储在内存当中，速度快，但会占用和数据量成正比的内存空间且数据在 mysql 重启时会丢失。

[参考](http://www.cnblogs.com/yuxiuyan/p/6511837.html)

#### 索引类型有哪些？

逻辑上：

- Single column 单行索引
- Concatenated 多行索引
- Unique 唯一索引
- NonUnique 非唯一索引
- Function-based 函数索引
- Domain 域索引

物理上：

- Partitioned 分区索引
- NonPartitioned 非分区索引

B-tree:

- Normal 正常型B树
- Rever Key 反转型B树
- Bitmap 位图索引

##### Mysql数据库索引类型

mysql 有四种不同的索引类型：

- 主键索引 ( PRIMARY )
- 唯一索引 ( UNIQUE )
- 普通索引 ( INDEX )
- 全文索引（FULLTEXT , MYISAM 及 mysql 5.6 以上的 Innodb ）

建立索引的目的是加快对表中记录的查找或排序，索引也并非越多越好，因为创建索引是要付出代价的：一是增加了数据库的存储空间，二是在插入和修改数据时要花费较多的时间维护索引。

#### 索引的原理，索引底层用什么实现的?

索引的原理大致概括为以空间换时间，数据库在未添加索引的时候进行查询默认的是进行全量搜索，也就是进行全局扫描，有多少条数据就要进行多少次查询，然后找到相匹配的数据就把他放到结果集中，直到全表扫描完。而建立索引之后，会将建立索引的KEY值放在一个n叉树上(BTree)。因为B树的特点就是适合在磁盘等直接存储设备上组织动态查找表，每次以索引进行条件查询时，会去树上根据key值直接进行搜索，次数约为log总条数，底数为页面存储数，例如一个100万数据的表，页面存储数为100，那么有索引的查询次数为3次log1000000100，但是全量搜索为100万次搜索，这种方式类似于二分法，但是这个是n分法。

MySQL支持多种索引类型，如BTree索引，哈希索引，全文索引等待

MySQL官方对索引的定义为：索引（Index）是帮助MySQL高效获取数据的数据结构。提取句子主干，就可以得到索引的本质：索引是数据结构。

索引的实现通常使用B树及其变种B+树。

原理：通过不断的缩小想要获得数据的范围来筛选出最终想要的结果，同时把随机的事件变成顺序的事件，也就是我们总是通过同一种查找方式来锁定数据。

> B树事实上是一种平衡的多叉查找树，也就是说最多可以开m个叉（m>=2）
>
> m阶B树满足以下条件：
>
> - 每个节点至多可以拥有m棵子树。
> - 根节点，只有至少有2个节点（要么极端情况，就是一棵树就一个根节点，单细胞生物，即是根，也是叶，也是树)。
> - 非根非叶的节点至少有的Ceil(m/2)个子树(Ceil表示向上取整)。
> - 非叶节点中的信息包括[n,A0,K1,A1,K2,A2,…,Kn,An]，，其中n表示该节点中保存的关键字个数，K为关键字且Ki<Ki+1，A为指向子树根节点的指针。
> - 从根到叶子的每一条路径都有相同的长度，也就是说，叶子节在相同的层，并且这些节点不带信息，实际上这些节点就表示找不到指定的值，也就是指向这些节点的指针为空。
>
> B树的特点
>
> - 关键字集合分布在整颗树中。
> - 任何一个关键字出现且只出现在一个节点中。
> - 搜索有可能在非叶子节点结束。
> - 其搜索性能等价于在关键字集合内做一次二分查找。
> - B树在插入删除新的数据记录会破坏B-Tree的性质，因为在插入删除时，需要对树进行一个分裂、合并、转移等操作以保持B-Tree性质。

> 作为B树的加强版，B+树与B树的差异在于:
>
> - 有n棵子树的节点含有n个关键字（也有认为是n-1个关键字）。
> - 所有的关键字全部存储在叶子节点上，且叶子节点本身根据关键字自小而大顺序连接。
> - 非叶子节点可以看成索引部分，节点中仅含有其子树（根节点）中的最大（或最小）关键字。
>
> B+树的查找过程，与B树类似，只不过查找时，如果在非叶子节点上的关键字等于给定值，并不终止，而是继续沿着指针直到叶子节点位置。因此在B+树，不管查找成功与否，每次查找都是走了一条从根到叶子节点的路径。
>
> B+树的特性如下：
>
> - 所有关键字都存储在叶子节上，且链表中的关键字恰好是有序的。
> - 不可能非叶子节点命中返回。
> - 非叶子节点相当于叶子节点的索引，叶子节点相当于是存储（关键字）数据的数据层。
> - 更适合文件索引系统。
>
> 一般在数据库系统或文件系统中使用的B+Tree结构都在经典B+Tree的基础上进行了优化，增加了顺序访问指针。做这个优化的目的是为了提高区间访问的性能.

##### MySQL为什么使用B树（B+树）

一般来说，索引本身也很大，不可能全部存储在内存中，因此索引往往以索引文件的形式存储在磁盘上。这样的话，索引查找过程中就要产生磁盘I/O消耗，相对于内存存取，I/O存取的消耗要高几个数量级，所以评价一个数据结构作为索引的优劣最重要的指标就是在查找过程中磁盘I/O操作次数的渐进复杂度。换句话说，索引的结构组织要尽量减少查找过程中磁盘I/O的存取次数。

在MySQL中，索引属于存储引擎级别的概念，不同存储引擎对索引的实现方式是不同的.

MyISAM引擎使用B+Tree作为索引结构，叶节点的data域存放的是数据记录的地址。

**在MySQL中，索引属于存储引擎级别的概念，不同存储引擎对索引的实现方式是不同的：**

MyISAM引擎使用B+Tree作为索引结构，叶节点的data域存放的是数据记录的地址。MyISAM的索引方式也叫做“非聚集”的，之所以这么称呼是为了与InnoDB的聚集索引区分。

虽然InnoDB也使用B+Tree作为索引结构，但具体实现方式却与MyISAM截然不同。第一个重大区别是InnoDB的数据文件本身就是索引文件。从上文知道，MyISAM索引文件和数据文件是分离的，索引文件仅保存数据记录的地址。而在InnoDB中，表数据文件本身就是按B+Tree组织的一个索引结构，这棵树的叶节点data域保存了完整的数据记录。这个索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引。第二个与MyISAM索引的不同是InnoDB的辅助索引data域存储相应记录主键的值而不是地址。换句话说，InnoDB的所有辅助索引都引用主键作为data域。

#### 在数据库中查询语句速度很慢，如何优化？

1. 建索引
2. 减少表之间的关联 
3. 优化sql，尽量让sql很快定位数据，不要让sql做全表查询，应该走索引,把数据 量大的表排在前面
4. 简化查询字段，没用的字段不要，已经对返回结果的控制，尽量返回少量数据
5. 尽量用PreparedStatement来查询，不要用Statement

#### 什么是存储过程？有哪些优缺点？

存储过程是一个预编译的SQL语句，优点是允许模块化的设计，就是说只需创建一次，以后在该程序中就可以调用多次。如果某次操作需要执行多次SQL，使用存储过程比单纯SQL语句执行要快。 调用： 1）可以用一个命令对象来调用存储过程。 2）可以供外部程序调用，比如：java程序。

**优点**

- 存储过程是预编译过的，执行效率高。 
- 存储过程的代码直接存放于数据库中，通过存储过程名直接调用，减少网络通讯。 
- 安全性高，执行存储过程需要有一定权限的用户。
- 存储过程可以重复使用，可减少数据库开发人员的工作量。

**缺点**

- 移植性差

##### 存储过程与函数的区别

| 存储过程                        | 函数                                       |
| :-------------------------- | :--------------------------------------- |
| 用于在数据库中完成特定的操作或者任务（如插入、删除等） | 用于特点的数据（如选择）                             |
| 程序头部声明用procedure            | 程序头部声明用function                          |
| 程序头部声明时不需描述返回类型             | 程序头部声明时要描述返回类型，二期PL/SQL至少要包括一个有效的return语句 |
| 可以使用in/out/in out 三种模式的参数   | 可以使用in/out/in out 三种模式的参数                |
| 可作为一个独立的PL/SQL语句来执行         | 不能独立执行，必须作为表达式的一部分调用                     |
| 可以通过out/in out返回零个或多个值      | 通过return语句返回一个值，且该值要与声明部分一致，也可以是通过out类型的参数带出的变量 |
| SQL语句（DML或SELECT）中不可调用存储过程  | SQL语句（DML或SELECT）中可以调用存储过程               |

#### 什么是触发器？

触发器是一种特殊的存储过程，主要是通过事件来触发而被执行的。它可以强化约束，来维护数据的完整性和一致性，可以跟踪数据库内的操作从而不允许未经许可的更新和变化。可以联级运算。如，某表上的触发器上包含对另一个表的数据操作，而该操作又会导致该表触发器被触发。

#### 什么是事务？

事务就是被绑定在一起作为一个逻辑工作单元的SQL语句分组，如果任何一个语句操作失败那么整个操作就被失败，以后操作就会回滚到操作前状态，或者是上有个节点。为了确保要么执行，要么不执行，就可以使用事务。要将有组语句作为事务考虑，就需要通过ACID测试，即原子性，一致性，隔离性和持久性。

#### 脏读、不可重复读、幻读的区别

##### **spring（数据库）事务隔离级别分为四种（级别递减）：**

- **Serializable （串行化）**：最严格的级别，事务串行执行，资源消耗最大；
- **REPEATABLE READ（重复读） **：保证了一个事务不会修改已经由另一个事务读取但未提交（回滚）的数据。避免了“脏读取”和“不可重复读取”的情况，但不能避免“[幻读](https://www.baidu.com/s?wd=%E5%B9%BB%E8%AF%BB&tn=24004469_oem_dg&rsv_dl=gh_pl_sl_csd)”，但是带来了更多的性能损失。
- **READ COMMITTED （提交读）**：大多数主流数据库的默认事务等级，保证了一个事务不会读到另一个并行事务已修改但未提交的数据，避免了“脏读取”，但不能避免“幻读”和“不可重复读取”。该级别适用于大多数系统。
- **Read Uncommitted（未提交读） **：事务中的修改，即使没有提交，其他事务也可以看得到，会导致“脏读”、“幻读”和“不可重复读取”。

**脏读：**所谓的脏读，其实就是读到了别的事务回滚前的脏数据。比如事务B执行过程中修改了数据X，在未提交前，事务A读取了X，而事务B却回滚了，这样事务A就形成了脏读。

也就是说，当前事务读到的数据是别的事务想要修改成为的但是没有修改成功的数据。

**不可重复读：**事务A首先读取了一条数据，然后执行逻辑的时候，事务B将这条数据改变了，然后事务A再次读取的时候，发现数据不匹配了，就是所谓的不可重复读了。

也就是说，当前事务先进行了一次数据读取，然后再次读取到的数据是别的事务修改成功的数据，导致两次读取到的数据不匹配，也就照应了不可重复读的语义。

**幻读：**事务A首先根据条件索引得到N条数据，然后事务B改变了这N条数据之外的M条或者增添了M条符合事务A搜索条件的数据，导致事务A再次搜索发现有N+M条数据了，就产生了幻读。

也就是说，当前事务读第一次取到的数据比后来读取到数据条目少。

> 不可重复读和幻读两者有些相似，但是前者针对的是update或delete，后者针对的insert。

#### 什么是锁？

锁：在所以的DBMS中，锁是实现事务的关键，锁可以保证事务的完整性和并发性。与现实生活中锁一样，它可以使某些数据的拥有者，在某段时间内不能使用某些数据或数据结构。当然锁还分级别的。

##### 乐观锁和悲观锁是什么？

###### 乐观锁

乐观并发控制（又名”乐观锁”，Optimistic Concurrency Control，缩写”OCC”）是一种并发控制的方法。它假设多用户并发的事务在处理时不会彼此互相影响，各事务能够在不产生锁的情况下处理各自影响的那部分数据。在提交数据更新之前，每个事务会先检查在该事务读取数据后，有没有其他事务又修改了该数据。如果其他事务有更新的话，正在提交的事务会进行回滚。

**乐观并发控制的阶段**

1. 读取：事务将数据读入缓存，这时系统会给事务分派一个时间戳。 
2. 校验：事务执行完毕后，进行提交。这时同步校验所有事务，如果事务所读取的数据在读取之后又被其他事务修改，则产生冲突，事务被中断回滚。 
3. 写入：通过校验阶段后，将更新的数据写入数据库。

> 乐观并发控制多数用于数据争用不大、冲突较少的环境中，这种环境中，偶尔回滚事务的成本会低于读取数据时锁定数据的成本，因此可以获得比其他并发控制方法更高的吞吐量。
>
> 相对于悲观锁，在对数据库进行处理的时候，乐观锁并不会使用数据库提供的锁机制。一般的实现乐观锁的方式就是记录数据版本。
>
> 数据版本,为数据增加的一个版本标识。当读取数据时，将版本标识的值一同读出，数据每更新一次，同时对版本标识进行更新。当我们提交更新的时候，判 断数据库表对应记录的当前版本信息与第一次取出来的版本标识进行比对，如果数据库表当前版本号与第一次取出来的版本标识值相等，则予以更新，否则认为是过 期数据。

**实现数据版本有两种方式，第一种是使用版本号，第二种是使用时间戳。**

- 使用版本号实现乐观锁

  *使用版本号时，可以在数据初始化时指定一个版本号，每次对数据的更新操作都对版本号执行+1操作。并判断当前版本号是不是该数据的最新的版本号。*

> 优势与不足
>
> 　　乐观并发控制相信事务之间的数据竞争(data race)的概率是比较小的，因此尽可能直接做下去，直到提交的时候才去锁定，所以不会产生任何锁和死锁。但如果直接简单这么做，还是有可能会遇到不可预 期的结果，例如两个事务都读取了数据库的某一行，经过修改以后写回数据库，这时就遇到了问题。

###### 悲观锁

在关系数据库管理系统里，悲观并发控制（又名”悲观锁”，Pessimistic Concurrency Control，缩写”PCC”）是一种并发控制的方法。它可以阻止一个事务以影响其他用户的方式来修改数据。如果一个事务执行的操作读某行数据应用了 锁，那只有当这个事务把锁释放，其他事务才能够执行与该锁冲突的操作。

> 悲观并发控制主要用于数据争用激烈的环境，以及发生并发冲突时使用锁保护数据的成本要低于回滚事务的成本的环境中。

MySQL InnoDB中使用悲观锁:

​	要使用悲观锁，我们必须关闭mysql数据库的自动提交属性，因为**MySQL默认使用autocommit模式**，也就是说，当你执行一个更新操作后，MySQL会立刻将结果进行提交。`set autocommit=0;`

**MySQL InnoDB默认行级锁**。**行级锁都是基于索引的，如果一条SQL语句用不到索引是不会使用行级锁的，会使用表级锁把整张表锁住，这点需要注意。** 

> 优势与不足
>
> ​	悲观并发控制实际上是”先取锁再访问”的保守策略，为数据处理的安全提供了保证。但是在效率方面，处理加锁的机制会让数据库产生额外的开销，还有增 加产生死锁的机会；另外，在只读型事务处理中由于不会产生冲突，也没必要使用锁，这样做只能增加系统负载；还有会降低了并行性，一个事务如果锁定了某行数 据，其他事务就必须等待该事务处理完才可以处理那行数

**乐观锁不是数据库自带的，需要我们自己去实现。悲观锁是由数据库自己实现了的。**

共享锁和排它锁是悲观锁的不同的实现，它俩都属于悲观锁的范畴。

###### 共享锁 

共享锁指的就是对于多个不同的事务，对同一个资源共享同一个锁。

通过在执行语句后面加上lock in share mode就代表对某些资源加上共享锁了。

###### 排他锁

排它锁与共享锁相对应，就是指对于多个不同的事务，对同一个资源只能有一把锁。

与共享锁类似，在需要执行的语句后面加上for update就可以了

###### 行锁

行锁，由字面意思理解，就是给某一行加上锁，也就是一条记录加上锁。

###### 表锁

表锁，和行锁相对应，给这个表加上锁。

#### 什么叫视图？游标是什么？

视图：是一种虚拟的表，具有和物理表相同的功能。可以对视图进行增，改，查，操作，试图通常是有一个表或者多个表的行或列的子集。对视图的修改会影响基本表。它使得我们获取数据更容易，相比多表查询。

游标：是对查询出来的结果集作为一个单元来有效的处理。游标可以定在该单元中的特定行，从结果集的当前行检索一行或多行。可以对结果集当前行做修改。一般不使用游标，但是需要逐条处理数据的时候，游标显得十分重要。

##### 视图的优缺点

优点:

1. 对数据库的访问，因为视图可以有选择性的选取数据库里的一部分。
2. 用户通过简单的查询可以从复杂查询中得到结果。
3. 维护数据的独立性，试图可从多个表检索数据。
4. 对于相同的数据可产生不同的视图。

缺点：

​    性能：查询视图时，必须把视图的查询转化成对基本表的查询，如果这个视图是由一个复杂的多表查询所定义，那么，那么就无法更改数据

#### 数据库三范式是什么?

- 第一范式：列不可再分
- 第二范式：行可以唯一区分，主键约束
- 第三范式：表的非主属性不能依赖与其他表的非主属性 外键约束

三大范式是一级一级依赖的，第二范式建立在第一范式上，第三范式建立第一第二范式上

#### 什么是sql注入？

所谓SQL注入式攻击，就是攻击者把SQL命令插入到Web表单的输入域或页面请求的查询字符串，**欺骗服务器执行恶意的SQL命令**。在某些表单中，用户输入的内容直接用来构造（或者影响）动态SQL命令，或作为存储过程的输入参数，这类表单特别容易受到SQL注入式攻击。

#### **如何防范SQL注入式攻击？**

1. 对于动态构造SQL查询的场合，可以使用下面的技术：
   - **替换单引号，即把所有单独出现的单引号改成两个单引号，防止攻击者修改SQL命令的含义**。
   - **删除用户输入内容中的所有连字符**
   - **对于用来执行查询的数据库帐户，限制其权限**。**用不同的用户帐户执行查询、插入、更新、删除操作**。
2. **用存储过程来执行所有的查询。**
3. **限制表单或查询字符串输入的长度**。
4. **检查用户输入的合法性**
5. **将用户登录名称、密码等数据加密保存**
6. **检查提取数据的查询所返回的记录数量。**

#### Oracle和Mysql的区别？

1. 库函数不同。
2. Oracle是用表空间来管理的，Mysql不是
3. 显示当前所有的表、用户、改变连接用户、显示当前连接用户、执行外部脚本的语句的不同。
4. 分页查询时候时候，mysql用limit oracle用rownum

#### 常见的sql优化

- 避免在where子句中使用 is null 或 is not null 对字段进行判断
- 避免在 where 子句中使用 != 或 <> 操作符
- 避免在 where 子句中使用 or来链接条件
- 少用 in 或 not in
- 注意 like 中通配符的使用
- 避免在 where 子句中对字段进行表达式操作
- 避免在 where 子句中对字段进行函数操作
- 在where语句或者order by 语句中避免对索引字段进行计算操作
- 在子查询中，用 exists 代替 in 是一个好的选择
- 通过变量的方式来设置参数
- 不要使用select *
- 不要使用列号
- 优先使用UNION ALL,避免使用UNION
- 复杂操作可以考虑适当拆成几步
- 在使用索引字段作为条件时，如果该索引是复合索引，那么必须使用到该索引中的第一个字段作为条件时才能保证系统使用该索引，否则该索引将不会被使用，并且应尽可能的让字段顺序与索引顺序相一致。 
- 索引并不是越多越好，索引固然可以提高相应的 select 的效率，但同时也降低了 insert 及 update 的效率，因为 insert 或 update 时有可能会重建索引，所以怎样建索引需要慎重考虑，视具体情况而定。一个表的索引数最好不要超过6个，若太多则应考虑一些不常使用到的列上建的索引是否有必要
- 应尽可能的避免更新 clustered 索引数据列，因为 clustered 索引数据列的顺序就是表记录的物理存储顺序，一旦该列值改变将导致整个表记录的顺序的调整，会耗费相当大的资源。若应用系统需要频繁更新 clustered 索引数据列，那么需要考虑是否应将该索引建为 clustered 索引。 
- 尽量使用数字型字段，若只含数值信息的字段尽量不要设计为字符型，这会降低查询和连接的性能，并会增加存储开销。这是因为引擎在处理查询和连接时会逐个比较字符串中每一个字符，而对于数字型而言只需要比较一次就够了。 
- 尽可能的使用 varchar/nvarchar 代替 char/nchar ，因为首先变长字段存储空间小，可以节省存储空间，其次对于查询来说，在一个相对较小的字段内搜索效率显然要高些。 
- 尽量使用表变量来代替临时表。如果表变量包含大量数据，请注意索引非常有限（只有主键索引）。
- 避免频繁创建和删除临时表，以减少系统表资源的消耗。 
- 如果使用到了临时表，在存储过程的最后务必将所有的临时表显式删除，先 truncate table ，然后 drop table ，这样可以避免系统表的较长时间锁定。 
- 尽量避免使用游标，因为游标的效率较差，如果游标操作的数据超过1万行，那么就应该考虑改写。 
- 使用基于游标的方法或临时表方法之前，应先寻找基于集的解决方案来解决问题，基于集的方法通常更有效。 
- 在所有的存储过程和触发器的开始处设置 SET NOCOUNT ON ，在结束时设置 SET NOCOUNT OFF 。无需在执行存储过程和触发器的每个语句后向客户端发送 DONE_IN_PROC 消息。 
- 尽量避免向客户端返回大数据量，若数据量过大，应该考虑相应需求是否合理。 
- 尽量避免大事务操作，提高系统并发能力。

**参考：**  [1](https://blog.csdn.net/csdnstudent/article/details/40398245)        [2](https://www.jb51.net/article/111015.htm) 

#### 如何处理慢查询

打开慢查询日志,linux下打开需在my.cnf的[mysqld]里面加上以下内容：

```
slow_query_log=TRUE(有些mysql版本是ON)
slow_query_log_file=/usr/local/mysql/slow_query_log.txt
long_query_time=3
```

Windows下，在my.ini配置文件的[mysqld]选项下增加：

```
slow_query_log=TRUE
slow_query_log_file=c:/slow_query_log.txt
long_query_time=3
```

添加完成之后记得一定要重启mysql服务才能生效记录输出。最后在MySQL客户端中输入命令：

show variables like '%quer%'; 核查一下是否更改成功。

查看配置：

```
//查看慢查询时间
show variables like "long_query_time";默认10s
//查看慢查询配置情况
show status like "%slow_queries%";
//查看慢查询日志路径
 show variables like "%slow%";
```

-slow_query_log是否记录慢查询。用long_query_time变量的值来确定“慢查询”。

-slow_query_log_file慢日志文件路径

-long_query_time慢日志执行时长（秒），超过设定的时间才会记日志

**补充**

查看正在锁的事务        SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCKS; 

查看等待锁的事务        SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCK_WAITS; 

查看服务器状态            show status like ‘%lock%’

查看当前有那些表是打开的     show open tables;   

​	In_use列表示有多少线程正在使用某张表，Name_locked表示表名是否被锁，这一般发生在Drop或Rename命令操作这张表时。

查看Innodb引擎状态信息     show engine innodb status;

[由SQL编写导致的慢查询](https://mp.weixin.qq.com/s?__biz=MjM5NzMyMjUwMg==&mid=2247485578&idx=1&sn=378ccdb141b5f3f9bf8a53c01303d19e&chksm=a6da82e391ad0bf58e5dc6e8f2fed7d58697cd28463cb69f5030c1f507fa5ca6ffc717899dee&scene=0&xtrack=1#rd) 

#### 数据库挂了怎么办？

[处理数据库异常挂掉](https://www.jianshu.com/p/e88f89bc9229)

##### 数据库锁表怎么办？

-- 查看那些表锁到了
show OPEN TABLES where In_use > 0;
-- 查看进程号
show processlist;  或者 show full processlist;
--删除进程
 kill 1085850；

**或者**

UNLOCK TABLES;

#### 主从复制

[mysql主从复制的步骤](https://www.aliyun.com/jiaocheng/1105672.html?spm=5176.100033.9.13.2075235f7JpNUG)

#### 什么影响了 MySQL 性能？

1. 影响性能的几个因素

   - 服务器硬件。
   - 服务器系统（系统参数优化）。
   - **存储引擎**。
     `MyISAM`： 不支持事务，表级锁。
     `InnoDB`: 支持事务，支持行级锁，事务`ACID`。
   - **数据库参数配置。**
   - **数据库结构设计和SQL语句。（重点优化）**

2. Mysql体系结构

   **分三层：客户端->服务层->存储引擎**

   ![](https://mmbiz.qpic.cn/mmbiz_png/JdLkEI9sZfe39A5picdNfpqh5RI8Hlk8Tg1rcESjpNLUyACgILhlXZ5Dby26z88ZOQ9d65bPOXUDpfyVVAJkBTQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

   - `MySQL`是**插件式的存储引擎**，其中存储引擎分很多种。只要实现符合mysql存储引擎的接口，可以开发自己的存储引擎!
   - 所有跨存储引擎的功能都是在服务层实现的。
   - MySQL的**存储引擎是针对表的，不是针对库的**。也就是说在一个数据库中可以使用不同的存储引擎。但是不建议这样做。

3. InnoDB存储引擎及其特性

   MySQL5.5`及之后版本默认的存储引擎：`InnoDB

   InnoDB使用表空间进行数据存储。

   ```
   show variables like 'innodb_file_per_table'
   ```

   innodb_file_per_table 为 ON 将建立独立的表空间，文件为tablename.ibd；innodb_file_per_table 为 OFF 将数据存储到系统的共享表空间，文件为ibdataX（X为从1开始的整数）；

   `.frm` ：是服务器层面产生的文件，类似服务器层的数据字典，记录表结构。

   ​:arrow_forward: 系统表空间（mysql5.5默认）与独立表空间（mysql5.6及以后默认）区别

   - 系统表空间无法简单的收缩文件大小，造成空间浪费，并会产生大量的磁盘碎片。
   - 独立表空间可以通过`optimeze table` 收缩系统文件，不需要重启服务器也不会影响对表的正常访问。
   - 如果对多个表进行刷新时，实际上是顺序进行的，会产生IO瓶颈。
   - 独立表空间可以同时向多个文件刷新数据。

   因此**强烈建立对Innodb 使用独立表空间**

   **特性**

   - 事务性存储引擎及两个特殊日志类型：Redo Log 和 Undo Log

     1. Innodb是一种事务性存储引擎
     2. 完全支持事物的ACID特性
     3. 支持事务所需要的两个特殊日志类型：Redo Log 和 Undo Log

     Redo Log : 实现事务的持久性（已提交的事务）

     Undo Log :未提交的事务，独立于表空间，需要随机访问，可以存储在高性能io设备上。

   - 支持行级锁

     1. InnoDB支持行级锁。
     2. 行级锁可以最大程度地支持并发。
     3. 行级锁是由存储引擎层实现的。

4. 锁

   > - 锁主要作用是管理共享资源的并发访问
   > - 锁用于实现事务的隔离性

   锁分为共享锁（读锁）和独占锁（写锁），除了读锁与读锁之间可以兼容外，其他两两都不兼容。

   MySQL的事务支持**不是绑定在MySQL服务器本身**，**而是与存储引擎相关**

   按照粒度，可以分为表级锁和行级锁。

   > 将**table_name**加表级锁命令：`lock table table_name write`; **写锁会阻塞其它用户对该表的‘读写’操作，直到**写锁被释放：`unlock tables`。

   1. **锁的开销越大，粒度越小，并发度越高。**
   2. 表级锁通常是在服务器层实现的。
   3. 行级锁是存储引擎层实现的。innodb的锁机制，服务器层是不知道的

   **阻塞和死锁**

   - 阻塞是由于资源不足引起的排队等待现象。
   - 死锁是由于两个对象在拥有一份资源的情况下申请另一份资源，而另一份资源恰好又是这两对象正持有的，导致两对象无法完成操作，且所持资源无法释放。

5. 选择正确的存储引擎

需要参考：

- 事务
- 备份（`Innobd`免费在线备份）
- 崩溃恢复
- 存储引擎的特有特性

总结：最好使用InnoDB引擎。 尽量别使用混合存储引擎，比如回滚会出问题在线热备问题。

6. 内存配置参数

   - 确定可以使用的内存上限。

     > 内存的使用上限不能超过物理内存，否则容易造成内存溢出；（对于32位操作系统，MySQL只能试用3G以下的内存。）

   - 确定MySQL的**每个连接单独**使用的内存。

     - sort_buffer_size #定义了每个线程排序缓存区的大小，MySQL在有查询、需要做排序操作时才会为每个缓冲区分配内存（直接分配该参数的全部内存）；

     - join_buffer_size #定义了每个线程所使用的连接缓冲区的大小，如果一个查询关联了多张表，MySQL会为每张表分配一个连接缓冲，导致一个查询产生了多个连接缓冲；

     - read_buffer_size #定义了当对一张MyISAM进行全表扫描时所分配读缓冲池大小，MySQL有查询需要时会为其分配内存，其必须是4k的倍数；

     - read_rnd_buffer_size #索引缓冲区大小，MySQL有查询需要时会为其分配内存，只会分配需要的大小。

       **注意**  以上四个参数是为一个线程分配的，如果有100个连接，那么需要×100。

     总内存 -（每个线程所需要的内存*连接数）= 系统保留内存

   - MySQL数据库实例：

      MySQL是**单进程多线程**（而oracle是多进程），也就是说`MySQL`实例在系统上表现就是一个服务进程，即进程；MySQL实例是线程和内存组成，实例才是真正用于操作数据库文件的；**一般情况下**一个实例操作一个或多个数据库；**集群情况下**多个实例操作一个或多个数据库。

     **如何为缓存池分配内存：**

     -  `Innodb_buffer_pool_size`，定义了Innodb所使用缓存池的大小，对其性能十分重要，必须足够大，但是过大时，使得Innodb 关闭时候需要更多时间把脏页从缓冲池中刷新到磁盘中；

     -  `key_buffer_size`，定义了MyISAM所使用的缓存池的大小，由于数据是依赖存储操作系统缓存的，所以要为操作系统预留更大的内存空间；

       **注意：** 即使开发使用的表全部是Innodb表，也要为MyISAM预留内存，因为MySQL系统使用的表仍然是MyISAM表。

       `max_connections` 控制允许的最大连接数， 一般2000更大。

       **不要使用外键约束保证数据的完整性。**

7. 性能优化顺序

   优先级：（从上到下）

   - 数据库结构设计和SQL语句
   - 数据库存储引擎的选择和参数设置
   - 系统选择及优化
   - 硬件升级

#### 什么影响了数据库查询速度？

![](https://mmbiz.qpic.cn/mmbiz_png/tuSaKc6SfPoPbUQbsk6d95CNIgPM0WSXIJM12yrh3ZFMibtsHRhkeeNnzL9v7gpyjdYMpDktgTlypF9mCxagL3Q/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

> **QPS：**`Queries Per Second`意思是“每秒查询率”，是一台服务器每秒能够相应的查询次数，是对一个特定的查询服务器在规定时间内所处理流量多少的衡量标准。
>
> **TPS：**是`TransactionsPerSecond`的缩写，也就是事务数/秒。它是软件测试结果的测量单位。客户机在发送请求时开始计时，收到服务器响应后结束计时，以此来计算使用的时间和完成的事务个数。

**Tips：**最好不要在主库上数据库备份，大型活动前取消这样的计划。

风险：

1. 效率低下的`sql`：超高的`QPS`与`TPS`。
2. 大量的并发：数据连接数被占满（`max_connection`默认`100`，一般把连接数设置得大一些）。并发量:同一时刻数据库服务器处理的请求数量
3. 超高的`CPU`使用率：`CPU`资源耗尽出现宕机。
4. 磁盘`IO`：磁盘`IO`性能突然下降、大量消耗磁盘性能的计划任务。解决：更快磁盘设备、调整计划任务、做好磁盘维护。

网卡流量：如何避免无法连接数据库的情况

- 减少从服务器的数量（从服务器会从主服务器复制日志）
- 进行分级缓存（避免前端大量缓存失效）
- 避免使用`select *` 进行查询
- 分离业务网络和服务器网络

大表带来的问题：

> 大表特点：记录行数巨大，单表超千万；表数据文件巨大，超过`10`个`G`

​	大表的危害：

    1.  慢查询：**很难在短时间内过滤出需要的数据**  

     2.  对`DDL`影响：

   **建立索引需要很长时间：** 

   > - `MySQL -v<5.5` 建立索引会锁表
   > - `MySQL -v>=5.5` 建立索引会造成主从延迟（`mysql`建立索引，先在主库上执行，再在从库上执行） 

    **修改表结构需要长时间的锁表：**会造成长时间的主从延迟('480秒延迟')

  解决： 分库分表

大事务带来的问题：

> 1. 事务是数据库系统区别于其他一切文件系统的重要特性之一
> 2. 事务是一组具有原子性的SQL语句，或是一个独立的工作单元

事务的ACID特性

原子性（atomicity）  一致性（consistent） 隔离性（isolation）  持久性（DURABILITY）

事务的隔离级别：

- 未提交读(`READ UNCOMMITED`) **脏读**,两个事务之间互相可见；
- 已提交读(`READ COMMITED`)符合隔离性的基本概念,一个事务进行时，其它已提交的事物对于该事务是可见的，即可以获取其它事务提交的数据。
- 可重复读(`REPEATABLE READ`) **InnoDB的默认隔离等级**。事务进行时，其它所有事务对其不可见，即多次执行读，得到的结果是一样的！
- 可串行化（`SERIALIZABLE`） 在读取的每一行数据上都加锁，会造成大量的锁超时和锁征用，严格数据一致性且没有并发是可使用。

![](https://mmbiz.qpic.cn/mmbiz_png/tuSaKc6SfPoPbUQbsk6d95CNIgPM0WSX42p1z2Aia765cE4ohDkTDsokdhEeGib9ciaafqUe4gHiac3MGk1UykqRqQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

*`redo log`机制保证事务更新的一致性和持久性*

大事务危害：

运行时间长，操作数据比较多的事务；

**风险：锁定数据太多，回滚时间长，执行时间长。**

- 锁定太多数据，造成大量阻塞和锁超时；
- 回滚时所需时间比较长，且数据仍然会处于锁定；
- 如果执行时间长，将造成主从延迟，因为只有当主服务器全部执行完写入日志时，从服务器才会开始进行同步，造成延迟。

解决：

- 避免一次处理太多数据，可以分批次处理；
- 移出不必要的`SELECT`操作，保证事务中只有必要的写操作。

#### Mysql性能优化

```
show status    //查看 MySQL 服务器运行的状态值
```

​:arrow_forward:  主要关注“Queries”、“Threadsconnected” 和 “Threadsrunning” 的值，即查询次数、线程连接数和线程运行数。

```
show processlist   //查看运行的线程
```

​:arrow_forward: 返回的 State 的值是我们判断性能好坏的关键：

[state值参考](https://dev.mysql.com/doc/refman/5.7/en/general-thread-states.html)

​:arrow_forward: 使用 MySQL 提供的 explain 查看 SQL 执行计划情况

​:arrow_forward: 使用 profiling 命令可以了解 SQL 语句消耗资源的详细信息( 每个执行步骤的开销 )

[Mysql优化参考](https://www.extlight.com/2017/10/07/MySQL-%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E6%8A%80%E5%B7%A7/#) 

#### SQL里的各种join用法

![](https://mmbiz.qpic.cn/mmbiz_png/vqlbVFl5Jn2fx4T60E8RNV6gdvX5icOExwpTtQibfXrlOZYdjwtuteH64IkRrgDrulic56ypMMWuRk5f8ZemQSxaA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

1. **INNER JOIN（内连接）**

   INNER JOIN 关键字在表中存在至少一个匹配时返回行

   ```
   SELECT column_name(s)
   FROM table1
   INNER JOIN table2
   ON table1.column_name=table2.column_name;
   或
   SELECT column_name(s)
   FROM table1
   JOIN table2
   ON table1.column_name=table2.column_name;
   ```

   *INNER JOIN 与 JOIN 是相同的。* 

2. **LEFT JOIN（左连接）**

   LEFT JOIN 关键字从左表（table1）返回所有的行，即使右表（table2）中没有匹配。如果右表中没有匹配，则结果为 NULL。

   ```
   SELECT column_name(s)
   FROM table1
   LEFT JOIN table2
   ON table1.column_name=table2.column_name;
   或
   SELECT column_name(s)
   FROM table1
   LEFT OUTER JOIN table2
   ON table1.column_name=table2.column_name;
   ```

   *在某些数据库中，LEFT JOIN 称为 LEFT OUTER JOIN。* 

3. **RIGHT JOIN（右连接）**

   RIGHT JOIN 关键字从右表（table2）返回所有的行，即使左表（table1）中没有匹配。如果左表中没有匹配，则结果为 NULL。

   ```
   SELECT column_name(s)
   FROM table1
   RIGHT JOIN table2
   ON table1.column_name=table2.column_name;
   或
   SELECT column_name(s)
   FROM table1
   RIGHT OUTER JOIN table2
   ON table1.column_name=table2.column_name;
   ```

   *在某些数据库中，RIGHT JOIN 称为 RIGHT OUTER JOIN。* 

4. **OUTER JOIN（外连接、全连接）** 

   FULL OUTER JOIN 关键字只要左表（table1）和右表（table2）其中一个表中存在匹配，则返回行.

   FULL OUTER JOIN 关键字结合了 LEFT JOIN 和 RIGHT JOIN 的结果。

   ```
   SELECT column_name(s)
   FROM table1
   FULL OUTER JOIN table2
   ON table1.column_name=table2.column_name;
   ```

   *MySQL中不支持 FULL OUTER JOIN*  

5. **LEFT JOIN EXCLUDING INNER JOIN（左连接-内连接）**

   返回左表有但右表没有关联数据的记录集。

6. **RIGHT JOIN EXCLUDING INNER JOIN（右连接-内连接）**

   返回右表有但左表没有关联数据的记录集。

7. **OUTER JOIN EXCLUDING INNER JOIN（外连接-内连接）**

   返回左表和右表里没有相互关联的记录集。

   *MySQL中不支持该操作*  

##### 更多的join用法

**CROSS JOIN（迪卡尔集）** 

返回左表与右表之间符合条件的记录的迪卡尔集。

**SELF JOIN** 

返回表与自己连接后符合条件的记录，一般用在表里有一个字段是用主键作为外键的情况。

​:arrow_forward: 注意：

- SQL 里的 JOIN 查询与数学里的求交集、并集等很像
- SQLite 不支持 RIGHT JOIN 和 FULL OUTER JOIN，可以使用 LEFT JOIN 和 UNION 来达到相同的效果；
- MySQL 不支持 FULL OUTER JOIN，可以使用 LEFT JOIN 和 UNION 来达到相同的效果；

#### Mysql语句的执行顺序语法模板

```
select distinct <select_list>

from 

<left_table><join_type> join <right_table> on <join_condition>

where <where_condition>

group by <group_by_rowname>

having <having_condition>

order by <order_by_condition>

limit <limit_number>
```

![](https://images2015.cnblogs.com/blog/885267/201703/885267-20170318172444463-1126212485.png)

 #### Oracle与mysql分页的区别和原理

**mysql使用分页**

```
select * from stu limit m, n; //m = (startPage-1)*pageSize,n = pageSize
```

1. 第一个参数值m表示起始行，第二个参数表示取多少行
2. m = (2-1)*10-1,n=10,表示limit  11,10.从11行开始，取10行，即第二页数据
3. m,n 参数值不能再语句当中写计算表达式，写到语句之前必须计算好值

**Oracle使用rownum分页**

```
select * from (
select rownum rn,a.* from table_name a where rownum <= x
//结束行，x = startPage*pageSize
)
where rn >= y; //起始行，y = (startPage-1)*pageSize+1
```

1. 》=  y  ,<=x表示从第y行（起始行）~x行（结束行）
2. rownum只能比较小于，不能比较大于，因为rownum是先查询后排序的。所以查询的时候需要设置别名，然后查询完成之后再通过调用别名进行大于的判断。

## Nginx

Nginx (engine x) 是一款轻量级的Web 服务器 、反向代理服务器及电子邮件（IMAP/POP3）代理服务器。

Nginx能做什么？

- 反向代理
- 负载均衡
- HTTP服务器（包含动静分离）
- 正向代理

Nginx可以支持热启动，Nginx从新读取配置的命令是：

` nginx -s reload`

> windows下是: 
>
> ​	nginx.exe -s reload

#### 反向代理

​        反向代理（Reverse Proxy）方式是指以代理服务器来接受internet上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给internet上请求连接的客户端，此时代理服务器对外就表现为一个反向代理服务器。简单来说就是真实的服务器不能直接被外部网络访问，所以需要一台代理服务器，而代理服务器能被外部网络访问的同时又跟真实服务器在同一个网络环境，当然也可能是同一台服务器，端口不同而已。

```
server {
        listen       80;                                                         
        server_name  localhost;                                               
        client_max_body_size 1024M;

        location / {
            proxy_pass http://localhost:8080;
            proxy_set_header Host $host:$server_port;
        }
    }
```

#### 正向代理

正向代理，意思是一个位于客户端和原始服务器(origin server)之间的服务器，为了从原始服务器取得内容，客户端向代理发送一个请求并指定目标(原始服务器)，然后代理向原始服务器转交请求并将获得的内容返回给客户端。客户端才能使用正向代理。当你需要把你的服务器作为代理服务器的时候，可以用Nginx来实现正向代理。

```
   resolver 114.114.114.114 8.8.8.8;
    server {

        resolver_timeout 5s;

        listen 81;

        access_log  e:\wwwroot\proxy.access.log;
        error_log   e:\wwwroot\proxy.error.log;

        location / {
            proxy_pass http://$host$request_uri;
        }
    }
```

 resolver是配置正向代理的DNS服务器，listen 是正向代理的端口，配置好了就可以在ie上面或者其他代理插件上面使用服务器ip+端口号进行代理了

##### 正向代理与反向代理比较

- 正向代理
  - 正向代理，我们的角色是 **被代理者**
  - 正向代理，我们不对外提供服务，反而是对外消费服务，属于消费者
- 反向代理
  - 反向代理，我们的角色是 **局域网 web服务**
  - 反向代理，我们对外提供服务，属于服务提供者

#### 负载均衡

负载均衡其意思就是分摊到多个操作单元上进行执行，例如Web服务器、FTP服务器、企业关键应用服务器和其它关键任务服务器等，从而共同完成工作任务。简单而言就是当有2台或以上服务器时，根据规则随机的将请求分发到指定的服务器上处理，负载均衡配置一般都需要同时配置反向代理，通过反向代理跳转到负载均衡

常见的几种负载均衡策略：

1. **基于轮询   RR** （默认）

   每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。

简单配置：

```
    upstream test {
        server localhost:8080;
        server localhost:8081;
    }
    server {
        listen       81;                                                         
        server_name  localhost;                                               
        client_max_body_size 1024M;

        location / {
            proxy_pass http://test;
            proxy_set_header Host $host:$server_port;
        }
    }
```

核心代码：

```
 upstream test {
        server localhost:8080;
        server localhost:8081;
    }
```

`upstream`块定义一个后端小集群，里边配置相关的Server组成这个集群，同时`upstream`为这个集群起个相应的名字，本实例叫`test`.

`proxy_pass`处于`location`块中，表示对于所有符合`/`的request，将会交给哪个集群进行处理，本实例为`http://test`

如果协议使用`https`，则将`http`直接改成`https`即可。另外，如果你在`upstream`中的`server`指令中指定了协议名，那么在`proxy_pass`指令中就不需要加上协议名称了。

2. 权重

指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况

```
  upstream test {
        server localhost:8080 weight=9;
        server localhost:8081 weight=1;
    }
```

3. ip_hash

想让对于相同客户端的请求每次都被分发到同一个Server进行处理，上面两种策略都是不做到。此策略可确保来自同一客户端的请求始终定向到同一服务器，但此服务器不可用时除外。既然相同客户端的请求能被同一台Server进行处理，那么相同客户端的会话Session就可以实现持久化了。

```
    upstream test {
        ip_hash;
        server localhost:8080;
        server localhost:8081;
    }
```

4. 基于最少连接数

   该策略主要使用了`least_conn`指令，可以按照机器的实际情况进行刚需分配。

   ```
   upstream myapp1 {
      least_conn;
      server srv1.example.com;
      server srv2.example.com;
      server srv3.example.com;
   }
   ```

5. fair(第三方)

   按后端服务器的响应时间来分配请求，响应时间短的优先分配。

   ```
       upstream backend { 
           fair; 
           server localhost:8080;
           server localhost:8081;
       } 
   ```

6. url_hash（第三方）

   按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效。 在upstream中加入hash语句，server语句中不能写入weight等其他的参数，hash_method是使用的hash算法

   ```
       upstream backend { 
           hash $request_uri; 
           hash_method crc32; 
           server localhost:8080;
           server localhost:8081;
       } 
   ```

**负载均衡健康检查**

当我们一个request进来被分发到相应的Server进行处理后，nginx会检查该request执行是否超时，是否执行失败了等情况，然后做出相应的处理；比如说当nginx检查出Server A执行某request时报出502错误了，那么下次nginx负载均衡时就会在`upstream`块中将Server A排除掉，不分发请求给到Server A了。

对于健康检查的功能，nginx提供了基本两个指令，即`max_fails`和`fail_timeout`,也就是说当nginx检查到某Server发生错误的request数达到`max_fails`或者执行某request执行时间超过`fail_timeout`了，如果发生超时了，nginx将开始使用实时请求优雅地探测Server，如果有响应，则认为对应的Server还是活着的，没有毛病的。

**负载均衡的作用**

- 转发功能：按照一定的算法【权重、轮询】，将客户端请求转发到不同应用服务器上，减轻单个服务器压力，提高系统并发量。
- 故障移除：通过心跳检测的方式，判断应用服务器当前是否可以正常工作，如果服务器期宕掉，自动将请求发送到其他应用服务器。
- 恢复添加：如检测到发生故障的应用服务器恢复工作，自动将其添加到处理用户请求队伍中。

#### HTTP服务器

Nginx本身也是一个静态资源的服务器，当只有静态资源的时候，就可以使用Nginx来做服务器，同时现在也很流行动静分离，就可以通过Nginx来实现。

动静分离是让动态网站里的动态网页根据一定规则把不变的资源和经常变的资源区分开来，动静资源做好了拆分以后，我们就可以根据静态资源的特点将其做缓存操作，这就是网站静态化处理的核心思路

```
upstream test{  
       server localhost:8080;  
       server localhost:8081;  
    }   

    server {  
        listen       80;  
        server_name  localhost;  

        location / {  
            root   e:\wwwroot;  
            index  index.html;  
        }  

        # 所有静态请求都由nginx处理，存放目录为html  
        location ~ \.(gif|jpg|jpeg|png|bmp|swf|css|js)$ {  
            root    e:\wwwroot;  
        }  

        # 所有动态请求都转发给tomcat处理  
        location ~ \.(jsp|do)$ {  
            proxy_pass  http://test;  
        }  

        error_page   500 502 503 504  /50x.html;  
        location = /50x.html {  
            root   e:\wwwroot;  
        }  
    }  
```

##### 正向代理、反向代理、透明代理使用

- 正向代理

  正向代理(forward)是一个位于客户端【用户A】和原始服务器(origin server)【服务器B】之间的服务器【代理服务器Z】，为了从原始服务器取得内容，用户A向代理服务器Z发送一个请求并指定目标(服务器B)，然后代理服务器Z向服务器B转交请求并将获得的内容返回给客户端。客户端必须要进行一些特别的设置才能使用正向代理。

  使用正向代理服务器作用主要有以下几点：

  - 访问本无法访问的服务器B
  - 加速访问服务器B
  - Cache作用
  - 客户端授权访问
  - 隐藏访问者的行踪

- 反向代理

  反向代理正好与正向代理相反，对于客户端而言代理服务器就像是原始服务器，并且客户端不需要进行任何特别的设置。客户端向反向代理的命名空间(name-space)中的内容发送普通请求，接着反向代理将判断向何处(原始服务器)转交请求，并将获得的内容返回给客户端。

  使用反向代理服务器作用如下：

  - 保护和隐藏原始资源服务器
  - 负载均衡

- 透明代理

  透明代理的意思是客户端根本不需要知道有代理服务器的存在，它改变你的request fields(报文)，并会传送真实IP。注意，加密的透明代理则是属于匿名代理，意思是不用设置使用代理了。



## 网络编程

#### TCP/IP

TCP/IP是个协议组，可分为三个层次：网络层、传输层和应用层。 
在网络层有IP协议、ICMP协议、ARP协议、RARP协议和BOOTP协议。 
在传输层中有TCP协议与UDP协议。 
在应用层有:TCP包括FTP、HTTP、TELNET、SMTP等协议 
​                    UDP包括DNS、TFTP等协议 

**Socket**

Socket是应用层与TCP/IP协议族通信的中间软件抽象层，它是一组接口。在设计模式中，Socket其实就是一个门面模式，它把复杂的TCP/IP协议族隐藏在Socket接口后面，对用户来说，一组简单的接口就是全部，让Socket去组织数据，以符合指定的协议。

#### TCP为何采用三次握手来建立连接

在TCP/IP协议中，TCP协议提供可靠的连接服务，采用三次握手建立一个连接

- 第一次握手：建立连接时，客户端发送syn包(syn=j)到服务器，并进入SYN_SEND状态，等待服务器确认；
- 第二次握手：服务器收到syn包，必须确认客户的SYN（ack=j+1），同时自己也发送一个SYN包（syn=k），即SYN+ACK包，此时服务器 进入SYN_RECV状态；
- 第三次握手：客户端收到服务器的SYN＋ACK包，向服务器发送确认包ACK(ack=k+1)，此包发送完毕，客户端和服务器进入 ESTABLISHED状态，完成三次握手。

> **三次握手的最主要目的是保证连接是双工的，可靠更多的是通过重传机制来保证的。**

**为了保证服务端能收接受到客户端的信息并能做出正确的应答而进行前两次(第一次和第二次)握手，为了保证客户端能够接收到服务端的信息并能做出正确的应答而进行后两次(第二次和第三次)握手。**

#### 为什么断开TCP连接需要进行四次握手 

立连接后，客户端和服务器都处于`ESTABLISED`状态。这时，客户端发起断开连接的请求：

- 客户端调用 close() 函数后，向服务器发送 FIN 数据包，进入`FIN_WAIT_1`状态。FIN 是 Finish 的缩写，表示完成任务需要断开连接。 

- 服务器收到数据包后，检测到设置了 FIN 标志位，知道要断开连接，于是向客户端发送“确认包”，进入`CLOSE_WAIT`状态。

  :arrow_forward:服务器收到请求后并不是立即断开连接，而是先向客户端发送“确认包”，告诉它我知道了，我需要准备一下才能断开连接

- 客户端收到“确认包”后进入`FIN_WAIT_2`状态，等待服务器准备完毕后再次发送数据包。

- 等待片刻后，服务器准备完毕，可以断开连接，于是再主动向客户端发送 FIN 包，告诉它我准备好了，断开连接吧。然后进入`LAST_ACK`状态。

- 客户端收到服务器的 FIN 包后，再向服务器发送 ACK 包，告诉它你断开连接吧。然后进入`TIME_WAIT`状态。

-  服务器收到客户端的 ACK 包后，就断开连接，关闭套接字，进入`CLOSED`状态。

因为TCP连接是全双工的网络协议，允许同时通信的双方同时进行数据的收发，同样也允许收发两个方向的连接被独立关闭，以避免client数据发送完毕，向server发送FIN关闭连接，而server还有发送到client的数据没有发送完毕的情况。所以关闭TCP连接需要进行四次握手，每次关闭一个方向上的连接需要FIN和ACK两次握手。

#### socket长连接和短连接区别

概念：长连接与短连接的概念：前者是整个通讯过程，客户端和服务端只用一个Socket对象，长期保持Socket的连接；后者是每次请求，都新建一个Socket,处理完一个请求就直接关闭掉Socket。所以，其实区分长短连接就是：整个客户和服务端的通讯过程是利用一个Socket还是多个Socket进行的。

**短连接**

连接->传输数据->关闭连接 
HTTP是无状态的，浏览器和服务器每进行一次HTTP操作，就建立一次连接，但任务结束就中断连接。 
也可以这样说：短连接是指SOCKET连接后发送后接收完数据后马上断开连接。 

**长连接 **
连接->传输数据->保持连接 -> 传输数据-> 。。。 ->关闭连接。 
长连接指建立SOCKET连接后不管是否使用都保持连接，但安全性较差。 

> **http的长连接**
> HTTP也可以建立长连接的，使用Connection:keep-alive，HTTP 1.1默认进行持久连接。HTTP1.1和HTTP1.0相比较而言，最大的区别就是增加了持久连接支持(貌似最新的 http1.0 可以显示的指定 keep-alive),但还是无状态的，或者说是不可以信任的。 

#### socket异步与同步区别

**1、异步 **
报文发送和接收是分开的，相互独立的，互不影响。这种方式又分两种情况： 

- 异步双工：接收和发送在同一个程序中，由两个不同的子进程分别负责发送和接收 
- 异步单工：接收和发送是用两个不同的程序来完成。 

**2、同步 **
报文发送和接收是同步进行，即报文发送后等待接收返回报文。 同步方式一般需要考虑超时问题，即报文发出去后不能无限等待，需要设定超时时间，超过该时间发送方不再等待读返回报文，直接通知超时返回。

#### 单工、半双工和全双工

根据通信双方的分工和信号传输方向可将通信分为三种方式：单工、半双工与全双工。在计算机网络中主要采用双工方式，其中：局域网采用半双工方式，城域网和广域网采用全双工方式。

- 单工(Simplex)方式：通信双方设备中发送器与接收器分工明确，只能在由发送器向接收器的单一固定方向上传送数据。采用单工通信的典型发送设备如早期计算机的读卡器，典型的接收设备如打印机。
- 半双工(Half Duplex)方式：通信双方设备既是发送器，也是接收器，两台设备可以相互传送数据，但某一时刻则只能向一个方向传送数据。例如，步话机是半双工设备，因为在一个时刻只能有一方说话。
- 全双工(Full Duplex)方式：通信双方设备既是发送器，也是接收器，两台设备可以同时在两个方向上传送数据。例如，电话是全双工设备，因为双方可同时说话。

## HTTP与HTTPS

#### 简述http与https的区别

1. https协议需要到ca申请证书，一般免费证书较少，因而需要一定费用。
2. http是超文本传输协议，信息是明文传输，https则是具有安全性的ssl(Secure Sockets Layer)加密传输协议。
3. http和https使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。
4. http的连接很简单，是无状态的；HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，比http协议安全。

## 安全

#### 简述SHA1,MD5,AES,DES,RSA分别是什么？在什么场景下使用？

**加密技术通常分为两大类:"对称式"和"非对称式"。**

+ **对称性加密算法：**对称式加密就是加密和解密使用同一个密钥。信息接收双方都需事先知道密匙和加解密算法且其密匙是相同的，之后便是对数据进行加解密了。对称加密算法用来对敏感数据等信息进行加密。
+ **非对称算法：**非对称式加密就是加密和解密所使用的不是同一个密钥，通常有两个密钥，称为"公钥"和"私钥"，它们两个必需配对使用，否则不能打开加密文件。发送双方A,B事先均生成一堆密匙，然后A将自己的公有密匙发送给B，B将自己的公有密匙发送给A，如果A要给B发送消息，则先需要用B的公有密匙进行消息加密，然后发送给B端，此时B端再用自己的私有密匙进行消息解密，B向A发送消息时为同样的道理。
+ **散列算法：**散列算法，又称哈希函数，是一种单向加密算法。在信息安全技术中，经常需要验证消息的完整性，散列(Hash)函数提供了这一服务，它对不同长度的输入消息，产生固定长度的输出。这个固定长度的输出称为原输入消息的"散列"或"消息摘要"(Message digest)。散列算法不算加密算法，因为其结果是不可逆的，既然是不可逆的，那么当然不是用来加密的，而是签名。

**对称性加密算法有：AES、DES、3DES**

> 用途： 对称加密算法用来对敏感数据等信息进行加密

- **DES**（Data Encryption Standard）：数据加密标准，速度较快，适用于加密大量数据的场合。
- **3DES**（Triple DES）：是基于DES，对一块数据用三个不同的密钥进行三次加密，强度更高。
- **AES**（Advanced Encryption Standard）：高级加密标准，是下一代的加密算法标准，速度快，安全级别高；AES是一个使用128为分组块的分组加密算法，分组块和128、192或256位的密钥一起作为输入，对4×4的字节数组上进行操作。众所周之AES是种十分高效的算法，尤其在8位架构中，这源于它面向字节的设计。AES 适用于8位的小型单片机或者普通的32位微处理器,并且适合用专门的硬件实现，硬件实现能够使其吞吐量（每秒可以到达的加密/解密bit数）达到十亿量级。同样，其也适用于RFID系统。

**非对称性算法有：RSA、DSA、ECC**

- **RSA**：由 RSA 公司发明，是一个支持变长密钥的公共密钥算法，需要加密的文件块的长度也是可变的。RSA在国外早已进入实用阶段，已研制出多种高速的RSA的专用芯片。
- **DSA**（Digital Signature Algorithm）：数字签名算法，是一种标准的 DSS（数字签名标准），严格来说不算加密算法。
- **ECC**（Elliptic Curves Cryptography）：椭圆曲线密码编码学。ECC和RSA相比，具有多方面的绝对优势，主要有：抗攻击性强。相同的密钥长度，其抗攻击性要强很多倍。计算量小，处理速度快。ECC总的速度比RSA、DSA要快得多。存储空间占用小。ECC的密钥尺寸和系统参数与RSA、DSA相比要小得多，意味着它所占的存贮空间要小得多。这对于加密算法在IC卡上的应用具有特别重要的意义。带宽要求低。当对长消息进行加解密时，三类密码系统有相同的带宽要求，但应用于短消息时ECC带宽要求却低得多。带宽要求低使ECC在无线网络领域具有广泛的应用前景。

**散列算法（签名算法）有：MD5、SHA1、HMAC**

> 用途：主要用于验证，防止信息被修改。具体用途如：文件校验、数字签名、鉴权协议

- **MD5**：MD5是一种不可逆的加密算法，目前是最牢靠的加密算法之一，尚没有能够逆运算的程序被开发出来，它对应任何字符串都可以加密成一段唯一的固定长度的代码。
- **SHA1**：是由NISTNSA设计为同DSA一起使用的，它对长度小于264的输入，产生长度为160bit的散列值，因此抗穷举(brute-force)性更好。SHA-1设计时基于和MD4相同原理,并且模仿了该算法。SHA-1是由美国标准技术局（NIST）颁布的国家标准，是一种应用最为广泛的Hash函数算法，也是目前最先进的加密技术，被政府部门和私营业主用来处理敏感的信息。而SHA-1基于MD5，MD5又基于MD4。
- **HMAC**：是密钥相关的哈希运算消息认证码（Hash-based Message Authentication Code）,HMAC运算利用哈希算法，以一个密钥和一个消息为输入，生成一个消息摘要作为输出。也就是说HMAC是需要一个密钥的。所以，HMAC_SHA1也是需要一个密钥的，而SHA1不需要。

**Base64**：其实不是安全领域下的加密解密算法，只能算是一个编码算法，通常用于把二进制数据编码为可写的字符形式的数据，对数据内容进行编码来适合传输(可以对img图像编码用于传输)。这是一种可逆的编码方式。编码后的数据是一个字符串，其中包含的字符为：A-Z、a-z、0-9、+、/，共64个字符，其实是65个字符，“=”是填充字符。

**HTTPS**（全称：Hypertext Transfer Protocol over Secure Socket Layer），是以安全为目标的HTTP通道，简单讲是HTTP的安全版。即HTTP下加入SSL层，HTTPS的安全基础是SSL(SSL使用40 位关键字作为RC4流加密算法)，因此加密的详细内容就需要SSL。https:URL表明它使用了HTTP，但HTTPS存在不同于HTTP的默认端口及一个加密/身份验证层（在HTTP与TCP之间），提供了身份验证与加密通讯方法；它的主要作用可以分为两种：一种是建立一个信息安全通道，来保证数据传输的安全；另一种就是确认网站的真实性。

**区别**

> 1. AES：更快，兼容设备，安全级别高；
> 2. SHA1：公钥后处理回传
> 3. DES：本地数据，安全级别低
> 4. RSA：非对称加密，有公钥和私钥
> 5. MD5：防篡改

**主要应用** 

- 加密算法是可逆的，用来对敏感数据进行保护。散列算法(签名算法、哈希算法)是不可逆的，主要用于身份验证。
- 大量数据加密建议采用对称加密算法，提高加解密速度；小量的机密数据，可以采用非对称加密算法。

## Spring

#### Spring声明式事务

Spring声明式事务管理，通过Spring AOP实现声明式事务管理

事务的四种属性

1. **事务的传播方式**

> 事务传播行为：是指添加事物时的策略

- PROPAGATION_REQUIRED   如果当前没有事务，就新建一个事务，如果已经存在一个事务中，加入到这个事务中。这是最常见的选择。
- PROPAGATION_SUPPORTS    支持当前事务，如果当前没有事务，就以非事务方式执行。
- PROPAGATION_MANDATORY   使用当前的事务，如果当前没有事务，就抛出异常。
- PROPAGATION_REQUIRES_NEW   新建事务，如果当前存在事务，把当前事务挂起。
- PROPAGATION_NOT_SUPPORTED     以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。
- PROPAGATION_NEVER     以非事务方式执行，如果当前存在事务，则抛出异常。
- PROPAGATION_NESTED   如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则执行与PROPAGATION_REQUIRED类似的操作。

2. **事务隔离级别**

- ISOLATION_DEFAULT：用底层数据库的默认隔离级别
- ISOLATION_READ_UNCOMMITTED（未提交读）：最低隔离级别、事务未提交前，就可被其他事务读取（会出现幻读、脏读、不可重复读）
- ISOLATION_READ_COMMITTED（提交读）：一个事务提交后才能被其他事务读取到（该隔离级别禁止其他事务读取到未提交事务的数据、所以还是会造成幻读、不可重复读）、sql server默认级别
- ISOLATION_REPEATABLE_READ（可重复读）：可重复读，保证多次读取同一个数据时，其值都和事务开始时候的内容是一致，禁止读取到别的事务未提交的数据（该隔离基本可防止脏读，不可重复读（重点在修改），但会出现幻读（重点在增加与删除））（MySql默认级别，更改可通过set transaction isolation level 级别）
- ISOLATION_SERIALIZABLE（序列化）：代价最高最可靠的隔离级别（该隔离级别能防止脏读、不可重复读、幻读）

>其他概念：
>
>- 丢失更新：两个事务同时更新一行数据，最后一个事务的更新会覆盖掉第一个事务的更新，从而导致第一个事务更新的数据丢失，这是由于没有加锁造成的；
>- 幻读：同样的事务操作过程中，不同时间段多次（不同事务）读取同一数据，读取到的内容不一致（一般是行数变多或变少）。
>- 脏读：一个事务读取到另外一个未提及事务的内容，即为脏读。
>- 不可重复读：同一事务中，多次读取内容不一致（一般行数不变，而内容变了）。

数据库隔离级别越高，执行代价越高，并发执行能力越差，因此在实际项目开发使用时要综合考虑，为了考虑并发性能一般使用提交读隔离级别，它能避免丢失更新和脏读。

3. 事务的超时值
4. 事务的只读标志


#### Spring容器中Bean的作用域

当通过Spring容器创建一个Bean实例时，不仅可以完成Bean实例的实例化，还可以为Bean指定特定的作用域。**Spring支持如下5种作用域：**

- **singleton**：单例模式，在整个Spring IoC容器中，使用singleton定义的Bean将只有一个实例
- **prototype**：原型模式，每次通过容器的getBean方法获取prototype定义的Bean时，都将产生一个新的Bean实例
- **request**：对于每次HTTP请求，使用request定义的Bean都将产生一个新实例，即每次HTTP请求将会产生不同的Bean实例。只有在Web应用中使用Spring时，该作用域才有效
- **session**：对于每次HTTP Session，使用session定义的Bean都将产生一个新实例。同样只有在Web应用中使用Spring时，该作用域才有效
- **globalsession**：每个全局的HTTP Session，使用session定义的Bean都将产生一个新实例。典型情况下，仅在使用portlet context的时候有效。同样只有在Web应用中使用Spring时，该作用域才有效

**其中比较常用的是singleton和prototype两种作用域。**对于singleton作用域的Bean，每次请求该Bean都将获得相同的实例。容器负责跟踪Bean实例的状态，负责维护Bean实例的生命周期行为；如果一个Bean被设置成prototype作用域，程序每次请求该id的Bean，Spring都会新建一个Bean实例，然后返回给程序。在这种情况下，Spring容器仅仅使用new 关键字创建Bean实例，一旦创建成功，容器不在跟踪实例，也不会维护Bean实例的状态。

**如果不指定Bean的作用域，Spring默认使用singleton作用域,且是饿汉模式。**  Java在创建Java实例时，需要进行内存申请；销毁实例时，需要完成垃圾回收，这些工作都会导致系统开销的增加。因此，prototype作用域Bean的创建、销毁代价比较大。而singleton作用域的Bean实例一旦创建成功，可以重复使用。因此，除非必要，否则尽量避免将Bean被设置成prototype作用域。

```
<!-- 默认的作用域：singleton -->
<bean id="p1" class="com.abc.Person" /> 
<!-- 指定的作用域：prototype -->
<bean id="p2" class="com.abc.Person" scope="prototype" />
```

spring singleton设置为懒汉模式:
<beans default-lazy-init="true">

#### Spring线程安全

Spring框架中的Bean，或者说组件，获取实例的时候都是默认单例模式，这是在多线程开发的时候可能会发生线程安全问题。

当多个用户同时请求一个服务时，容器会给每一个请求分配一个线程，这时多个线程会并发执行该请求对应的业务逻辑（成员方法），此时就要注意了，如果该处理逻辑中有对单例状态的修改（体现为该单例的成员属性），则必须考虑线程同步问题。

**同步机制的比较：** 

ThreadLocal和线程同步机制，他们都是为了解决多线程中相同变量的访问冲突问题。

在同步机制中，通过对象的锁机制保证同一时间只有一个线程访问变量。这时该变量是多个线程共享的，使用同步机制要求程序慎密地分析什么时候对变量进行读写，什么时候需要锁定某个对象，什么时候释放对象锁等繁杂的问题，程序设计和编写难度相对较大。 

而ThreadLocal则从另一个角度来解决多线程的并发访问。ThreadLocal会为每一个线程提供一个独立的变量副本，从而隔离了多个线程对数据的访问冲突。因为每一个线程都拥有自己的变量副本，从而也就没有必要对该变量进行同步了。ThreadLocal提供了线程安全的共享对象，在编写多线程代码时，可以把不安全的变量封装进ThreadLocal。 

由于ThreadLocal中可以持有任何类型的对象，低版本JDK所提供的get()返回的是Object对象，需要强制类型转换。但JDK 5.0通过泛型很好的解决了这个问题，在一定程度地简化ThreadLocal的使用

概括起来说，对于多线程资源共享的问题，**同步机制采用了“以时间换空间”的方式，而ThreadLocal采用了“以空间换时间”的方式**。前者仅提供一份变量，让不同的线程排队访问，而后者为每一个线程都提供了一份变量，因此可以同时访问而互不影响。 

Spring使用ThreadLocal解决线程安全问题 

> 若每个线程中对全局变量、静态变量只有读操作，而无写操作，一般来说，这个全局变量是线程安全的；若有多个线程同时执行写操作，一般都需要考虑线程同步，否则就可能影响线程安全。
>
> 1. 常量始终是线程安全的，因为只存在读操作。 
> 2. 每次调用方法前都新建一个实例是线程安全的，因为不会访问共享的资源。
> 3. 局部变量是线程安全的。因为每执行一个方法，都会在独立的空间创建局部变量，它不是共享的资源。局部变量包括方法的参数变量和方法内变量。

- 有状态就是有数据存储功能。有状态对象(Stateful Bean)，就是有实例变量的对象  ，可以保存数据，是非线程安全的。在不同方法调用间不保留任何状态。
- 无状态就是一次操作，不能保存数据。无状态对象(Stateless Bean)，就是没有实例变量的对象  .不能保存数据，是不变类，是线程安全的。

无状态的Bean适合用不变模式，技术就是单例模式，这样可以共享实例，提高性能。有状态的Bean，多线程环境下不安全，那么适合用Prototype原型模式。Prototype: 每次对bean的请求都会创建一个新的bean实例。

> Struts2默认的实现是Prototype模式。也就是每个请求都新生成一个Action实例，所以不存在线程安全问题。需要注意的是，如果由Spring管理action的生命周期， scope要配成prototype作用域

#### Spring  IOC容器初始化过程

IoC容器  全称Inversion of Control，即控制反转，即  

**把某些业务对象的的控制权交给一个平台或者框架来同一管理，这个同一管理的平台可以称为IoC容器。**

Spring中有两个主要的容器系列：

- 实现BeanFactory接口的简单容器；
- 实现ApplicationContext接口的高级容器。

> ApplicationContext比较复杂，它不但继承了BeanFactory的大部分属性，还继承其它可扩展接口，扩展的了许多高级的属性.
>
> 在BeanFactory子类中有一个**DefaultListableBeanFactory**类，它包含了基本Spirng IoC容器所具有的重要功能，开发时不论是使用BeanFactory系列还是ApplicationContext系列来创建容器基本都会使用到DefaultListableBeanFactory类，可以这么说，在spring中实际上把它当成默认的IoC容器来使用。

IoC容器的初始化过程可以分为三步：

- Resource定位（Bean的定义文件定位）
- 将Resource定位好的资源载入到BeanDefinition
- 将BeanDefiniton注册到容器中

**第一步：Resource定位**

Resource是Sping中用于封装I/O操作的接口。在创建spring容器时，通常要访问XML配置文件，除此之外还可以通过访问文件类型、二进制流等方式访问资源，还有当需要网络上的资源时可以通过访问URL，Spring把这些文件统称为Resource。

常用的resource资源类型如下：

- **FileSystemResource：**以文件的绝对路径方式进行访问资源，效果类似于Java中的File;
- **ClassPathResourcee：**以类路径的方式访问资源，效果类似于this.getClass().getResource("/").getPath();
- **ServletContextResource：**web应用根目录的方式访问资源，效果类似于request.getServletContext().getRealPath("");
- **UrlResource：**访问网络资源的实现类。例如file: http: ftp:等前缀的资源对象;
- **ByteArrayResource: **访问字节数组资源的实现类。

Spring提供了ResourceLoader接口用于实现不同的Resource加载策略，该接口的实例对象中可以获取一个resource对象，也就是说将不同Resource实例的创建交给ResourceLoader的实现类来处理。

> 注：ApplicationContext的所有实现类都实现RecourceLoader接口，因此可以直接调用getResource（参数）获取Resoure对象**。**不同的ApplicatonContext实现类使用getResource方法取得的资源类型不同，例如：FileSystemXmlApplicationContext.getResource获取的就是FileSystemResource实例；ClassPathXmlApplicationContext.gerResource获取的就是ClassPathResource实例；XmlWebApplicationContext.getResource获取的就是ServletContextResource实例，另外像不需要通过xml直接使用注解@Configuation方式加载资源的AnnotationConfigApplicationContext等等。

在资源定位过程完成以后，就为资源文件中的bean的载入创造了I/O操作的条件。

**第二步：通过返回的resource对象，进行BeanDefinition的载入**

BeanDefinition相当于一个数据结构，这个数据结构的生成过程是根据定位的resource资源对象中的bean而来的，这些bean在Spirng IoC容器内部表示成了的BeanDefintion这样的数据结构，IoC容器对bean的管理和依赖注入的实现都是通过操作BeanDefinition来进行的。

在Spring中配置文件主要格式是XML，对于用来读取XML型资源文件来进行初始化的IoC 容器而言，该类容器会使用到AbstractXmlApplicationContext类，该类定义了一个名为loadBeanDefinitions(DefaultListableBeanFactory beanFactory) 的方法用于获取BeanDefinition。

这些容器会创建一个**XmlBeanDefinitionReader类**对象专门用来载入所有的BeanDefinition。

**第三步：将BeanDefiniton注册到容器中**

最终Bean配置会被解析成BeanDefinition并与beanName,Alias一同封装到**BeanDefinitionHolder类**中， 之后beanFactory.registerBeanDefinition(beanName, bdHolder.getBeanDefinition())，注册到**DefaultListableBeanFactory**.beanDefinitionMap中。之后客户端如果要获取Bean对象，Spring容器会根据注册的BeanDefinition信息进行实例化。

##### 容器初始化流程图

Spring 启动时读取应用程序提供的Bean配置信息，并在Spring容器中生成一份相应的Bean配置注册表，然后根据这张注册表实例化Bean，装配号Bean之间的依赖关系，为上层应用提供准备就绪的运行环境。

![](https://images2015.cnblogs.com/blog/517313/201607/517313-20160727114343684-1872047900.jpg)

该图描述了Spring容器从加载配置文件到创建出一个完整Bean的作业流程：

![](https://images2015.cnblogs.com/blog/517313/201606/517313-20160607151122855-1777635642.jpg)



### Spring面试题

#### Spring 在框架整合中起什么作用

Spring：轻量级框架  作用：Bean工厂，用来管理Bean的生命周期和框架集成。

两大核心：
①. IOC/DI(控制反转/依赖注入) ：把dao依赖注入到service层，service层反转给action层，Spring顶层容器为BeanFactory。
②. AOP：面向切面编程

#### ？ Spring的优点 

- **控制反转：**Spring通过控制反转实现了**松散耦合**，对象们给出它们的依赖，而不是创建或查找依赖的对象们。
- **面向切面的编程(AOP)：**Spring支持面向切面的编程，并且把应用**业务逻辑和系统服务分开**。
- **MVC框架：**Spring的WEB框架是个精心设计的框架，是Web框架的一个很好的替代品。
- **低侵入式设计，代码污染极低,独立于各种应用服务器，基于Spring框架的应用，可以真正实现Write Once,Run Anywhere的承诺。**
- **集成能力强：**集成多种优秀的开源框架。（Hibernate、Struts、Hessian等）。
- **异常处理：**Spring 提供方便的API把具体技术相关的异常（比如由JDBC，Hibernate or JDO抛出的）转化为一致的unchecked 异常。
- **容器：**Spring 包含并管理应用中对象的生命周期和配置。
- **轻量：**Spring 是轻量的，基本的版本大约2MB。

#### ？ IOC 在项目中的作用

作用：Ioc解决对象之间的依赖问题，把所有Bean的依赖关系通过配置文件或注解关联起来，降低了耦合度。

#### ？ Spring的配置文件中的内容

- 开启事务注解驱动
- 事务管理器
- 开启注解功能，并配置扫描包
- 配置数据库
- 配置SQL会话工厂，别名，映射文件
- 不用编写Dao层的实现类

#### ？ Spring  DI的三种方式

- 构造器注入：通过构造方法初始化

  <constructor-arg index="0" type="java.lang.String" value="宝马"></constructor-arg>

- setter方法注入：通过setter方法初始化

  <property name="id" value="1111"></property>

- 接口注入

#### ？ Spring AOP IOC 的实现原理

IOC：通过反射机制生成对象注入

IOC(控制反转)或DI（依赖注入）:明确定义组件的接口，独立开发各个组件，然后根据组件的依赖关系组装运行；即将创建及管理对象的权利交给Spring容器。Spring是一个轻型容器(light-weight Container)，其核心是Bean工厂(Bean Factory)，用以构造我们所需要的M(Model）。能够让相互协作的软件组件保持松散耦合。降低了业务对象替换的复杂性，提高了组件之间的解耦。

AOP：动态代理

AOP(面向切面编程)：通过预编译方式和运行期动态代理实现在不修改源代码的情况下给程序动态统一添加功能的一种技术。即系统级的服务从代码中解耦出来。例如：将日志记录，性能统计，安全控制，事务处理，异常处理等代码从业务逻辑代码中划分出来。允许你把遍布应用各处的功能分离出来形成可重用组件。

#### ？ 如何理解控制反转

Ioc—Inversion of Control，即“控制反转”，不是什么技术，而是一种设计思想。在Java开发中，Ioc意味着将你设计好的对象交给容器控制，而不是传统的在你的对象内部直接控制。

- 谁控制谁，控制什么：传统Java SE程序设计，我们直接在对象内部通过new进行创建对象，是程序主动去创建依赖对象；而IoC是有专门一个容器来创建这些对象，即由Ioc容器来控制对象的创建；**谁控制谁？当然是IoC 容器控制了对象；控制什么？那就是主要控制了外部资源获取（不只是对象包括比如文件等）。**
- 为何是反转，哪些方面反转了：有反转就有正转，传统应用程序是由我们自己在对象中主动控制去直接获取依赖对象，也就是正转；而反转则是由容器来帮忙创建及注入依赖对象；为何是反转？**因为由容器帮我们查找及注入依赖对象，对象只是被动的接受依赖对象，所以是反转；哪些方面反转了？依赖对象的获取被反转了。**

#### ？ 如何理解依赖注入

**DI—Dependency Injection，即“依赖注入”**：**组件之间依赖关系**由容器在运行期决定，形象的说，即**由容器动态的将某个依赖关系注入到组件之中**。**依赖注入的目的并非为软件系统带来更多功能，而是为了提升组件重用的频率，并为系统搭建一个灵活、可扩展的平台。**通过依赖注入机制，我们只需要通过简单的配置，而无需任何代码就可指定目标需要的资源，完成自身的业务逻辑，而不需要关心具体的资源来自何处，由谁实现。

- 谁依赖于谁：当然是**应用程序依赖于IoC容器**；
- 为什么需要依赖：**应用程序需要IoC容器来提供对象需要的外部资源**；
- 谁注入谁：很明显是**IoC容器注入应用程序某个对象，应用程序依赖的对象**；
- 注入了什么：就是**注入某个对象所需要的外部资源（包括对象、资源、常量数据）**。

#### ？BeanFactory和ApplicationContext有什么区别 

BeanFactory负责读取bean配置文档，管理bean的加载，实例化，维护bean之间的依赖关系，负责bean的声明周期。

ApplicationContext除了提供上述BeanFactory所能提供的功能之外，还提供了更完整的框架功能：

- 国际化支持
- 资源访问：Resource rs = ctx. getResource(“classpath:config.properties”), “file:c:/config.properties”
- 事件传递：通过实现ApplicationContextAware接口
- 载入多个（有继承关系）上下文 ，使得每一个上下文都专注于一个特定的层次，比如应用的web层  

> .BeanFactroy采用的是延迟加载形式来注入Bean的，即只有在使用到某个Bean时(调用getBean())，才对该Bean进行加载实例化，这样，我们就不能发现一些存在的[spring](http://lib.csdn.net/base/javaee)的配置问题。而ApplicationContext则相反，它是在容器启动时，一次性创建了所有的Bean。这样，在容器启动时，我们就可以发现Spring中存在的配置错误。 
>
> BeanFactory和ApplicationContext都支持BeanPostProcessor、BeanFactoryPostProcessor的使用，但两者之间的区别是：BeanFactory需要手动注册，而ApplicationContext则是自动注册

#### ? Spring有几种配置方式

spring有三种配置方式

- 传统的XML配置方式
- 基于注解的配置
- 基于类的Java Config

##### Explicit configuration in XML：显示的XML配置

优点：

1. XML配置方式进一步降低了耦合，使得应用更加容易扩展，即使对配置文件进一步修改也不需要工程进行修改和重新编译。
2. 在处理大的业务量的时候，用XML配置应该更加好一些。

缺点：

1. 配置文件读取和解析需要花费一定的时间，配置文件过多的时候难以管理。
2. 无法对配置的正确性进行校验，增加了测试难度。

##### Implicit bean discovery and automatic wiring：隐式的bean扫描，基于java注解配置，自动注入

@Component：标注一个普通的Spring Bean类

在方法处通过@Autowired使方法入参绑定Bean，然后在方法中通过代码进行注入

优点：

1. 在class文件中，降低维护成本
2. 不需要第三方解析工具，利用java反射机制
3. 编辑期就可以检验正确性，提高开发效率

缺点：

1. 如果需要对annotation进行修改，那么要重新编译整个工程。
2. 业务类之间的关系不如XML配置那样容易把握。
3. 如果在程序中annotation比较多，直接影响代码质量，对于代码的简洁度有影响。
4. 符合条件的多个bean注入时，spring不知道如何选择，会有异常NoUniqueBeanDefinitionException。

##### Explicit configuration in Java：显示的JavaConfig，基于java类配置。

在标注了@Configuration的java类中，通过在类方法标注@Bean定义一个Bean。

 通过在成员变量或者方法入参处标注@Autowired按类型匹配注入，也可以使用@Qualifier按名称配置注入。

优点：

1. 在class文件中，降低维护成本。
2. 不需要第三方解析工具。
3. 编辑期就可以检验正确性，提高开发效率。

缺点：

1. 配置代码过多时，直接影响代码质量，对于代码的简洁度有影响。
2. 业务类之间的关系不如XML配置那样容易把握。
3. 如果需要修改配置，则要重新编译整个工程。

#### ？ spring Bean的生命周期

![](https://images0.cnblogs.com/i/580631/201405/181453414212066.png)

Bean的完整生命周期经历了各种方法调用，这些方法可以划分为以下几类：

- Bean自身的方法：这个包括了Bean本身调用的方法和通过配置文件中<bean>的init-method和destroy-method指定的方法
- Bean级生命周期接口方法：这个包括了BeanNameAware、BeanFactoryAware、InitializingBean和DiposableBean这些接口的方法
- 容器级生命周期接口方法：这个包括了InstantiationAwareBeanPostProcessor 和 BeanPostProcessor 这两个接口实现，一般称它们的实现类为“后处理器”。
- 工厂后处理器接口方法：这个包括了AspectJWeavingEnabler, ConfigurationClassPostProcessor, CustomAutowireConfigurer等等非常有用的工厂后处理器接口的方法。工厂后处理器也是容器级的。在应用上下文装配配置文件之后立即调用。

> 一个Bean从创建到销毁，如果是用BeanFactory来生成,管理Bean的话，会经历几个执行阶段
>
> - Bean的建立：容器寻找Bean的定义信息并将其实例化。
> - 属性注入：使用依赖注入，Spring按照Bean定义信息配置Bean所有属性
> - BeanNameAware的setBeanName()：如果Bean类有实现org.springframework.beans.BeanNameAware接口，工厂调用Bean的setBeanName()方法传递Bean的ID。
> - BeanFactoryAware的setBeanFactory()：如果Bean类有实现org.springframework.beans.factory.BeanFactoryAware接口，工厂调用setBeanFactory()方法传入工厂自身。
> - BeanPostProcessors的ProcessBeforeInitialization():如果有org.springframework.beans.factory.config.BeanPostProcessors和Bean关联，那么其postProcessBeforeInitialization()方法将被调用。
> - initializingBean的afterPropertiesSet()：如果Bean类已实现org.springframework.beans.factory.InitializingBean接口，则执行他的afterProPertiesSet()方法
> - Bean定义文件中定义init-method
> - BeanPostProcessors的ProcessaAfterInitialization()如果有任何的BeanPostProcessors实例与Bean实例关联，则执行BeanPostProcessors实例的ProcessaAfterInitialization()方法
>
> 此时，Bean已经可以被应用系统使用，并且将保留在BeanFactory中直到它不再被使用。有两种方法可以将其从BeanFactory中删除掉：
>
> - DisposableBean的destroy()： 在容器关闭时，如果Bean类有实现org.springframework.beans.factory.DisposableBean接口，则执行他的destroy()方法
> - Bean定义文件中定义destroy-method : 在容器关闭时，可以在Bean定义文件中使用"destroy-method"属性设定方法名称，
>
> 如果是使用ApplicationContext来生成并管理Bean的话则稍有不同，使用ApplicationContext来生成及管理Bean实例的话，在执行BeanFactoryAware的setBeanFactory()阶段后，若Bean类上有实现org.springframework.context.ApplicationContextAware接口，则执行其setApplicationContext()方法，接着才执行BeanPostProcessors的ProcessBeforeInitialization()及之后的流程。

> Spring上下文中的Bean也类似:
>
> 1. 实例化一个Bean－－也就是我们常说的new；
> 2. 按照Spring上下文对实例化的Bean进行配置－－也就是IOC注入；
> 3. 如果这个Bean已经实现了BeanNameAware接口，会调用它实现的setBeanName(String)方法，此处传递的就是Spring配置文件中Bean的id值
> 4. 如果这个Bean已经实现了BeanFactoryAware接口，会调用它实现的setBeanFactory(setBeanFactory(BeanFactory)传递的是Spring工厂自身（可以用这个方式来获取其它Bean，只需在Spring配置文件中配置一个普通的Bean就可以）；
> 5. 如果这个Bean已经实现了ApplicationContextAware接口，会调用setApplicationContext(ApplicationContext)方法，传入Spring上下文（同样这个方式也可以实现步骤4的内容，但比4更好，因为ApplicationContext是BeanFactory的子接口，有更多的实现方法）；
> 6. 如果这个Bean关联了BeanPostProcessor接口，将会调用postProcessBeforeInitialization(Object obj, String s)方法，BeanPostProcessor经常被用作是Bean内容的更改，并且由于这个是在Bean初始化结束时调用那个的方法，也可以被应用于内存或缓存技术；
> 7. 如果Bean在Spring配置文件中配置了init-method属性会自动调用其配置的初始化方法。
> 8. 如果这个Bean关联了BeanPostProcessor接口，将会调用postProcessAfterInitialization(Object obj, String s)方法、；
> 9. 当Bean不再需要时，会经过清理阶段，如果Bean实现了DisposableBean这个接口，会调用那个其实现的destroy()方法；
> 10. 最后，如果这个Bean的Spring配置中配置了destroy-method属性，会自动调用其配置的销毁方法。

#### ? spring bean 的自动装配

- Spring IOC容器可以自动装配Bean，需要做的仅仅是在的autowire属性里指定自动装配的模式
- byType（根据类型自动装配）：若IOC容器中有多个与目标Bean类型一致的Bean，在这种情况下，Spring将无法判定哪个Bean最合适该属性，所以不能执行自动装配
- byName（根据名称自动装配）：必须将目标Bean的名称和属性名设置的完全相同
- constructor（通过构造器自动装配）：当Bean中存在多个构造器时，此种自动装配方式将会很复杂，不推荐使用

#### ？ Autowired注解详解

通过@Autowired注解对Bean的属性变量.属性Setter方法以及构造函数进行标注,配合AutowiredAnnotationBeanProcessor完成Bean的自动配置。使用@Autowired注释进行byType注入。

> 当不能确定 Spring 容器中一定拥有某个类的 Bean 时，可以在需要自动注入该类 Bean 的地方可以使用 @Autowired(required = false) ，这等于告诉 Spring：在找不到匹配 Bean 时也不报错。

**@Qualifier**

使用@Autowired注释进行byType注入，如果需要byName（byName就是通过id去标识）注入，增加@Qualifier注释。一般在候选Bean数目不为1时应该加@Qualifier注释。

在默认情况下使用 @Autowired 注释进行自动注入时，Spring 容器中匹配的候选 Bean 数目必须有且仅有一个。当找不到一个匹配的 Bean 时，Spring 容器将抛出BeanCreationException 异常，并指出必须至少拥有一个匹配的 Bean。

@Autowired可以对成员变量、方法以及构造函数进行注释，而@Qualifier的标注对象是成员变量、方法入参、构造函数入参。正是由于注释对象的不同，所以Spring不将 @Autowired和@Qualifier统一成一个注释类。

@Qualifier 只能和@Autowired 结合使用，是对@Autowired有益的补充。

一般来讲，@Qualifier对方法签名中入参进行注释会降低代码的可读性，而对成员变量注释则相对好一些。

**@Resource**

Spring不但支持自己定义的@Autowired注解，还支持几个由JSR-250规范定义的注解，它们分别是@Resource、@PostConstruct以及@PreDestroy。

@Resource的作用相当于@Autowired，只不过@Autowired按byType自动注入，而@Resource默认按 byName自动注入罢了。@Resource有两个属性是比较重要的，分是name和type，Spring将@Resource注解的name属性解析为bean的名字，而type属性则解析为bean的类型。所以如果使用name属性，则使用byName的自动注入策略，而使用type属性时则使用byType自动注入策略。如果既不指定name也不指定type属性，这时将通过反射机制使用byName自动注入策略。

@Resource装配顺序：

- 如果同时指定了name和type，则从Spring上下文中找到唯一匹配的bean进行装配，找不到则抛出异常
- 如果指定了name，则从上下文中查找名称（id）匹配的bean进行装配，找不到则抛出异常
-  如果指定了type，则从上下文中找到类型匹配的唯一bean进行装配，找不到或者找到多个，都会抛出异常
- 如果既没有指定name，又没有指定type，则自动按照byName方式进行装配；如果没有匹配，则回退为一个原始类型进行匹配，如果匹配则自动装配；

#### ？ 构造方法注入和setter注入有什么区别

**Spring的依赖注入有三种方式:**

1. 构造器注入
2. setter注入
3. 接口注入

**构造器注入**

主要是依赖于构造方法去实现,构造方法可以是有参也可以是无参,我们在平常都是通过类的构造方法来创建类对象,以及给他赋值,同样Spring 也可以采用反射的方式,通过构造方法来完成注入注入(赋值),这就是构造器注入的原理.

```
<bean id="Role" class="com.xiaojiang.Spring.Role">
        <constructor-arg value="1" type="int"></constructor-arg>
        <constructor-arg value="小江" type="java.lang.String"></constructor-arg>
        <constructor-arg value="有点丑" type="java.lang.String"></constructor-arg>
    </bean>
```

constructor-arg元素用于定义类构造方法的参数,其中type用于定义参数的类型,也可以使用index来定义参数的位置,而这里的value是用于设置值,以上的代码就是通过一个Spring去装配一个Bean。

**setter注入**

是Spring现在最主流的注入方式,它可以利用Java Bean 规范所定义set/get方法来完成注入,可读性灵活性高,它不需要使用构造器注入时出现的多个参数,它可以把构造方法声明成无参构造,再使用setter注入设置相对应的值,其实也是通过java反射技术去实现的.

```
<bean id="Role" class="com.xiaojiang.Spring.Role">
        <property name="id" value="1"><property>
        <property name="roleName" value="小江"><property>
        <property name="note" value="测试"><property>
</bean>  
```

#### ? Spring框架的事件

- ContextRefreshedEvent   ： ApplicationContext初始化或者被更新是会触发，ConfigurableApplicationContext接口中的refresh()方法被调用会触发
- ContextStartedEvent ：ConfigurableApplicationContext接口中的start()方法被调用会触发
- ContextStoppededEvent：ConfigurableApplicationContext接口中的stop()方法被调用会触发
- ContextClosedEvent：AppliactionContext被关闭时触发该事件，所有容器管理的单例bean被销毁。
- RequestHandledEvent：当一个http请求结束时触发该事件

如果一个bean实现了ApplicationListener接口，当一个ApplicationEvent被发布后，遍历所有监听器，对于每一个监听器来说其实都可以获取到监听事件，但是是否进行处理则由事件监听器来决定，如果要处理，使用onApplicationEvent()方法来进行监听器的处理

自定义监听事件，需要ApplicationEvent接口，ApplicationContext使用publishEvent()方法来发布事件。



## springMVC

### Web MVC模式

![](https://mmbiz.qpic.cn/mmbiz_png/hvUCbRic69sDVG1qdQ3e2k6YD4W6k4xhfDzSQgMjCruU78eKsspOO2tiadnGia6NicjBnBUdWSicaTevus499ic8hMaw/640?tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

#### SpringMVC介绍及使用

SpringMVC 框架是以请求为驱动，围绕 Servlet 设计，将请求发给控制器，然后通过模型对象，分派器来展示请求结果视图。其中核心类是 DispatcherServlet，它是一个 Servlet，顶层是实现的Servlet接口。

> 需要在 web.xml 中配置 DispatcherServlet 。并且需要配置 Spring 监听器ContextLoaderListener

```
<listener>
    <listener-class>org.springframework.web.context.ContextLoaderListener
    </listener-class>
</listener>
<servlet>
    <servlet-name>springmvc</servlet-name>
    <servlet-class>org.springframework.web.servlet.DispatcherServlet
    </servlet-class>
    <!-- 如果不设置init-param标签，则必须在/WEB-INF/下创建xxx-servlet.xml文件，其中xxx是servlet-name中配置的名称。 -->
    <init-param>
        <param-name>contextConfigLocation</param-name>
        <param-value>classpath:spring/springmvc-servlet.xml</param-value>
    </init-param>
    <load-on-startup>1</load-on-startup>
</servlet>
<servlet-mapping>
    <servlet-name>springmvc</servlet-name>
    <url-pattern>/</url-pattern>
</servlet-mapping>
```

#### springMVC工作原理

> 流程简述：
>
> 客户端发送请求-> 前端控制器 DispatcherServlet 接受客户端请求 -> 找到处理器映射 HandlerMapping 解析请求对应的 Handler-> HandlerAdapter 会根据 Handler 来调用真正的处理器开处理请求，并处理相应的业务逻辑 -> 处理器返回一个模型视图 ModelAndView -> 视图解析器进行解析 -> 返回一个视图对象->前端控制器 DispatcherServlet 渲染数据（Moder）->将得到视图对象返回给用户

![](https://mmbiz.qpic.cn/mmbiz_png/hvUCbRic69sDVG1qdQ3e2k6YD4W6k4xhfLcuuo0xyJOVTRbGSQzueyj45Nrew5VVf5JjJvr17wGc6XqZQlQuiabA/640?tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

流程说明：

- 客户端（浏览器）发送请求，直接请求到 DispatcherServlet
- DispatcherServlet 根据请求信息调用 HandlerMapping，解析请求对应的 Handler
- 解析到对应的 Handler（也就是我们平常说的 Controller 控制器）后，开始由 HandlerAdapter 适配器处理
- HandlerAdapter 会根据 Handler 来调用真正的处理器开处理请求，并处理相应的业务逻辑
- 处理器处理完业务后，会返回一个 ModelAndView 对象，Model 是返回的数据对象，View 是个逻辑上的 View
- ViewResolver 会根据逻辑 View 查找实际的 View
- DispaterServlet 把返回的 Model 传给 View（视图渲染）
- 把 View 返回给请求者（浏览器）

#### Springmvc重要组件

**前端控制器DispatcherServlet（不需要工程师开发）,由框架提供（重要）**

作用：Spring MVC 的入口函数。接收请求，响应结果，相当于转发器，中央处理器。有了 DispatcherServlet 减少了其它组件之间的耦合度。用户请求到达前端控制器，它就相当于mvc模式中的c，DispatcherServlet是整个流程控制的中心，由它调用其它组件处理用户的请求，DispatcherServlet的存在降低了组件之间的耦合性。

**处理器映射器HandlerMapping(不需要工程师开发),由框架提供**

作用：根据请求的url查找Handler。HandlerMapping负责根据用户请求找到Handler即处理器（Controller），SpringMVC提供了不同的映射器实现不同的映射方式，例如：配置文件方式，实现接口方式，注解方式等。

**处理器适配器HandlerAdapter**

作用：按照特定规则（HandlerAdapter要求的规则）去执行Handler通过HandlerAdapter对处理器进行执行，这是适配器模式的应用，通过扩展适配器可以对更多类型的处理器进行执行。

**处理器Handler(需要工程师开发)**

注意：编写Handler时按照HandlerAdapter的要求去做，这样适配器才可以去正确执行Handler
Handler 是继DispatcherServlet前端控制器的后端控制器，在DispatcherServlet的控制下Handler对具体的用户请求进行处理。
由于Handler涉及到具体的用户业务请求，所以一般情况需要工程师根据业务需求开发Handler。

**视图解析器View resolver(不需要工程师开发),由框架提供**

作用：进行视图解析，根据逻辑视图名解析成真正的视图（view）
View Resolver负责将处理结果生成View视图，View Resolver首先根据逻辑视图名解析成物理视图名即具体的页面地址，再生成View视图对象，最后对View进行渲染将处理结果通过页面展示给用户。 springmvc框架提供了很多的View视图类型，包括：jstlView、freemarkerView、pdfView等。
一般情况下需要通过页面标签或页面模版技术将模型数据通过页面展示给用户，需要由工程师根据业务需求开发具体的页面。

**视图View(需要工程师开发)**

View是一个接口，实现类支持不同的View类型（jsp、freemarker、pdf…）

> **注意：处理器Handler（也就是我们平常说的Controller控制器）以及视图层view都是需要我们自己手动开发的。其他的一些组件比如：前端控制器DispatcherServlet、处理器映射器HandlerMapping、处理器适配器HandlerAdapter等等都是框架提供给我们的，不需要自己手动开发。** 

#### DispatcherServlet详细解析

DispatcherServlet类中的属性beans：

- HandlerMapping：用于handlers映射请求和一系列的对于拦截器的前处理和后处理，大部分用@Controller注解。
- HandlerAdapter：帮助DispatcherServlet处理映射请求处理程序的适配器，而不用考虑实际调用的是 哪个处理程序。
- ViewResolver：根据实际配置解析实际的View类型。
- ThemeResolver：解决Web应用程序可以使用的主题，例如提供个性化布局。
- MultipartResolver：解析多部分请求，以支持从HTML表单上传文件。-
- FlashMapManager：存储并检索可用于将一个请求属性传递到另一个请求的input和output的FlashMap，通常用于重定向。

> 在Web MVC框架中，每个DispatcherServlet都拥自己的WebApplicationContext，它继承了ApplicationContext。WebApplicationContext包含了其上下文和Servlet实例之间共享的所有的基础框架beans。

**HandlerMapping**接口处理请求的映射HandlerMapping接口的实现类：

- SimpleUrlHandlerMapping类通过配置文件把URL映射到Controller类。
- DefaultAnnotationHandlerMapping类通过注解把URL映射到Controller类。

**HandlerAdapter**接口-处理请求映射

**AnnotationMethodHandlerAdapter**：通过注解，把请求URL映射到Controller类的方法上。

**HandlerExceptionResolver**接口-异常处理接口

- SimpleMappingExceptionResolver通过配置文件进行异常处理。
- AnnotationMethodHandlerExceptionResolver：通过注解进行异常处理。

**ViewResolver**接口解析View视图。

**UrlBasedViewResolver**类 通过配置文件，把一个视图名交给到一个View来处理。

#### **SpringMVC的九大组件**

- initMultipartResolver(context);  

  用于处理上传请求。处理方法是将普通的request包装成MultipartHttpServletRequest，后者可以直接调用getFile方法获取File.

- initLocaleResolver(context); 

  SpringMVC主要有两个地方用到了Locale：一是ViewResolver视图解析的时候；二是用到国际化资源或者主题的时候。

- initThemeResolver(context); 

  用于解析主题。SpringMVC中一个主题对应 一个properties文件，里面存放着跟当前主题相关的所有资源、如图片、css样式等。SpringMVC的主题也支持国际化， 

- initHandlerMappings(context);  

  用来查找Handler的。

- initHandlerAdapters(context); 

  从名字上看，它就是一个适配器。Servlet需要的处理方法的结构却是固定的，都是以request和response为参数的方法。//如何让固定的Servlet处理方法调用灵活的Handler来进行处理呢？这就是HandlerAdapter要做的事情

- initHandlerExceptionResolvers(context); 

  其它组件都是用来干活的。在干活的过程中难免会出现问题，出问题后怎么办呢？//这就需要有一个专门的角色对异常情况进行处理，在SpringMVC中就是HandlerExceptionResolver。

- initRequestToViewNameTranslator(context);

  有的Handler处理完后并没有设置View也没有设置ViewName，这时就需要从request获取ViewName了，//如何从request中获取ViewName就是RequestToViewNameTranslator要做的事情了。

- initViewResolvers(context); 

  ViewResolver用来将String类型的视图名和Locale解析为View类型的视图。//View是用来渲染页面的，也就是将程序返回的参数填入模板里，生成html（也可能是其它类型）文件。

- initFlashMapManager(context);

  用来管理FlashMap的，FlashMap主要用在redirect重定向中传递参数。

#### SpringMVC常用注解说明

@Controller

在类上面定义，表明该类为控制器，返回字符串与redirect:xxx

@RequestMapping

在类或方法上面使用此注解，设置URL访问地址。它有两个属性，value指定访问路径，method指定指定请求方式，请求方式在RequestMethod这个类中，全部以常量形式定义，它默认使用GET请求。

@RequestParam

指定Request请求参数，在方法参数中定义，相当于传统的request.getParameter()。

@PathVariable

获取URL访问路径变量，这是Spring MVC 3.0框架才加入的特性，基于RESTful风格的URL访问路径。

@ModelAttribute

全局式的方法，在一组URL访问路径中，每次都会执行，方法返回结果保存在module会话中。

@Service

在类上面定义，指定被注解的类是业务逻辑组件，如果不指定具体的Bean ID，则采用默认命名方式，即类名的首字母小写。

@Autowired

IoC自动注入功能，替换以前的set写法，在SSH2中就已经开始使用了。

@Qualifier

对同一接口类有不同实现指定具体的实现类。

@ResponseBody

同样定义在方法上，Ajax调用声明，指定方法返回结果为Ajax回调函数结果。这是Spring MVC3.0框架中增加的一个新特性。

@InitBinder

初始化数据绑定与类型转换，将传入的参数转换为自定义类型，或者对参数进行自定义处理。

### SpringMVC面试题

#### spring mvc如何匹配请求路径

@RequestMapping是用来映射请求的，比如get请求，post请求，或者REST风格与非REST风格的。 该注解可以用在类上或者方法上，如果用于类上，表示该类中所有方法的父路径。

RequestMapping可以实现模糊匹配路径：

- ? ：匹配一个字符
- ：匹配任意字符
- **：匹配多层路径

#### **spring mvc**如何获取请求的参数

**@PathVariable**

该注解用来映射请求URL中绑定的占位符。通过@PathVariable可以将URL中占位符的参数绑定到controller处理方法的入参中

```
@RequestMapping("/testPathVariable/{id}")
public String testPathVariable(@PathVariable(value="id") Integer id){
	//TODO
}
```

**@RequestParam**

```
@RequestMapping(value="/testRequestParam")
public String testRequestParam(@RequestParam(value="username") String username, @RequestParam(value="age", required=false, defaultValue="0") int age){
	//TODO
}
```

**利用REST风格实现增删改查**

```
//SpringMVCTest类中自下而上的实现了查（get）增（post）删（delete）和改（put）的接口
@RequestMapping(value="/testRest/{id}", method=RequestMethod.PUT)
public String testRestPut(@PathVariable(value="id") Integer id){
   System.out.println("test put:" + id);
   return SUCCESS;
}

@RequestMapping(value="/testRest/{id}", method=RequestMethod.DELETE)
public String testRestDelete(@PathVariable(value="id") Integer id){
   System.out.println("test delete:" + id);
   return SUCCESS;
}

@RequestMapping(value="/testRest", method=RequestMethod.POST)
public String testRest(){
   System.out.println("test post");
   return SUCCESS;
}

@RequestMapping(value="/testRest/{id}", method=RequestMethod.GET)
public String testRest(@PathVariable(value="id") Integer id){
   System.out.println("test get:" + id);
   return SUCCESS;
}
```

```
//对应前台页面
<form action="springmvc/testRest/1" method="post">
   <input type="hidden" name="_method" value= "PUT"/>
   <input type="submit" value="testRestPut"/>
</form><br/><br/>

<form action="springmvc/testRest/1" method="post">
   <input type="hidden" name="_method" value="DELETE"/>
   <input type="submit" value="TestRest DELETE"/>
</form><br><br>

<form action="springmvc/testRest" method="post">
   <input type="submit" value="testRestPost">
</form><br/><br/>

<a href="springmvc/testRest/1">testRest</a><br/><br/>
```

还需要在配置文件web.xml中添加支持将post转化为delete和put请求的声明

```
<!-- 配置HiddenHttpMethodFilter：可以把POST请求转为DELETE或POST请求 -->
<filter>
   <filter-name>HiddenHttpMethodFilter</filter-name>
   <filter-class>org.springframework.web.filter.HiddenHttpMethodFilter</filter-class>
</filter>

<filter-mapping>
   <filter-name>HiddenHttpMethodFilter</filter-name>
   <url-pattern>/*</url-pattern>
</filter-mapping>
```

**@CookieValue**

是一种映射，映射的是一个Cookie值

#### **关于REST**

1. 表述性状态转移，是web服务的一种架构风格，是一种思想，而非标准或软件。
2. 通常基于使用HTTP，URI，XML、JSON、HTML这些现广泛流行的协议。
3. 属于轻量级（使用时没有太多依赖，耦合性低），跨平台、跨语言的架构设计。

**REST式（RESTful）的web服务**

- Web service的两种标准：JAX-WS  、JAX-RS
- REST式的web服务是ROA（面向资源的架构）、执行JAX-RS标准

**REST架构原则**

1. 同一资源具有多种表现形式，比如xml,json；
2. 每个资源具有唯一资源标识符
3. 操作无状态(服务器只处理当前request,利用pool技术提高稳定性和性能)
4. 符合REST原则的架构方式即为 RESTful

**URI和URL**

uri  http://example.com/users/

url http://example.com/users/{user} ，带参

URI范围大于URL。

经验告诉我们，uri和url在定义时限定不要使用大写字母，使用中线 - 代替下划线_,参数列表应该被encode过

注：*[https 和http区别，https属于加密传输，更安全，需要收费]*

#### 使用springMVC做权限管理

1. SpringMVC具有统一的入口DispatcherServlet，所有的请求都通过DispatcherServlet。

   ```
   <!-- 初始化 DispatcherServlet时，该框架在 web应用程序WEB-INF目录中寻找一个名为[servlet-名称]-servlet.xml的文件，  
            并在那里定义相关的Beans，重写在全局中定义的任何Beans -->  
      <servlet>  
        <servlet-name>springMybatis</servlet-name>  
        <servlet-class>org.springframework.web.servlet.DispatcherServlet</servlet-class>  
        <load-on-startup>1</load-on-startup>  
      </servlet>  
      <servlet-mapping>  
        <servlet-name>springMybatis</servlet-name>  
        <!-- 所有的的请求，都会被DispatcherServlet处理 -->  
        <url-pattern>/</url-pattern>  
      </servlet-mapping>
   ```

2. 静态资源不拦截

    一般实现拦截器主要是为了权限管理，主要是拦截一些url请求，所以不对静态资源进行拦截。要过滤掉静态资源一般有两种方式：

   - 第一种是采用<mvc:default-servlet-handler />，（一般Web应用服务器默认的Servlet名称是"default"，所以这里我们激活Tomcat的defaultServlet来处理静态文件，在web.xml里配置如下代码即可：）

     ```
     <!--　该servlet为tomcat,jetty等容器提供,将静态资源映射从/改为/static/目录，如原来访问　http://localhost/foo.css　,现在http://localhost/static/foo.css　-->  
     <!-- 不拦截静态文件 -->  
     <servlet-mapping>  
         <servlet-name>default</servlet-name>  
         <url-pattern>/js/*</url-pattern>  
         <url-pattern>/css/*</url-pattern>  
         <url-pattern>/images/*</url-pattern>  
         <url-pattern>/fonts/*</url-pattern>  
     </servlet-mapping>
     ```

     > Tomcat, Jetty, JBoss, and GlassFish  默认 Servlet的名字 -- "default"
     >
     > Resin 默认 Servlet的名字 -- "resin-file"
     >
     > WebLogic 默认 Servlet的名字  -- "FileServlet"
     >
     > WebSphere  默认 Servlet的名字 -- "SimpleFileServlet"

     ```
     <mvc:default-servlet-handler 
     default-servlet-name="所使用的Web服务器默认使用的Servlet名称" />
     ```

   - 第二种是采用<mvc:resources />，在springmvc的配置文件中加入以下代码：

     ```
     <mvc:resources mapping="/js/**" location="/static_resources/javascript/"/>    
     <mvc:resources mapping="/styles/**" location="/static_resources/css/"/>    
     <mvc:resources mapping="/images/**" location="/static_resources/images/"/>
     ```

3. 自定义拦截器

   SpringMVC的拦截器HandlerInterceptorAdapter对应提供了三个preHandle，postHandle，afterCompletion方法。preHandle在业务处理器处理请求之前被调用。

   要想实现自己的权限管理逻辑，需要继承HandlerInterceptorAdapter并重写其三个方法。

   首先在springmvc.xml中加入自己定义的拦截器我的实现逻辑CommonInterceptor

   ```
   <!--配置拦截器, 多个拦截器,顺序执行 -->
   <mvc:interceptors>  
     <mvc:interceptor>  
       <!-- 匹配的是url路径， 如果不配置或/**,将拦截所有的Controller -->
       <mvc:mapping path="/" />
       <mvc:mapping path="/user/**" />
       <mvc:mapping path="/test/**" />
       <bean class="com.alibaba.interceptor.CommonInterceptor"></bean>  
     </mvc:interceptor>
     <!-- 当设置多个拦截器时，先按顺序调用preHandle方法，然后逆序调用每个拦截器的postHandle和afterCompletion方法 -->
   </mvc:interceptors>
   ```

#### ? SpringMvc 的控制器是不是单例模式，如果是，有什么问题，怎么解决

单例模式，在多线程访问时有线程安全问题 。不要用同步，在控制器里面不能写字段

#### ？ 前台多个参数，这些参数都是一个对象，快速得到对象

直接在方法中声明这个对象，SpringMvc就自动把属性赋值到这个对象里面

#### ？ SpringMvc中函数的返回值

String，ModelAndView，List，Set 等
一般String，Ajax请求，返回一个List集合

#### ？ SpringMvc中的转发和重定向

转发： return：“hello”

重定向 ：return：“redirect:hello.jsp”

#### ？ SpringMvc和Ajax之间的相互调用

通过JackSon框架把java里面对象直接转换成js可识别的json对象，具体步骤如下：

- 加入JackSon.jar
- 在配置文件中配置json的映射
- 在接受Ajax方法里面直接返回Object，list等，方法前面需要加上注解@ResponseBody

#### ？ springMVC与struts2  区别

- 入口不同

  Struts2：filter过滤器；SpringMvc：一个Servlet即前端控制器

- 开发方式不同：

  Struts2：基于类开发，传递参数通过类的属性，只能设置为多例

  基于方法开发(一个url对应一个方法)，请求参数传递到方法形参，可以为单例也可以为多例(建议单例)

- 请求方式不同：

  Struts2：值栈存储请求和响应的数据，通过OGNL存取数据

  SpringMvc：通过参数解析器将request请求内容解析，给方法形参赋值，将数据和视图封装成ModelAndView对象，最后又将ModelAndView中的模型数据通过request域传输到页面，jsp视图解析器默认使用的是jstl。

#### ？ SpringMvc支持跨域访问

跨域，即跨站HTTP请求(Cross-site HTTP request)，指发起请求的资源所在域不同于请求指向资源所在域的HTTP请求。

> 当使用前后端分离，后端主导的开发方式进行前后端协作开发时，常常有如下情景：
>
> - 后端开发完毕在服务器上进行部署并给前端API文档。
> - 前端在本地进行开发并向远程服务器上部署的后端发送请求。
>   在这种开发过程中，如果前端想要一边开发一边测试接口，就需要使用跨域的方式。

**通过注解的方式允许跨域**

可以在Controller类或其方法上加`@CrossOrigin`注解，来使之支持跨域。

```
@CrossOrigin(origins = "*", maxAge=3600)
@RestController@RequestMapping("/User")
public class UserController {
}
```

其中origins为CrossOrigin的默认参数，即跨域来源，*即任何来源，也可以是其他域名。例如：

```
@CrossOrigin("http://test.com")
@CrossOrigin(origins="http://test.com",maxAge=3600)
```

**通过配置文件的方式允许跨域**

在web.xml中添加如下配置：

```
 <filter-mapping>
        <filter-name>CorsFilter</filter-name>
        <url-pattern>/*</url-pattern>
    </filter-mapping>
```

使用这个Filter即可让整个服务器全局允许跨域。

## 设计模式

> 工厂模式可以分为三类:
>
> - 简单工厂模式（Simple Factory） 
> - 工厂方法模式（Factory Method） 
> - 抽象工厂模式（Abstract Factory） 
>
> > 这三种模式从上到下逐步抽象，并且更具一般性 
> >
> > 工厂模式分为两类：工厂方法模式（Factory Method）与抽象工厂模式（Abstract Factory）。
> >
> > 将简单工厂模式（Simple Factory）看为工厂方法模式的一种特例，两者归为一类。 

### 工厂方法模式

> 定义一个用于创建对象的接口，让子类决定实例化哪一个类，工厂方法使一个类的实例化延迟到其子类。在工厂方法模式中，核心的工厂类不再负责所有的对象的创建，而是将具体创建的工作交给子类去做。这个核心类则摇身一变，成为了一个抽象工厂角色，仅负责给出具体工厂子类必须实现的接口，而不接触哪一个类应当被实例化这种细节。

- 一个抽象产品类，可以派生出多个具体产品类。   
- 一个抽象工厂类，可以派生出多个具体工厂类。   
- 每个具体工厂类只能创建一个具体产品类的实例。

工厂方法模式组成：

- 抽象工厂角色： 这是工厂方法模式的核心，它与应用程序无关。是具体工厂角色必须实现的接口或者必须继承的父类。在java中它由抽象类或者接口来实现。 
- 具体工厂角色：它含有和具体业务逻辑有关的代码。由应用程序调用以创建对应的具体产品的对象。 
- 抽象产品角色：它是具体产品继承的父类或者是实现的接口。在java中一般有抽象类或者接口来实现。 
- 具体产品角色：具体工厂角色所创建的对象就是此角色的实例。在java中由具体的类来实现。 

#### 简单工厂模式 

> 属于类的创新型模式，又叫静态工厂方法模式（Static FactoryMethod Pattern）,是通过专门定义一个类来负责创建其他类的实例，被创建的实例通常都具有共同的父类。

 简单工厂模式中包含的角色及其相应的职责:

- 工厂角色（Creator）：这是简单工厂模式的核心，由它负责创建所有的类的内部逻辑。当然工厂类必须能够被外界调用，创建所需要的产品对象。
- 抽象（Product）产品角色：简单工厂模式所创建的所有对象的父类，注意，这里的父类可以是接口也可以是抽象类，它负责描述所有实例所共有的公共接口。
- 具体产品（Concrete Product）角色：简单工厂所创建的具体实例对象，这些具体的产品往往都拥有共同的父类。

**核心思想：有一个专门的类来负责创建实例的过程。**

优点：工厂类是整个模式的关键所在。它包含必要的判断逻辑，能够根据外界给定的信息，决定究竟应该创建哪个具体类的对象。用户在使用时可以直接根据工厂类去创建所需的实例，而无需了解这些对象是如何创建以及如何组织的。有利于整个软件体系结构的优化。

缺点：由于工厂类集中了所有实例的创建逻辑，这就直接导致一旦这个工厂出了问题，所有的客户端都会受到牵连；而且由于简单工厂模式的产品室基于一个共同的抽象类或者接口，这样一来，当产品的种类增加的时候，即有不同的产品接口或者抽象类的时候，工厂类就需要判断何时创建何种种类的产品，这就和创建何种种类产品的产品相互混淆在了一起，违背了单一职责，导致系统丧失灵活性和可维护性。而且更重要的是，简单工厂模式违背了“开放封闭原则”，就是违背了“系统对扩展开放，对修改关闭”的原则，因为当我新增加一个产品的时候必须修改工厂类，相应的工厂类就需要重新编译一遍。

### 抽象工厂模式

> 为创建一组相关或相互依赖的对象提供一个接口，而且无需指定他们的具体类。在以下情况下，适用于工厂方法模式:
>
> - (1) 当一个类不知道它所必须创建的对象的类的时候。
> - (2) 当一个类希望由它的子类来指定它所创建的对象的时候。
> - (3) 当类将创建对象的职责委托给多个帮助子类中的某一个，并且你希望将哪一个帮助子类是代理者这一信息局部化的时候。

- 多个抽象产品类，每个抽象产品类可以派生出多个具体产品类。   
- 一个抽象工厂类，可以派生出多个具体工厂类。   
- 每个具体工厂类可以创建多个具体产品类的实例。 

### 代理模式

> 为其他对象提供一种代理以控制对这个对象的访问。所谓代理，就是一个人或者机构代表另一个人或者机构采取行动。在一些情况下，一个客户不想或者不能够直接引用一个对象，而代理对象可以在客户端和目标对象之间起到中介的作用。
>
> 提供了对目标对象另外的访问方式;即通过代理对象访问目标对象.这样做的好处是:可以在目标对象实现的基础上,增强额外的功能操作,即扩展目标对象的功能.

**代理模式的关键点是:代理对象与目标对象.代理对象是对目标对象的扩展,并会调用目标对象.**

#### 静态代理

> 静态代理在使用时,需要定义接口或者父类,被代理对象与代理对象一起实现相同的接口或者是继承相同父类.

**优点**：可以做到在符合开闭原则的情况下对目标对象进行功能扩展。

**缺点**：我们得为每一个服务都得创建代理类，工作量太大，不易管理。同时接口一旦发生改变，代理类也得相应修改。

#### 动态代理

>  特点：
>
>  - 代理对象,不需要实现接口
>  - 代理对象的生成,是利用JDK的API,动态的在内存中构建代理对象(需要我们指定创建代理对象/目标对象实现的接口的类型)
>  - 动态代理也叫做:JDK代理,接口代理

**JDK中生成代理对象的API**      代理类所在包 :    ` java.lang.reflect.Proxy`

JDK实现代理只需要使用newProxyInstance方法,

```
static Object newProxyInstance(ClassLoader loader, 
            Class[] interfaces,InvocationHandler h )
```

该方法是在Proxy类中是静态方法,且接收的三个参数依次为:

- ClassLoader loader,:指定当前目标对象使用类加载器,获取加载器的方法是固定的
- Class[] interfaces,:目标对象实现的接口的类型,使用泛型方式确认类型
- InvocationHandler h:事件处理,执行目标对象的方法时,会触发事件处理器的方法,会把当前执行目标对象的方法作为参数传入

**注意**    代理对象不需要实现接口,但是目标对象一定要实现接口,否则不能用动态代理

```
/**
* 创建动态代理对象
* 动态代理不需要实现接口,但是需要指定接口类型
*/
public class ProxyFactory{

   //维护一个目标对象
   private Object target;
   public ProxyFactory(Object target){
       this.target=target;
   }

  //给目标对象生成代理对象
   public Object getProxyInstance(){
       return Proxy.newProxyInstance(
               target.getClass().getClassLoader(),
               target.getClass().getInterfaces(),
               new InvocationHandler() {
                   @Override
                   public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
                       System.out.println("开始事务2");
                       //执行目标对象方法
                       Object returnValue = method.invoke(target, args);
                       System.out.println("提交事务2");
                       return returnValue;
                   }
               }
       );
   }

}
```

```
// 目标对象
IUserDao target = new UserDao();
// 给目标对象，创建代理对象
IUserDao proxy = (IUserDao) new ProxyFactory(target).getProxyInstance();
```



#### CGLIB代理

> 以目标对象子类的方式类实现代理
>
> Cglib代理,也叫作子类代理,它是在内存中构建一个子类对象从而实现对目标对象功能的扩展.
>
> JDK的动态代理有一个限制,就是使用动态代理的对象必须实现一个或多个接口,如果想代理没有实现接口的类,就可以使用Cglib实现.
>
> Cglib包的底层是通过使用一个小而块的字节码处理框架ASM来转换字节码并生成新的类.不鼓励直接使用ASM,因为它要求你必须对JVM内部结构包括class文件的格式和指令集都很熟悉.

**Cglib子类代理实现方法:**

1. 需要引入cglib的jar文件,但是Spring的核心包中已经包括了Cglib功能,所以直接引入spring-core-3.2.5.jar即可.
2. 引入功能包后,就可以在内存中动态构建子类
3. 代理的类不能为final,否则报错
4. 目标对象的方法如果为final/static,那么就不会被拦截,即不会执行目标对象额外的业务方法.


> CGLib采用了非常底层的字节码技术，其原理是通过字节码技术为一个类创建子类，并在子类中采用方法拦截的技术拦截所有父类方法的调用，顺势织入横切逻辑。但因为采用的是继承，所以不能对final修饰的类进行代理。JDK动态代理与CGLib动态代理均是实现Spring AOP的基础。

```
/**
* Cglib子类代理工厂
* 对UserDao在内存中动态构建一个子类对象
*/
public class ProxyFactory implements MethodInterceptor{
   //维护目标对象
   private Object target;

   public ProxyFactory(Object target) {
       this.target = target;
   }

   //给目标对象创建一个代理对象
   public Object getProxyInstance(){
       //1.工具类
       Enhancer en = new Enhancer();
       //2.设置父类
       en.setSuperclass(target.getClass());
       //3.设置回调函数
       en.setCallback(this);
       //4.创建子类(代理对象)
       return en.create();

   }

   @Override
   public Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy) throws Throwable {
       System.out.println("开始事务...");

       //执行目标对象的方法
       Object returnValue = method.invoke(target, args);

       System.out.println("提交事务...");

       return returnValue;
   }
}
```

```
       //目标对象
       UserDao target = new UserDao();
       //代理对象
       UserDao proxy = (UserDao)new ProxyFactory(target).getProxyInstance();
```

> **总结**： 
>
>  **在Spring的AOP编程中:**
>
> 如果加入容器的目标对象有实现接口,用JDK代理.
> 如果目标对象没有实现接口,用Cglib代理.
>
> CGLIB创建的动态代理对象比JDK创建的动态代理对象的性能更高，但是CGLIB创建代理对象时所花费的时间却比JDK多得多。所以对于单例的对象，因为无需频繁创建对象，用CGLIB合适，反之使用JDK方式要更为合适一些。同时由于CGLib由于是采用动态创建子类的方法，对于final修饰的方法无法进行代理。

### 单例模式

确保一个类只有一个实例，而且自行实例化并向整个系统提供这个实例。单例模式注意事项：

只能使用单例类提供的方法得到单例对象，不要使用反射，否则将会实例化一个新对象。不要做断开单例类对象与类中静态引用的危险操作。多线程使用单例使用共享资源时，注意线程安全问题。

**实现要点**

- 声明为private来隐藏构造器
- private static Singleton实例
- 声明为public来暴露实例获取方法

单例模式主要追求三个方面性能

- 线程安全
- 调用效率高
- 延迟加载

> 单例模式有很多好处，它能够避免实例对象的重复创建，不仅可以减少每次创建对象的时间开销，还可以节约内存空间；能够避免由于操作多个实例导致的逻辑错误。如果一个对象有可能贯穿整个应用程序，而且起到了全局统一管理控制的作用，那么单例模式也许是一个值得考虑的选择。

#### 饿汉模式

```

public class Singleton{
    private static Singleton instance = new Singleton();
    private Singleton(){}
    public static Singleton newInstance(){
        return instance;
    }
}
```

> 好处是只在类加载的时候创建一次实例，不会存在多个线程创建多个实例的情况，避免了多线程同步的问题。它的缺点也很明显，即使这个单例没有用到也会被创建，而且在类加载之后就被创建，内存就被浪费了。
>
> 这种实现方式适合单例占用内存比较小，在初始化时就会被用到的情况。

#### 懒汉模式

```
public class Singleton{
    private static Singleton instance = null;
    private Singleton(){}
    public static Singleton newInstance(){
        if(null == instance){
            instance = new Singleton();
        }
        return instance;
    }
}
```

> 懒汉模式中单例是在需要的时候才去创建的，如果单例已经创建，再次调用获取接口将不会重新创建新的对象，而是直接返回之前创建的对象。
>
> 这里的懒汉模式并没有考虑线程安全问题，在多个线程可能会并发调用它的getInstance()方法，导致创建多个实例，因此需要加锁解决线程同步问题

**加锁版本**

```
public class Singleton{
    private static Singleton instance = null;
    private Singleton(){}
    public static synchronized Singleton newInstance(){
        if(null == instance){
            instance = new Singleton();
        }
        return instance;
    }
}
```

#### 双重校验锁

> 加锁的懒汉模式看起来即解决了线程并发问题，又实现了延迟加载，然而它存在着性能问题，依然不够完美。synchronized修饰的同步方法比一般方法要慢很多，如果多次调用getInstance()，累积的性能损耗就比较大了。因此就有了双重校验锁

```
public class Singleton {
    private static volatile Singleton instance = null;
    private Singleton(){}
    public static Singleton getInstance() {
        if (instance == null) {
            synchronized (Singleton.class) {
                if (instance == null) {
                    instance = new Singleton();
                }
            }
        }
        return instance;
    }
}
```

volatile的一个语义是禁止指令重排序优化，也就保证了instance变量被赋值的时候对象已经是初始化过的

#### 静态内部类

```
public class Singleton{
    private static class SingletonHolder{
        public static Singleton instance = new Singleton();
    }
    private Singleton(){}
    public static Singleton newInstance(){
        return SingletonHolder.instance;
    }
}
```

> 利用了类加载机制来保证只创建一个instance实例。它与饿汉模式一样，也是利用了类加载机制，因此不存在多线程并发的问题。不一样的是，它是在内部类里面去创建对象实例。这样的话，只要应用中不使用内部类，JVM就不会去加载这个单例类，也就不会创建单例对象，从而实现懒汉式的延迟加载。也就是说这种方式可以同时保证延迟加载和线程安全。

#### 枚举

```
public enum Singleton{
    instance;
    public void whateverMethod(){}    
}
```

> 其他的四种实现单例的方式都有共同的缺点：
>
> - 需要额外的工作来实现序列化，否则每次反序列化一个序列化的对象时都会创建一个新的实例。
> - 可以使用反射强行调用私有构造器
>
> 而枚举类很好的解决了这两个问题，使用枚举除了线程安全和防止反射调用构造器之外，还提供了自动序列化机制，防止反序列化的时候创建新的对象。

- 线程安全

- 由于枚举类的会在编译期编译为继承自java.lang.Enum的类，其构造函数为私有，不能再创建枚举对象，枚举对象的声明和初始化都是在static块中，所以由JVM的ClassLoader机制保证了线程的安全性。但是不能实现延迟加载

- 序列化

  由于枚举类型采用了特殊的序列化方法，从而保证了在一个JVM中只能有一个实例

**单例模式性能总结**

| 方式     | 优点                | 缺点     |
| ------ | ----------------- | ------ |
| 饿汉式    | 线程安全，调用效率高        | 不能延迟加载 |
| 懒汉式    | 线程安全，可以延长加载       | 调用效率不高 |
| 双重校验锁式 | 线程安全，调用效率高，可以延长加载 |        |
| 静态内部类式 | 线程安全，调用效率高，可以延长加载 |        |
| 枚举单例   | 线程安全，调用效率高        | 不能延迟加载 |

**其他参考** ：[单例模式的破坏与防御](https://blog.csdn.net/jq_ak47/article/details/54894793)

## JVM

### JVM加载class文件的原理机制

### Java垃圾回收机制

## 集合

### jdk7、jdk8的HashMap和ConcurrentMap

#### java7HashMap

![](https://mmbiz.qpic.cn/mmbiz_png/TNUwKhV0JpQ2dZ3WKkIM4iaa5WqfKFiaqjquyACpicqnxAGx7rVeqLicOSUxhd4BnUSwOz5XLtjnTdAvIkdwo3Ry0g/640?tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

HashMap 里面是一个**数组**，然后数组中每个元素是一个**单向链表**。

每个绿色实体是嵌套类 Entry 的实例，Entry 包含四个属性：key, value, hash 值和用于单向链表的 next。

capacity：当前数组容量，始终保持 2^n，可以扩容，扩容后数组大小为当前的 2 倍。

loadFactor：负载因子，默认为 0.75。

threshold：扩容的阈值，等于 capacity * loadFactor

##### put过程

```
public V put(K key, V value) {
    // 当插入第一个元素的时候，需要先初始化数组大小
    if (table == EMPTY_TABLE) {
        inflateTable(threshold);
    }
    // 如果 key 为 null，感兴趣的可以往里看，最终会将这个 entry 放到 table[0] 中
    if (key == null)
        return putForNullKey(value);
    // 1. 求 key 的 hash 值
    int hash = hash(key);
    // 2. 找到对应的数组下标
    int i = indexFor(hash, table.length);
    // 3. 遍历一下对应下标处的链表，看是否有重复的 key 已经存在，
    //    如果有，直接覆盖，put 方法返回旧值就结束了
    for (Entry<K,V> e = table[i]; e != null; e = e.next) {
        Object k;
        if (e.hash == hash && ((k = e.key) == key || key.equals(k))) {
            V oldValue = e.value;
            e.value = value;
            e.recordAccess(this);
            return oldValue;
        }
    }

    modCount++;
    // 4. 不存在重复的 key，将此 entry 添加到链表中，细节后面说
    addEntry(hash, key, value, i);
    return null;
}
```

**数组初始化**

```
private void inflateTable(int toSize) {
    // 保证数组大小一定是 2 的 n 次方。
    // 比如这样初始化：new HashMap(20)，那么处理成初始数组大小是 32
    int capacity = roundUpToPowerOf2(toSize);
    // 计算扩容阈值：capacity * loadFactor
    threshold = (int) Math.min(capacity * loadFactor, MAXIMUM_CAPACITY + 1);
    // 算是初始化数组吧
    table = new Entry[capacity];
    initHashSeedAsNeeded(capacity); //ignore
}
```

**计算数组具体位置**

```
static int indexFor(int hash, int length) {
    // assert Integer.bitCount(length) == 1 : "length must be a non-zero power of 2";
    return hash & (length-1);
}
```

**添加节点到链表中**

```
void addEntry(int hash, K key, V value, int bucketIndex) {
    // 如果当前 HashMap 大小已经达到了阈值，并且新值要插入的数组位置已经有元素了，那么要扩容
    if ((size >= threshold) && (null != table[bucketIndex])) {
        // 扩容，后面会介绍一下
        resize(2 * table.length);
        // 扩容以后，重新计算 hash 值
        hash = (null != key) ? hash(key) : 0;
        // 重新计算扩容后的新的下标
        bucketIndex = indexFor(hash, table.length);
    }
    // 往下看
    createEntry(hash, key, value, bucketIndex);
}

// 这个很简单，其实就是将新值放到扩容后的数组的相应位置处的链表的表头，然后 size++
void createEntry(int hash, K key, V value, int bucketIndex) {
    Entry<K,V> e = table[bucketIndex];
    table[bucketIndex] = new Entry<>(hash, key, value, e);
    size++;
}
```

**数组扩容**

```
void resize(int newCapacity) {
    Entry[] oldTable = table;
    int oldCapacity = oldTable.length;
    if (oldCapacity == MAXIMUM_CAPACITY) {
        threshold = Integer.MAX_VALUE;
        return;
    }
    // 新的数组
    Entry[] newTable = new Entry[newCapacity];
    // 将原来数组中的值迁移到新的更大的数组中
    transfer(newTable, initHashSeedAsNeeded(newCapacity));
    table = newTable;
    threshold = (int)Math.min(newCapacity * loadFactor, MAXIMUM_CAPACITY + 1);
}
```

##### get过程

相对于 put 过程，get 过程是非常简单的：

1. 根据 key 计算 hash 值。
2. 找到相应的数组下标：hash & (length – 1)。
3. 遍历该数组位置处的链表，直到找到相等(==或equals)的 key。

```
public V get(Object key) {
    // 之前说过，key 为 null 的话，会被放到 table[0]，所以只要遍历下 table[0] 处的链表就可以了
    if (key == null)
        return getForNullKey();
    // 
    Entry<K,V> entry = getEntry(key);

    return null == entry ? null : entry.getValue();
}
```

**getEntry(key)**

```
final Entry<K,V> getEntry(Object key) {
    if (size == 0) {
        return null;
    }

    int hash = (key == null) ? 0 : hash(key);
    // 确定数组下标，然后从头开始遍历链表，直到找到为止
    for (Entry<K,V> e = table[indexFor(hash, table.length)];
         e != null;
         e = e.next) {
        Object k;
        if (e.hash == hash &&
            ((k = e.key) == key || (key != null && key.equals(k))))
            return e;
    }
    return null;
}
```

#### Java7ConcurrentHashMap

整个 ConcurrentHashMap 由一个个 Segment 组成，Segment 代表”部分“或”一段“的意思，所以很多地方都会将其描述为**分段锁**。

简单理解就是，ConcurrentHashMap 是一个 Segment 数组，Segment 通过继承 ReentrantLock 来进行加锁，所以每次需要加锁的操作锁住的是一个 segment，这样只要保证每个 Segment 是线程安全的，也就实现了全局的线程安全。

![](https://mmbiz.qpic.cn/mmbiz_png/TNUwKhV0JpQ2dZ3WKkIM4iaa5WqfKFiaqjSWZZ6DUdg2C9V0LIWMnAF0fqkLcwB6anodqGXUr9dzUwGOxDiaGeTzw/640?tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

**concurrencyLevel：** 并行级别、并发数、Segment 数。默认是 16，也就是说 ConcurrentHashMap 有 16 个 Segments，所以理论上，这个时候，最多可以同时支持 16 个线程并发写，只要它们的操作分别分布在不同的 Segment 上。这个值可以在初始化的时候设置为其他值，但是一旦初始化以后，它是不可以扩容的。再具体到每个 Segment 内部，其实每个 Segment 很像之前介绍的 HashMap，不过它要保证线程安全，所以处理起来要麻烦些。

##### 初始化

- initialCapacity：初始容量，这个值指的是整个 ConcurrentHashMap 的初始容量，实际操作的时候需要平均分给每个 Segment。
- loadFactor：负载因子，之前我们说了，Segment 数组不可以扩容，所以这个负载因子是给每个 Segment 内部使用的。

```
public ConcurrentHashMap(int initialCapacity,
                         float loadFactor, int concurrencyLevel) {
    if (!(loadFactor > 0) || initialCapacity < 0 || concurrencyLevel <= 0)
        throw new IllegalArgumentException();
    if (concurrencyLevel > MAX_SEGMENTS)
        concurrencyLevel = MAX_SEGMENTS;
    // Find power-of-two sizes best matching arguments
    int sshift = 0;
    int ssize = 1;
    // 计算并行级别 ssize，因为要保持并行级别是 2 的 n 次方
    while (ssize < concurrencyLevel) {
        ++sshift;
        ssize <<= 1;
    }
    // 我们这里先不要那么烧脑，用默认值，concurrencyLevel 为 16，sshift 为 4
    // 那么计算出 segmentShift 为 28，segmentMask 为 15，后面会用到这两个值
    this.segmentShift = 32 - sshift;
    this.segmentMask = ssize - 1;

    if (initialCapacity > MAXIMUM_CAPACITY)
        initialCapacity = MAXIMUM_CAPACITY;

    // initialCapacity 是设置整个 map 初始的大小，
    // 这里根据 initialCapacity 计算 Segment 数组中每个位置可以分到的大小
    // 如 initialCapacity 为 64，那么每个 Segment 或称之为"槽"可以分到 4 个
    int c = initialCapacity / ssize;
    if (c * ssize < initialCapacity)
        ++c;
    // 默认 MIN_SEGMENT_TABLE_CAPACITY 是 2，这个值也是有讲究的，因为这样的话，对于具体的槽上，
    // 插入一个元素不至于扩容，插入第二个的时候才会扩容
    int cap = MIN_SEGMENT_TABLE_CAPACITY; 
    while (cap < c)
        cap <<= 1;

    // 创建 Segment 数组，
    // 并创建数组的第一个元素 segment[0]
    Segment<K,V> s0 =
        new Segment<K,V>(loadFactor, (int)(cap * loadFactor),
                         (HashEntry<K,V>[])new HashEntry[cap]);
    Segment<K,V>[] ss = (Segment<K,V>[])new Segment[ssize];
    // 往数组写入 segment[0]
    UNSAFE.putOrderedObject(ss, SBASE, s0); // ordered write of segments[0]
    this.segments = ss;
}
```

初始化完成，我们得到了一个 Segment 数组。就当是用 new ConcurrentHashMap() 无参构造函数进行初始化的，那么初始化完成后：

- Segment 数组长度为 16，不可以扩容
- Segment[i] 的默认大小为 2，负载因子是 0.75，得出初始阈值为 1.5，也就是以后插入第一个元素不会触发扩容，插入第二个会进行第一次扩容
- 这里初始化了 segment[0]，其他位置还是 null，至于为什么要初始化 segment[0]，后面的代码会介绍
- 当前 segmentShift 的值为 32 – 4 = 28，segmentMask 为 16 – 1 = 15，姑且把它们简单翻译为移位数和掩码，这两个值马上就会用到。

##### put过程

```
public V put(K key, V value) {
    Segment<K,V> s;
    if (value == null)
        throw new NullPointerException();
    // 1. 计算 key 的 hash 值
    int hash = hash(key);
    // 2. 根据 hash 值找到 Segment 数组中的位置 j
    //    hash 是 32 位，无符号右移 segmentShift(28) 位，剩下低 4 位，
    //    然后和 segmentMask(15) 做一次与操作，也就是说 j 是 hash 值的最后 4 位，也就是槽的数组下标
    int j = (hash >>> segmentShift) & segmentMask;
    // 刚刚说了，初始化的时候初始化了 segment[0]，但是其他位置还是 null，
    // ensureSegment(j) 对 segment[j] 进行初始化
    if ((s = (Segment<K,V>)UNSAFE.getObject          // nonvolatile; recheck
         (segments, (j << SSHIFT) + SBASE)) == null) //  in ensureSegment
        s = ensureSegment(j);
    // 3. 插入新值到 槽 s 中
    return s.put(key, hash, value, false);
}
```

根据 hash 值很快就能找到相应的 Segment，之后就是 Segment 内部的 put 操作了.

Segment 内部是由 **数组+链表** 组成的。

```
final V put(K key, int hash, V value, boolean onlyIfAbsent) {
    // 在往该 segment 写入前，需要先获取该 segment 的独占锁
    //    先看主流程，后面还会具体介绍这部分内容
    HashEntry<K,V> node = tryLock() ? null :
        scanAndLockForPut(key, hash, value);
    V oldValue;
    try {
        // 这个是 segment 内部的数组
        HashEntry<K,V>[] tab = table;
        // 再利用 hash 值，求应该放置的数组下标
        int index = (tab.length - 1) & hash;
        // first 是数组该位置处的链表的表头
        HashEntry<K,V> first = entryAt(tab, index);

        // 下面这串 for 循环虽然很长，不过也很好理解，想想该位置没有任何元素和已经存在一个链表这两种情况
        for (HashEntry<K,V> e = first;;) {
            if (e != null) {
                K k;
                if ((k = e.key) == key ||
                    (e.hash == hash && key.equals(k))) {
                    oldValue = e.value;
                    if (!onlyIfAbsent) {
                        // 覆盖旧值
                        e.value = value;
                        ++modCount;
                    }
                    break;
                }
                // 继续顺着链表走
                e = e.next;
            }
            else {
                // node 到底是不是 null，这个要看获取锁的过程，不过和这里都没有关系。
                // 如果不为 null，那就直接将它设置为链表表头；如果是null，初始化并设置为链表表头。
                if (node != null)
                    node.setNext(first);
                else
                    node = new HashEntry<K,V>(hash, key, value, first);

                int c = count + 1;
                // 如果超过了该 segment 的阈值，这个 segment 需要扩容
                if (c > threshold && tab.length < MAXIMUM_CAPACITY)
                    rehash(node); // 扩容后面也会具体分析
                else
                    // 没有达到阈值，将 node 放到数组 tab 的 index 位置，
                    // 其实就是将新的节点设置成原链表的表头
                    setEntryAt(tab, index, node);
                ++modCount;
                count = c;
                oldValue = null;
                break;
            }
        }
    } finally {
        // 解锁
        unlock();
    }
    return oldValue;
}
```

**初始化槽: ensureSegment**

ConcurrentHashMap 初始化的时候会初始化第一个槽 segment[0]，对于其他槽来说，在插入第一个值的时候进行初始化。

这里需要考虑并发，因为很可能会有多个线程同时进来初始化同一个槽 segment[k]，不过只要有一个成功了就可以。

```
private Segment<K,V> ensureSegment(int k) {
    final Segment<K,V>[] ss = this.segments;
    long u = (k << SSHIFT) + SBASE; // raw offset
    Segment<K,V> seg;
    if ((seg = (Segment<K,V>)UNSAFE.getObjectVolatile(ss, u)) == null) {
        // 这里看到为什么之前要初始化 segment[0] 了，
        // 使用当前 segment[0] 处的数组长度和负载因子来初始化 segment[k]
        // 为什么要用“当前”，因为 segment[0] 可能早就扩容过了
        Segment<K,V> proto = ss[0];
        int cap = proto.table.length;
        float lf = proto.loadFactor;
        int threshold = (int)(cap * lf);

        // 初始化 segment[k] 内部的数组
        HashEntry<K,V>[] tab = (HashEntry<K,V>[])new HashEntry[cap];
        if ((seg = (Segment<K,V>)UNSAFE.getObjectVolatile(ss, u))
            == null) { // 再次检查一遍该槽是否被其他线程初始化了。

            Segment<K,V> s = new Segment<K,V>(lf, threshold, tab);
            // 使用 while 循环，内部用 CAS，当前线程成功设值或其他线程成功设值后，退出
            while ((seg = (Segment<K,V>)UNSAFE.getObjectVolatile(ss, u))
                   == null) {//并发操作使用 CAS 进行控制
                if (UNSAFE.compareAndSwapObject(ss, u, null, seg = s))
                    break;
            }
        }
    }
    return seg;
}
```

> 如果当前线程 CAS 失败，这里的 while 循环是为了将 seg 赋值返回。

**获取写入锁scanAndLockForPut**

在往某个 segment 中 put 的时候，首先会调用 node = tryLock() ? null : scanAndLockForPut(key, hash, value)，也就是说先进行一次 tryLock() 快速获取该 segment 的独占锁，如果失败，那么进入到 scanAndLockForPut 这个方法来获取锁。

```
private HashEntry<K,V> scanAndLockForPut(K key, int hash, V value) {
    HashEntry<K,V> first = entryForHash(this, hash);
    HashEntry<K,V> e = first;
    HashEntry<K,V> node = null;
    int retries = -1; // negative while locating node

    // 循环获取锁
    while (!tryLock()) {
        HashEntry<K,V> f; // to recheck first below
        if (retries < 0) {
            if (e == null) {
                if (node == null) // speculatively create node
                    // 进到这里说明数组该位置的链表是空的，没有任何元素
                    // 当然，进到这里的另一个原因是 tryLock() 失败，所以该槽存在并发，不一定是该位置
                    node = new HashEntry<K,V>(hash, key, value, null);
                retries = 0;
            }
            else if (key.equals(e.key))
                retries = 0;
            else
                // 顺着链表往下走
                e = e.next;
        }
        // 重试次数如果超过 MAX_SCAN_RETRIES（单核1多核64），那么不抢了，进入到阻塞队列等待锁
        //    lock() 是阻塞方法，直到获取锁后返回
        else if (++retries > MAX_SCAN_RETRIES) {
            lock();
            break;
        }
        else if ((retries & 1) == 0 &&
                 // 这个时候是有大问题了，那就是有新的元素进到了链表，成为了新的表头
                 //     所以这边的策略是，相当于重新走一遍这个 scanAndLockForPut 方法
                 (f = entryForHash(this, hash)) != first) {
            e = first = f; // re-traverse if entry changed
            retries = -1;
        }
    }
    return node;
}
```

这个方法有两个出口，一个是 tryLock() 成功了，循环终止，另一个就是重试次数超过了 MAX_SCAN_RETRIES，进到 lock() 方法，此方法会阻塞等待，直到成功拿到独占锁。这个方法主要是**获取该 segment 的独占锁**，如果需要的话顺便实例化了一下 node。

**扩容：rehash**

重复一下，segment 数组不能扩容，扩容是 segment 数组某个位置内部的数组 HashEntry[] 进行扩容，扩容后，容量为原来的 2 倍。

put 的时候，如果判断该值的插入会导致该 segment 的元素个数超过阈值，那么先进行扩容，再插值.

该方法不需要考虑并发，因为到这里的时候，是持有该 segment 的独占锁的。

```
// 方法参数上的 node 是这次扩容后，需要添加到新的数组中的数据。
private void rehash(HashEntry<K,V> node) {
    HashEntry<K,V>[] oldTable = table;
    int oldCapacity = oldTable.length;
    // 2 倍
    int newCapacity = oldCapacity << 1;
    threshold = (int)(newCapacity * loadFactor);
    // 创建新数组
    HashEntry<K,V>[] newTable =
        (HashEntry<K,V>[]) new HashEntry[newCapacity];
    // 新的掩码，如从 16 扩容到 32，那么 sizeMask 为 31，对应二进制 ‘000...00011111’
    int sizeMask = newCapacity - 1;

    // 遍历原数组，老套路，将原数组位置 i 处的链表拆分到 新数组位置 i 和 i+oldCap 两个位置
    for (int i = 0; i < oldCapacity ; i++) {
        // e 是链表的第一个元素
        HashEntry<K,V> e = oldTable[i];
        if (e != null) {
            HashEntry<K,V> next = e.next;
            // 计算应该放置在新数组中的位置，
            // 假设原数组长度为 16，e 在 oldTable[3] 处，那么 idx 只可能是 3 或者是 3 + 16 = 19
            int idx = e.hash & sizeMask;
            if (next == null)   // 该位置处只有一个元素，那比较好办
                newTable[idx] = e;
            else { // Reuse consecutive sequence at same slot
                // e 是链表表头
                HashEntry<K,V> lastRun = e;
                // idx 是当前链表的头结点 e 的新位置
                int lastIdx = idx;

                // 下面这个 for 循环会找到一个 lastRun 节点，这个节点之后的所有元素是将要放到一起的
                for (HashEntry<K,V> last = next;
                     last != null;
                     last = last.next) {
                    int k = last.hash & sizeMask;
                    if (k != lastIdx) {
                        lastIdx = k;
                        lastRun = last;
                    }
                }
                // 将 lastRun 及其之后的所有节点组成的这个链表放到 lastIdx 这个位置
                newTable[lastIdx] = lastRun;
                // 下面的操作是处理 lastRun 之前的节点，
                //    这些节点可能分配在另一个链表中，也可能分配到上面的那个链表中
                for (HashEntry<K,V> p = e; p != lastRun; p = p.next) {
                    V v = p.value;
                    int h = p.hash;
                    int k = h & sizeMask;
                    HashEntry<K,V> n = newTable[k];
                    newTable[k] = new HashEntry<K,V>(h, p.key, v, n);
                }
            }
        }
    }
    // 将新来的 node 放到新数组中刚刚的 两个链表之一 的 头部
    int nodeIndex = node.hash & sizeMask; // add the new node
    node.setNext(newTable[nodeIndex]);
    newTable[nodeIndex] = node;
    table = newTable;
}
```

##### get过程

- 计算 hash 值，找到 segment 数组中的具体位置，或我们前面用的“槽”
- 槽中也是一个数组，根据 hash 找到数组中具体的位置
- 到这里是链表了，顺着链表进行查找即可、

```
public V get(Object key) {
    Segment<K,V> s; // manually integrate access methods to reduce overhead
    HashEntry<K,V>[] tab;
    // 1. hash 值
    int h = hash(key);
    long u = (((h >>> segmentShift) & segmentMask) << SSHIFT) + SBASE;
    // 2. 根据 hash 找到对应的 segment
    if ((s = (Segment<K,V>)UNSAFE.getObjectVolatile(segments, u)) != null &&
        (tab = s.table) != null) {
        // 3. 找到segment 内部数组相应位置的链表，遍历
        for (HashEntry<K,V> e = (HashEntry<K,V>) UNSAFE.getObjectVolatile
                 (tab, ((long)(((tab.length - 1) & h)) << TSHIFT) + TBASE);
             e != null; e = e.next) {
            K k;
            if ((k = e.key) == key || (e.hash == h && key.equals(k)))
                return e.value;
        }
    }
    return null;
}
```

##### 并发问题分析

**put操作的线程安全性**

1. 初始化槽，这个我们之前就说过了，使用了 CAS 来初始化 Segment 中的数组。
2. 添加节点到链表的操作是插入到表头的，所以，如果这个时候 get 操作在链表遍历的过程已经到了中间，是不会影响的。如果 get 操作在 put 之后，需要保证刚刚插入表头的节点被读取，这个依赖于 setEntryAt 方法中使用的 UNSAFE.putOrderedObject。
3. 扩容。扩容是新创建了数组，然后进行迁移数据，最后面将 newTable 设置给属性 table。所以，如果 get 操作此时也在进行，那么也没关系，如果 get 先行，那么就是在旧的 table 上做查询操作；而 put 先行，那么 put 操作的可见性保证就是 table 使用了 volatile 关键字。

**remove操作的线程安全性**

get 操作需要遍历链表，但是 remove 操作会”破坏”链表。

如果 remove 破坏的节点 get 操作已经过去了，那么这里不存在任何问题。

如果 remove 先破坏了一个节点，分两种情况考虑：

1. 如果此节点是头结点，那么需要将头结点的 next 设置为数组该位置的元素，table 虽然使用了 volatile 修饰，但是 volatile 并不能提供数组内部操作的可见性保证，所以源码中使用了 UNSAFE 来操作数组，请看方法 setEntryAt。
2. 如果要删除的节点不是头结点，它会将要删除节点的后继节点接到前驱节点中，这里的并发保证就是 next 属性是 volatile 的。

#### java8HashMap

由 **数组+链表+红黑树** 组成

根据 Java7 HashMap 的介绍，我们知道，查找的时候，根据 hash 值我们能够快速定位到数组的具体下标，但是之后的话，需要顺着链表一个个比较下去才能找到我们需要的，时间复杂度取决于链表的长度，为 **O(n)**。

为了降低这部分的开销，在 Java8 中，当链表中的元素超过了 8 个以后，会将链表转换为红黑树，在这些位置进行查找的时候可以降低时间复杂度为 O(logN)。

![](http://qianniu.javastack.cn/18-12-4/75398751.jpg)

Java7 中使用 Entry 来代表每个 HashMap 中的数据节点，Java8 中使用 **Node**，基本没有区别，都是 key，value，hash 和 next 这四个属性，不过，Node 只能用于链表的情况，红黑树的情况需要使用 **TreeNode**。

##### put过程

```
public V put(K key, V value) {
    return putVal(hash(key), key, value, false, true);
}
 
// 第三个参数 onlyIfAbsent 如果是 true，那么只有在不存在该 key 时才会进行 put 操作
// 第四个参数 evict 我们这里不关心
final V putVal(int hash, K key, V value, boolean onlyIfAbsent,
               boolean evict) {
    Node<K,V>[] tab; Node<K,V> p; int n, i;
    // 第一次 put 值的时候，会触发下面的 resize()，类似 java7 的第一次 put 也要初始化数组长度
    // 第一次 resize 和后续的扩容有些不一样，因为这次是数组从 null 初始化到默认的 16 或自定义的初始容量
    if ((tab = table) == null || (n = tab.length) == 0)
        n = (tab = resize()).length;
    // 找到具体的数组下标，如果此位置没有值，那么直接初始化一下 Node 并放置在这个位置就可以了
    if ((p = tab[i = (n - 1) & hash]) == null)
        tab[i] = newNode(hash, key, value, null);
 
    else {// 数组该位置有数据
        Node<K,V> e; K k;
        // 首先，判断该位置的第一个数据和我们要插入的数据，key 是不是"相等"，如果是，取出这个节点
        if (p.hash == hash &&
            ((k = p.key) == key || (key != null && key.equals(k))))
            e = p;
        // 如果该节点是代表红黑树的节点，调用红黑树的插值方法，本文不展开说红黑树
        else if (p instanceof TreeNode)
            e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);
        else {
            // 到这里，说明数组该位置上是一个链表
            for (int binCount = 0; ; ++binCount) {
                // 插入到链表的最后面(Java7 是插入到链表的最前面)
                if ((e = p.next) == null) {
                    p.next = newNode(hash, key, value, null);
                    // TREEIFY_THRESHOLD 为 8，所以，如果新插入的值是链表中的第 9 个
                    // 会触发下面的 treeifyBin，也就是将链表转换为红黑树
                    if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st
                        treeifyBin(tab, hash);
                    break;
                }
                // 如果在该链表中找到了"相等"的 key(== 或 equals)
                if (e.hash == hash &&
                    ((k = e.key) == key || (key != null && key.equals(k))))
                    // 此时 break，那么 e 为链表中[与要插入的新值的 key "相等"]的 node
                    break;
                p = e;
            }
        }
        // e!=null 说明存在旧值的key与要插入的key"相等"
        // 对于我们分析的put操作，下面这个 if 其实就是进行 "值覆盖"，然后返回旧值
        if (e != null) {
            V oldValue = e.value;
            if (!onlyIfAbsent || oldValue == null)
                e.value = value;
            afterNodeAccess(e);
            return oldValue;
        }
    }
    ++modCount;
    // 如果 HashMap 由于新插入这个值导致 size 已经超过了阈值，需要进行扩容
    if (++size > threshold)
        resize();
    afterNodeInsertion(evict);
    return null;
}
```

和 Java7 稍微有点不一样的地方就是，Java7 是先扩容后插入新值的，Java8 先插值再扩容

**数组扩容**

resize() 方法用于**初始化数组或数组扩容**，每次扩容后，容量为原来的 2 倍，并进行数据迁移。

```
final Node<K,V>[] resize() {
    Node<K,V>[] oldTab = table;
    int oldCap = (oldTab == null) ? 0 : oldTab.length;
    int oldThr = threshold;
    int newCap, newThr = 0;
    if (oldCap > 0) { // 对应数组扩容
        if (oldCap >= MAXIMUM_CAPACITY) {
            threshold = Integer.MAX_VALUE;
            return oldTab;
        }
        // 将数组大小扩大一倍
        else if ((newCap = oldCap << 1) < MAXIMUM_CAPACITY &&
                 oldCap >= DEFAULT_INITIAL_CAPACITY)
            // 将阈值扩大一倍
            newThr = oldThr << 1; // double threshold
    }
    else if (oldThr > 0) // 对应使用 new HashMap(int initialCapacity) 初始化后，第一次 put 的时候
        newCap = oldThr;
    else {// 对应使用 new HashMap() 初始化后，第一次 put 的时候
        newCap = DEFAULT_INITIAL_CAPACITY;
        newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);
    }
 
    if (newThr == 0) {
        float ft = (float)newCap * loadFactor;
        newThr = (newCap < MAXIMUM_CAPACITY && ft < (float)MAXIMUM_CAPACITY ?
                  (int)ft : Integer.MAX_VALUE);
    }
    threshold = newThr;
 
    // 用新的数组大小初始化新的数组
    Node<K,V>[] newTab = (Node<K,V>[])new Node[newCap];
    table = newTab; // 如果是初始化数组，到这里就结束了，返回 newTab 即可
 
    if (oldTab != null) {
        // 开始遍历原数组，进行数据迁移。
        for (int j = 0; j < oldCap; ++j) {
            Node<K,V> e;
            if ((e = oldTab[j]) != null) {
                oldTab[j] = null;
                // 如果该数组位置上只有单个元素，那就简单了，简单迁移这个元素就可以了
                if (e.next == null)
                    newTab[e.hash & (newCap - 1)] = e;
                // 如果是红黑树，具体我们就不展开了
                else if (e instanceof TreeNode)
                    ((TreeNode<K,V>)e).split(this, newTab, j, oldCap);
                else { 
                    // 这块是处理链表的情况，
                    // 需要将此链表拆成两个链表，放到新的数组中，并且保留原来的先后顺序
                    // loHead、loTail 对应一条链表，hiHead、hiTail 对应另一条链表，代码还是比较简单的
                    Node<K,V> loHead = null, loTail = null;
                    Node<K,V> hiHead = null, hiTail = null;
                    Node<K,V> next;
                    do {
                        next = e.next;
                        if ((e.hash & oldCap) == 0) {
                            if (loTail == null)
                                loHead = e;
                            else
                                loTail.next = e;
                            loTail = e;
                        }
                        else {
                            if (hiTail == null)
                                hiHead = e;
                            else
                                hiTail.next = e;
                            hiTail = e;
                        }
                    } while ((e = next) != null);
                    if (loTail != null) {
                        loTail.next = null;
                        // 第一条链表
                        newTab[j] = loHead;
                    }
                    if (hiTail != null) {
                        hiTail.next = null;
                        // 第二条链表的新的位置是 j + oldCap，这个很好理解
                        newTab[j + oldCap] = hiHead;
                    }
                }
            }
        }
    }
    return newTab;
}
```

##### get过程

1. 计算 key 的 hash 值，根据 hash 值找到对应数组下标: hash & (length-1)
2. 判断数组该位置处的元素是否刚好就是我们要找的，如果不是，走第三步
3. 判断该元素类型是否是 TreeNode，如果是，用红黑树的方法取数据，如果不是，走第四步
4. 遍历链表，直到找到相等(==或equals)的 key.

```
public V get(Object key) {
    Node<K,V> e;
    return (e = getNode(hash(key), key)) == null ? null : e.value;
}
```

```
final Node<K,V> getNode(int hash, Object key) {
    Node<K,V>[] tab; Node<K,V> first, e; int n; K k;
    if ((tab = table) != null && (n = tab.length) > 0 &&
        (first = tab[(n - 1) & hash]) != null) {
        // 判断第一个节点是不是就是需要的
        if (first.hash == hash && // always check first node
            ((k = first.key) == key || (key != null && key.equals(k))))
            return first;
        if ((e = first.next) != null) {
            // 判断是否是红黑树
            if (first instanceof TreeNode)
                return ((TreeNode<K,V>)first).getTreeNode(hash, key);
 
            // 链表遍历
            do {
                if (e.hash == hash &&
                    ((k = e.key) == key || (key != null && key.equals(k))))
                    return e;
            } while ((e = e.next) != null);
        }
    }
    return null;
}
```

#### java8 ConcurrentHashMap

![](http://qianniu.javastack.cn/18-12-4/335817.jpg)

结构上和 Java8 的 HashMap 基本上一样，不过它要保证线程安全性，所以在源码上确实要复杂一些。

##### 初始化

```
// 这构造函数里，什么都不干
public ConcurrentHashMap() {
}
public ConcurrentHashMap(int initialCapacity) {
    if (initialCapacity < 0)
        throw new IllegalArgumentException();
    int cap = ((initialCapacity >= (MAXIMUM_CAPACITY >>> 1)) ?
               MAXIMUM_CAPACITY :
               tableSizeFor(initialCapacity + (initialCapacity >>> 1) + 1));
    this.sizeCtl = cap;
}
```

##### put过程

```
public V put(K key, V value) {
    return putVal(key, value, false);
}
final V putVal(K key, V value, boolean onlyIfAbsent) {
    if (key == null || value == null) throw new NullPointerException();
    // 得到 hash 值
    int hash = spread(key.hashCode());
    // 用于记录相应链表的长度
    int binCount = 0;
    for (Node<K,V>[] tab = table;;) {
        Node<K,V> f; int n, i, fh;
        // 如果数组"空"，进行数组初始化
        if (tab == null || (n = tab.length) == 0)
            // 初始化数组，后面会详细介绍
            tab = initTable();
 
        // 找该 hash 值对应的数组下标，得到第一个节点 f
        else if ((f = tabAt(tab, i = (n - 1) & hash)) == null) {
            // 如果数组该位置为空，
            //    用一次 CAS 操作将这个新值放入其中即可，这个 put 操作差不多就结束了，可以拉到最后面了
            //          如果 CAS 失败，那就是有并发操作，进到下一个循环就好了
            if (casTabAt(tab, i, null,
                         new Node<K,V>(hash, key, value, null)))
                break;                   // no lock when adding to empty bin
        }
        // hash 居然可以等于 MOVED，这个需要到后面才能看明白，不过从名字上也能猜到，肯定是因为在扩容
        else if ((fh = f.hash) == MOVED)
            // 帮助数据迁移，这个等到看完数据迁移部分的介绍后，再理解这个就很简单了
            tab = helpTransfer(tab, f);
 
        else { // 到这里就是说，f 是该位置的头结点，而且不为空
 
            V oldVal = null;
            // 获取数组该位置的头结点的监视器锁
            synchronized (f) {
                if (tabAt(tab, i) == f) {
                    if (fh >= 0) { // 头结点的 hash 值大于 0，说明是链表
                        // 用于累加，记录链表的长度
                        binCount = 1;
                        // 遍历链表
                        for (Node<K,V> e = f;; ++binCount) {
                            K ek;
                            // 如果发现了"相等"的 key，判断是否要进行值覆盖，然后也就可以 break 了
                            if (e.hash == hash &&
                                ((ek = e.key) == key ||
                                 (ek != null && key.equals(ek)))) {
                                oldVal = e.val;
                                if (!onlyIfAbsent)
                                    e.val = value;
                                break;
                            }
                            // 到了链表的最末端，将这个新值放到链表的最后面
                            Node<K,V> pred = e;
                            if ((e = e.next) == null) {
                                pred.next = new Node<K,V>(hash, key,
                                                          value, null);
                                break;
                            }
                        }
                    }
                    else if (f instanceof TreeBin) { // 红黑树
                        Node<K,V> p;
                        binCount = 2;
                        // 调用红黑树的插值方法插入新节点
                        if ((p = ((TreeBin<K,V>)f).putTreeVal(hash, key,
                                                       value)) != null) {
                            oldVal = p.val;
                            if (!onlyIfAbsent)
                                p.val = value;
                        }
                    }
                }
            }
            // binCount != 0 说明上面在做链表操作
            if (binCount != 0) {
                // 判断是否要将链表转换为红黑树，临界值和 HashMap 一样，也是 8
                if (binCount >= TREEIFY_THRESHOLD)
                    // 这个方法和 HashMap 中稍微有一点点不同，那就是它不是一定会进行红黑树转换，
                    // 如果当前数组的长度小于 64，那么会选择进行数组扩容，而不是转换为红黑树
                    //    具体源码我们就不看了，扩容部分后面说
                    treeifyBin(tab, i);
                if (oldVal != null)
                    return oldVal;
                break;
            }
        }
    }
    // 
    addCount(1L, binCount);
    return null;
}
```

**初始化过程：initTable**

初始化一个合适大小的数组，然后会设置 sizeCtl。初始化方法中的并发问题是通过对 sizeCtl 进行一个 CAS 操作来控制的。

**链表转红黑树treeifyBin**

treeifyBin 不一定就会进行红黑树转换，也可能是仅仅做数组扩容

**扩容：tryPresize**

这里的扩容也是做翻倍扩容的，扩容后数组容量为原来的 2 倍。

**数据迁移：transfer**

将原来的 tab 数组的元素迁移到新的 nextTab 数组中

此方法支持多线程执行，外围调用此方法的时候，会保证第一个发起数据迁移的线程，nextTab 参数为 null，之后再调用此方法的时候，nextTab 不会为 null。

##### get过程

1. 计算hash值
2. 根据 hash 值找到数组对应位置: (n – 1) & h
3. 根据该位置处结点性质进行相应查找：
   - 如果该位置为 null，那么直接返回 null 就可以了
   - 如果该位置处的节点刚好就是我们需要的，返回该节点的值即可
   - 如果该位置节点的 hash 值小于 0，说明正在扩容，或者是红黑树，后面我们再介绍 find 方法
   - 如果以上 3 条都不满足，那就是链表，进行遍历比对即可。

### HashMap常见面试题 

#### ？HashMap线程安全的吗

它是线程不安全的：

- 当用在方法内的局部变量时，局部变量属于当前线程级别的变量，其他线程访问不了，所以这时也不存在线程安全不安全的问题了。
- 当用在单例对象成员变量的时候呢？这时候多个线程过来访问的就是同一个HashMap了，对同个HashMap操作这时候就存在线程安全的问题了。

#### ?几种常见的线程安全的map

##### HashTable

HashTable的get/put方法都被synchronized关键字修饰，说明它们是方法级别阻塞的，它们占用共享资源锁，所以导致同时只能一个线程操作get或者put，而且get/put操作不能同时执行，所以这种同步的集合效率非常低，一般不建议使用这个集合。

```
    @SuppressWarnings("unchecked")
    public synchronized V get(Object key) {
        Entry<?,?> tab[] = table;
        int hash = key.hashCode();
        int index = (hash & 0x7FFFFFFF) % tab.length;
        for (Entry<?,?> e = tab[index] ; e != null ; e = e.next) {
            if ((e.hash == hash) && e.key.equals(key)) {
                return (V)e.value;
            }
        }
        return null;
    }
```

```
public synchronized V put(K key, V value) {
        // Make sure the value is not null
        if (value == null) {
            throw new NullPointerException();
        }

        // Makes sure the key is not already in the hashtable.
        Entry<?,?> tab[] = table;
        int hash = key.hashCode();
        int index = (hash & 0x7FFFFFFF) % tab.length;
        @SuppressWarnings("unchecked")
        Entry<K,V> entry = (Entry<K,V>)tab[index];
        for(; entry != null ; entry = entry.next) {
            if ((entry.hash == hash) && entry.key.equals(key)) {
                V old = entry.value;
                entry.value = value;
                return old;
            }
        }

        addEntry(hash, key, value, index);
        return null;
    }
```

##### **SynchronizedMap**

这种是直接使用工具类里面的方法创建SynchronizedMap，把传入进行的HashMap对象进行了包装同步而已

这个同步方式实现也比较简单，看出SynchronizedMap的实现方式是加了个对象锁，每次对HashMap的操作都要先获取这个mutex的对象锁才能进入，所以性能也不会比HashTable好到哪里去，也不建议使用。

```
private static class SynchronizedMap<K,V>
        implements Map<K,V>, Serializable {
        private static final long serialVersionUID = 1978198479659022715L;

        private final Map<K,V> m;     // Backing Map
        final Object      mutex;        // Object on which to synchronize

        SynchronizedMap(Map<K,V> m) {
            this.m = Objects.requireNonNull(m);
            mutex = this;
        }

        SynchronizedMap(Map<K,V> m, Object mutex) {
            this.m = m;
            this.mutex = mutex;
        }

        public int size() {
            synchronized (mutex) {return m.size();}
        }
        public boolean isEmpty() {
            synchronized (mutex) {return m.isEmpty();}
        }
        public V get(Object key) {
            synchronized (mutex) {return m.get(key);}
        }
        public V put(K key, V value) {
            synchronized (mutex) {return m.put(key, value);}
        }
        public V remove(Object key) {
            synchronized (mutex) {return m.remove(key);}
        }
        
        //......
    }
```

##### **ConcurrentHashMap**

最推荐使用的线程安全的Map，也是实现方式最复杂的一个集合，每个版本的实现方式也不一样，在jdk8之前是使用分段加锁的一个方式，分成16个桶，每次只加锁其中一个桶，而在jdk8又加入了红黑树和CAS算法来实现。

#### ? java7与java8的HashMap和ConcurrentMap对比

[参考](https://www.cnblogs.com/hts-technology/p/9305118.html)

#### ? **JDK1.7的concurrenthashmap和JDK1.8又有什么区别？**

1.8的实现已经抛弃了Segment分段锁机制，利用Node数组+CAS+Synchronized来保证并发更新的安全，底层采用数组+链表+红黑树的存储结构。

#### ? jdk1.7和jdk1.8的HashMap区别

1. JDK1.7用的是头插法，而JDK1.8及之后使用的都是尾插法，那么为什么要这样做呢？因为JDK1.7是用单链表进行的纵向延伸，当采用头插法就是能够提高插入的效率，但是也会容易出现逆序且环形链表死循环问题。但是在JDK1.8之后是因为加入了红黑树使用尾插法，能够避免出现逆序且链表死循环的问题。
2. 扩容后数据存储位置的计算方式也不一样：
   - 在JDK1.7的时候是直接用hash值和需要扩容的二进制数进行&（这里就是为什么扩容的时候为啥一定必须是2的多少次幂的原因所在，因为如果只有2的n次幂的情况时最后一位二进制数才一定是1，这样能最大程度减少hash碰撞）（hash值 & length-1） 。
   - 而在JDK1.8的时候直接用了JDK1.7的时候计算的规律，也就是扩容前的原始位置+扩容的大小值=JDK1.8的计算方式，而不再是JDK1.7的那种异或的方法。但是这种方式就相当于只需要判断Hash值的新增参与运算的位是0还是1就直接迅速计算出了扩容后的储存方式。
3. JDK1.7的时候使用的是数组+ 单链表的数据结构。但是在JDK1.8及之后时，使用的是数组+链表+红黑树的数据结构（当链表的深度达到8的时候，也就是默认阈值，就会自动扩容把链表转成红黑树的数据结构来把时间复杂度从O（N）变成O（logN）提高了效率）。

#### ？ HashMap与HashTable区别

- HashMap几乎可以等价于Hashtable，除了HashMap是非synchronized的，并可以接受null(HashMap可以接受为null的键值(key)和值(value)，而Hashtable则不行)。

- HashMap是非synchronized，而Hashtable是synchronized，这意味着Hashtable是线程安全的，多个线程可以共享一个Hashtable；而如果没有正确的同步的话，多个线程是不能共享HashMap的。Java 5提供了ConcurrentHashMap，它是HashTable的替代，比HashTable的扩展性更好。

- 另一个区别是HashMap的迭代器(Iterator)是fail-fast迭代器，而Hashtable的enumerator迭代器不是fail-fast的。所以当有其它线程改变了HashMap的结构（增加或者移除元素），将会抛出ConcurrentModificationException，但迭代器本身的remove()方法移除元素则不会抛出ConcurrentModificationException异常。但这并不是一个一定发生的行为，要看JVM。这条同样也是Enumeration和Iterator的区别。

- 由于Hashtable是线程安全的也是synchronized，所以在单线程环境下它比HashMap要慢。如果你不需要同步，只需要单一线程，那么使用HashMap性能要好过Hashtable。

- HashMap不能保证随着时间的推移Map中的元素次序是不变的。

- HashMap提供对key的Set进行遍历，因此它是fail-fast的，但HashTable提供对key的Enumeration进行遍历，它不支持fail-fast。

- HashMap是对Map接口的实现，HashTable实现了Map接口和Dictionary抽象类

- HashMap的初始容量为16，Hashtable初始容量为11，两者的填充因子默认都是0.75。

  HashMap扩容时是当前容量翻倍，即:capacity*2，Hashtable扩容时是容量翻倍+1，即:capacity*2+1

- **两者计算hash的方法不同：**

  - Hashtable计算hash是直接使用key的hashcode对table数组的长度直接进行取模
  - HashMap计算hash对key的hashcode进行了二次hash，以获得更好的散列值，然后对table数组长度取摸

- **HashMap和Hashtable的底层实现都是数组+链表结构实现。** 

### 集合框架常见面试题 

#### ？ 集合框架的优点

- 使用核心集合类降低开发成本，而非实现我们自己的集合类。
- 随着使用经过严格测试的集合框架类，代码质量会得到提高。
- 通过使用JDK附带的集合类，可以降低代码维护成本。
- 复用性和可操作性。

#### ？ 集合框架中的泛型有什么优点

- Java1.5引入了泛型，所有的集合接口和实现都大量地使用它。
- 泛型允许我们为集合提供一个可以容纳的对象类型，因此，如果你添加其它类型的任何元素，它会在编译时报错。
- 这避免了在运行时出现ClassCastException，因为你将会在编译时得到报错信息。
- 泛型也使得代码整洁，我们不需要使用显式转换和instanceOf操作符。
- 它也给运行时带来好处，因为不会产生类型检查的字节码指令。

#### ? Java集合框架的基础接口有哪些

Collection为集合层级的根接口。一个集合代表一组对象，这些对象即为它的元素。Java平台不提供这个接口任何直接的实现。

Set是一个不能包含重复元素的集合。这个接口对数学集合抽象进行建模，被用来代表集合，就如一副牌。

List是一个有序集合，可以包含重复元素。你可以通过它的索引来访问任何元素。List更像长度动态变换的数组。

Map是一个将key映射到value的对象.一个Map不能包含重复的key：每个key最多只能映射一个value。

一些其它的接口有Queue、Dequeue、SortedSet、SortedMap和ListIterator。

#### ？ **fail-fast与fail-safe有什么区别**

Iterator的fail-fast属性与当前的集合共同起作用，因此它不会受到集合中任何改动的影响。Java.util包中的所有集合类都被设计为fail-fast的，

而java.util.concurrent中的集合类都为fail-safe的。

Fall—fast迭代器抛出ConcurrentModificationException，

fall—safe迭代器从不抛出ConcurrentModificationException。

#### ？ 如何决定选用HashMap还是TreeMap

对于在Map中插入、删除和定位元素这类操作，HashMap是最好的选择。然而，假如你需要对一个有序的key集合进行遍历，TreeMap是更好的选择。基于你的collection的大小，也许向HashMap中添加元素会更快，将map换为TreeMap进行有序key的遍历。

#### ? ArrayList和Vector有何异同点

ArrayList和Vector在很多时候都很类似:

- 两者都是基于索引的，内部由一个数组支持。
- 两者维护插入的顺序，我们可以根据插入顺序来获取元素。
- ArrayList和Vector的迭代器实现都是fail-fast的。
- ArrayList和Vector两者允许null值，也可以使用索引值对元素进行随机访问。

两者的区别：

- Vector是同步的，而ArrayList不是。然而，如果你寻求在迭代的时候对列表进行改变，你应该使用CopyOnWriteArrayList。
- ArrayList比Vector快，它因为有同步，不会过载。
- ArrayList更加通用，因为我们可以使用Collections工具类轻易地获取同步列表和只读列表。

#### ? Array和ArrayList有何区别？什么时候更适合用Array

Array可以容纳基本类型和对象，而ArrayList只能容纳对象。

Array是指定大小的，而ArrayList大小是固定的。

Array没有提供ArrayList那么多功能，比如addAll、removeAll和iterator等。尽管ArrayList明显是更好的选择，但也有些时候Array比较好用：

- 如果列表的大小已经指定，大部分情况下是存储和遍历它们。
- 对于遍历基本数据类型，尽管Collections使用自动装箱来减轻编码任务，在指定大小的基本类型的列表上工作也会变得很慢。
- 如果你要使用多维数组，使用【】【】 比   List<List<>>更容易。

#### ?  ArrayList和LinkedList有何区别

ArrayList和LinkedList两者都实现了List接口，但是它们之间有些不同"

- ArrayList是由Array所支持的基于一个索引的数据结构，所以它提供对元素的随机访问，复杂度为O(1)，但LinkedList存储一系列的节点数据，每个节点都与前一个和下一个节点相连接。所以，尽管有使用索引获取元素的方法，内部实现是从起始点开始遍历，遍历到索引的节点然后返回元素，时间复杂度为O(n)，比ArrayList要慢。
- 与ArrayList相比，在LinkedList中插入、添加和删除一个元素会更快，因为在一个元素被插入到中间的时候，不会涉及改变数组的大小，或更新索引。
- LinkedList比ArrayList消耗更多的内存，因为LinkedList中的每个节点存储了前后节点的引用。

#### ?  哪些集合类提供对元素的随机访问

ArrayList、HashMap、TreeMap和HashTable类提供对元素的随机访问。

#### ？ 哪些集合类是线程安全的

Vector、HashTable、Properties和Stack是同步类，所以它们是线程安全的，可以在多线程环境下使用。Java1.5并发API包括一些集合类，允许迭代时修改，因为它们都工作在集合的克隆上，所以它们在多线程环境中是安全的。

#### ? 队列和栈是什么，列出它们的区别

栈和队列两者都被用来预存储数据。java.util.Queue是一个接口，它的实现类在Java并发包中。队列允许先进先出（FIFO）检索元素，但并非总是这样。Queue接口允许从两端检索元素。栈与队列很相似，但它允许对元素进行后进先出（LIFO）进行检索。Stack是一个扩展自Vector的类，而Queue是一个接口。

#### ？**Collections类是什么**

Java.util.Collections是一个工具类仅包含静态方法，它们操作或返回集合。

它包含操作集合的多态算法，返回一个由指定集合支持的新集合和其它一些内容。这个类包含集合框架算法的方法，比如折半搜索、排序、混编和逆序等。

#### ？ **Comparable和Comparator接口有何区别**

Comparable和Comparator接口被用来对对象集合或者数组进行排序。Comparable接口被用来提供对象的自然排序，我们可以使用它来提供基于单个逻辑的排序。

Comparator接口被用来提供不同的排序算法，我们可以选择需要使用的Comparator来对给定的对象集合进行排序。

#### ？ 如何对一组对象进行排序

如果我们需要对一个对象数组进行排序，我们可以使用Arrays.sort()方法。如果我们需要排序一个对象列表，我们可以使用Collection.sort()方法。

两个类都有用于自然排序（使用Comparable）或基于标准的排序（使用Comparator）的重载方法sort()。Collections内部使用数组排序方法，所有它们两者都有相同的性能，只是Collections需要花时间将列表转换为数组。

#### ？ 如何从给定集合那里创建一个synchronized的集合

我们可以使用Collections.synchronizedCollection(Collection c)根据指定集合来获取一个synchronized（线程安全的）集合。

#### ？ **Iterator和ListIterator的区别**

- ListIterator有add()方法，可以向List中添加对象，而Iterator不能。
- ListIterator和Iterator都有hasNext()和next()方法，可以实现顺序向后遍历，但是ListIterator有hasPrevious()和previous()方法，可以实现逆向（顺序向前）遍历。Iterator就不可以。
- ListIterator可以定位当前的索引位置，nextIndex()和previousIndex()可以实现。Iterator没有此功能。
- 都可实现删除对象，但是ListIterator可以实现对象的修改，set()方法可以实现。Iierator仅能遍历，不能修改。

#### ？**什么是CopyOnWriteArrayList，它与ArrayList有何不同**

CopyOnWriteArrayList是ArrayList的一个线程安全的变体，其中所有可变操作（add、set等等）都是通过对底层数组进行一次新的复制来实现的。相比较于ArrayList它的写操作要慢一些，因为它需要实例的快照。

CopyOnWriteArrayList中写操作需要大面积复制数组，所以性能肯定很差，但是读操作因为操作的对象和写操作不是同一个对象，读之间也不需要加锁，读和写之间的同步处理只是在写完后通过一个简单的"="将引用指向新的数组对象上来，这个几乎不需要时间，这样读操作就很快很安全，适合在多线程里使用，绝对不会发生ConcurrentModificationException ，因此CopyOnWriteArrayList适合使用在读操作远远大于写操作的场景里，比如缓存。

#### ？ **Hashmap如何同步**

**当我们需要一个同步的HashMap时，有两种选择：**

- 使用Collections.synchronizedMap（..）来同步HashMap。
- 使用ConcurrentHashMap的

这两个选项之间的首选是使用ConcurrentHashMap，这是因为我们不需要锁定整个对象，以及通过ConcurrentHashMap分区地图来获得锁。

#### ？ **IdentityHashMap和HashMap的区别**

IdentityHashMap是Map接口的实现。不同于HashMap的，这里采用参考平等。

- 在HashMap中如果两个元素是相等的，则key1.equals(key2)
- 在IdentityHashMap中如果两个元素是相等的，则key1 == key2

